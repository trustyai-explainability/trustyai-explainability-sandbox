Name,HF dataset downloads,Exists,Dataset,Evaluation Type,OpenLLM leaderboard,Tier
gsm8k,540352,true,gsm8k,generate_until,false,1
gsm8k_llama,540352,false,Unknown,Unknown,false,3
gsm8k_cot_zeroshot,540352,true,gsm8k,generate_until,false,1
gsm8k_cot,540352,true,gsm8k,generate_until,false,1
gsm8k_cot_llama,540352,true,gsm8k,generate_until,false,1
gsm8k_cot_self_consistency,540352,true,gsm8k,generate_until,false,1
c4,280882,false,Unknown,Unknown,false,3
chain_of_thought,271045,false,Unknown,Unknown,false,3
mrpc,252292,true,glue,multiple_choice,false,1
rte,252292,true,glue,multiple_choice,false,1
qnli,252292,true,glue,multiple_choice,false,1
mnli,252292,true,glue,multiple_choice,false,1
mnli_mismatch,252292,true,glue,multiple_choice,false,1
sst2,252292,true,glue,multiple_choice,false,1
qqp,252292,true,glue,multiple_choice,false,1
wnli,252292,true,glue,multiple_choice,false,1
cola,252292,true,glue,multiple_choice,false,1
glue,252292,false,Unknown,Unknown,false,3
ai2_arc,219310,false,Unknown,Unknown,false,3
arc_challenge_chat,219310,true,allenai/ai2_arc,generate_until,false,1
llama,219310,false,Unknown,Unknown,false,3
arc_challenge_llama,219310,false,Unknown,Unknown,false,3
arc_easy,219310,true,allenai/ai2_arc,multiple_choice,false,1
arc_challenge,219310,true,allenai/ai2_arc,multiple_choice,false,1
openllm,213563,true,Unknown,Unknown,false,1
hellaswag,186239,true,hellaswag,multiple_choice,false,1
winogrande,158151,true,winogrande,multiple_choice,false,1
mmlu_college_physics,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu,140066,true,Unknown,Unknown,false,1
mmlu_college_biology,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_astronomy,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_jurisprudence,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_other,140066,true,Unknown,Unknown,false,1
mmlu_stem,140066,true,Unknown,Unknown,false,1
mmlu_us_foreign_policy,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_humanities,140066,true,Unknown,Unknown,false,1
mmlu_elementary_mathematics,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_abstract_algebra,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_college_medicine,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_macroeconomics,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_clinical_knowledge,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_formal_logic,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_professional_accounting,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_computer_science,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_nutrition,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_philosophy,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_marketing,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_biology,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_physics,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_human_sexuality,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_professional_medicine,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_business_ethics,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_electrical_engineering,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_anatomy,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_security_studies,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_european_history,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_medical_genetics,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_logical_fallacies,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_moral_scenarios,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_public_relations,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_global_facts,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_miscellaneous,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_human_aging,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_geography,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_moral_disputes,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_world_history,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_mathematics,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_microeconomics,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_conceptual_physics,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_machine_learning,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_government_and_politics,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_college_computer_science,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_psychology,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_us_history,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_college_mathematics,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_social_sciences,140066,true,Unknown,Unknown,false,1
mmlu_high_school_chemistry,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_international_law,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_computer_security,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_virology,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_professional_psychology,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_world_religions,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_humanities_tasks,140066,false,Unknown,Unknown,false,3
mmlu_social_sciences_tasks,140066,false,Unknown,Unknown,false,3
mmlu_other_tasks,140066,false,Unknown,Unknown,false,3
mmlu_stem_tasks,140066,false,Unknown,Unknown,false,3
mmlu_professional_law,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_prehistory,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_statistics,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_management,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_sociology,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_college_chemistry,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_econometrics,140066,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_cot_zeroshot,139126,true,Unknown,Unknown,false,1
mmlu_generative,139126,true,Unknown,Unknown,false,1
mmlu_cot_llama_stem_tasks,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_other_tasks,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_social_sciences_tasks,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_humanities_tasks,139126,false,Unknown,Unknown,false,3
mmlu_flan_n_shot_loglikelihood,139126,true,Unknown,Unknown,false,1
mmlu_continuation,139126,true,Unknown,Unknown,false,1
mmlu_flan_n_shot_generative,139126,true,Unknown,Unknown,false,1
mmlu_llama_high_school_computer_science,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_high_school_european_history,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_high_school_geography,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot,139126,true,Unknown,Unknown,false,1
mmlu_llama_world_religions,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_medical_genetics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_astronomy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_humanities_tasks,139126,false,Unknown,Unknown,false,3
mmlu_llama_social_sciences_tasks,139126,false,Unknown,Unknown,false,3
mmlu_llama_other_tasks,139126,false,Unknown,Unknown,false,3
mmlu_llama_security_studies,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_stem_tasks,139126,false,Unknown,Unknown,false,3
mmlu_llama_abstract_algebra,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_college_biology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_college_physics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_jurisprudence,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_college_medicine,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_clinical_knowledge,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_moral_scenarios,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_high_school_mathematics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_moral_disputes,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_philosophy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_high_school_microeconomics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_marketing,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_formal_logic,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_college_biology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_social_sciences,139126,true,Unknown,Unknown,false,1
mmlu_llama_humanities,139126,true,Unknown,Unknown,false,1
mmlu_llama,139126,true,Unknown,Unknown,false,1
mmlu_llama_logical_fallacies,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_anatomy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_electrical_engineering,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_business_ethics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_professional_medicine,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_human_sexuality,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_high_school_physics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_high_school_biology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_nutrition,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_computer_security,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_us_foreign_policy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_professional_law,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_professional_accounting,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_virology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_high_school_world_history,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_high_school_government_and_politics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_high_school_psychology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_human_aging,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_high_school_us_history,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_international_law,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_college_computer_science,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_conceptual_physics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_miscellaneous,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_global_facts,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_prehistory,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_elementary_mathematics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_econometrics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_stem,139126,true,Unknown,Unknown,false,1
mmlu_flan_cot_fewshot_high_school_european_history,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_world_religions,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_high_school_world_history,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_high_school_government_and_politics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_professional_psychology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_high_school_statistics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_college_chemistry,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_sociology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_management,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_econometrics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_prehistory,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_virology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_management,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_public_relations,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_sociology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_college_chemistry,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_high_school_statistics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_professional_psychology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_machine_learning,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_high_school_chemistry,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_college_mathematics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_high_school_geography,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_moral_disputes,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_high_school_mathematics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_high_school_microeconomics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_computer_security,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_miscellaneous,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_other,139126,true,Unknown,Unknown,false,1
mmlu_flan_cot_fewshot_jurisprudence,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_college_medicine,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_clinical_knowledge,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_high_school_macroeconomics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_college_mathematics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_high_school_chemistry,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_llama_machine_learning,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_professional_law,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_us_foreign_policy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_nutrition,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_philosophy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_marketing,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_high_school_biology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_high_school_physics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_human_sexuality,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_professional_medicine,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_business_ethics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_electrical_engineering,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_anatomy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_logical_fallacies,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_virology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_professional_accounting,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_security_studies,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_high_school_computer_science,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_public_relations,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_elementary_mathematics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_formal_logic,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_global_facts,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_medical_genetics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_moral_scenarios,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_professional_law,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_marketing,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_world_religions,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_cot_llama_moral_scenarios,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_biology,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_stem,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_macroeconomics,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_humanities,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_abstract_algebra,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_astronomy,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_social_sciences,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_college_biology,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_college_physics,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_jurisprudence,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_college_medicine,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_clinical_knowledge,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_medical_genetics,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_physics,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_global_facts,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_formal_logic,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_elementary_mathematics,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_public_relations,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_computer_science,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_security_studies,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_european_history,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_professional_accounting,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_logical_fallacies,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_anatomy,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_electrical_engineering,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_business_ethics,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_professional_medicine,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_marketing,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_philosophy,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_nutrition,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_econometrics,139126,false,Unknown,Unknown,false,3
mmlu_continuation_high_school_macroeconomics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_cot_llama_us_foreign_policy,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_professional_law,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_virology,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_world_religions,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_world_history,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_government_and_politics,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_psychology,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_human_aging,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_us_history,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_international_law,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_college_computer_science,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_conceptual_physics,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_miscellaneous,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_computer_security,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_microeconomics,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_mathematics,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_moral_disputes,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_geography,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_college_mathematics,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_chemistry,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_machine_learning,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_professional_psychology,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_high_school_statistics,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_college_chemistry,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_sociology,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_management,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_human_sexuality,139126,false,Unknown,Unknown,false,3
mmlu_cot_llama_prehistory,139126,false,Unknown,Unknown,false,3
mmlu_flan_cot_zeroshot_high_school_world_history,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_high_school_chemistry,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_philosophy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_nutrition,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_us_foreign_policy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_abstract_algebra,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_high_school_macroeconomics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_prehistory,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_econometrics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_management,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_sociology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_college_chemistry,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_high_school_statistics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_professional_psychology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_machine_learning,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_college_mathematics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_cot_llama_other,139126,false,Unknown,Unknown,false,3
mmlu_flan_cot_zeroshot_high_school_geography,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_moral_disputes,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_high_school_mathematics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_high_school_microeconomics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_computer_security,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_miscellaneous,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_conceptual_physics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_college_computer_science,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_international_law,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_high_school_us_history,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_human_aging,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_high_school_psychology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_high_school_government_and_politics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_global_facts,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_econometrics_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_prehistory_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_prehistory,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_college_physics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_astronomy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_high_school_biology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_high_school_physics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_human_sexuality,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_professional_medicine,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_business_ethics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_electrical_engineering,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_anatomy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_logical_fallacies,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_professional_accounting,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_high_school_european_history,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_security_studies,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_high_school_computer_science,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_public_relations,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_international_law,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_elementary_mathematics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_medical_genetics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_moral_scenarios,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_clinical_knowledge,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_college_medicine,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_jurisprudence,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_college_physics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_college_biology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_astronomy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_abstract_algebra,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_high_school_macroeconomics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_college_computer_science,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_conceptual_physics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_high_school_us_history,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_public_relations_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_continuation_high_school_world_history,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_biology_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_high_school_physics_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_human_sexuality_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_professional_medicine_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_business_ethics_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_electrical_engineering_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_anatomy_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_logical_fallacies_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_professional_accounting_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_high_school_european_history_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_security_studies_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_high_school_computer_science_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_human_aging,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_continuation_virology,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_formal_logic_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_global_facts_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_medical_genetics_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_moral_scenarios_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_clinical_knowledge_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_college_medicine_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_jurisprudence_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_marketing_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_college_physics_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_philosophy_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_us_foreign_policy_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_professional_psychology_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_machine_learning_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_loglikelihood_nutrition,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_generative_high_school_physics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_college_mathematics_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_world_religions,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_continuation_high_school_european_history,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_professional_accounting,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_logical_fallacies,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_anatomy,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_electrical_engineering,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_business_ethics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_generative_college_medicine,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_jurisprudence,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_college_physics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_public_relations,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_high_school_computer_science,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_security_studies,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_high_school_european_history,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_virology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_professional_accounting,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_professional_law,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_us_foreign_policy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_nutrition,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_philosophy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_marketing,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_astronomy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_high_school_biology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_human_sexuality,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_professional_medicine,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_business_ethics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_electrical_engineering,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_anatomy,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_logical_fallacies,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_high_school_chemistry_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_high_school_geography_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_moral_scenarios,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_continuation_high_school_psychology,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_elementary_mathematics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_public_relations,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_high_school_computer_science,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_security_studies,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_high_school_us_history,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_astronomy_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_continuation_human_aging,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_medical_genetics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_miscellaneous,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_college_physics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_management,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_college_mathematics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_high_school_government_and_politics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_professional_psychology,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_global_facts,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_high_school_statistics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_college_chemistry,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_prehistory,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_sociology,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_high_school_geography,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_computer_security,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_econometrics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_moral_disputes,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_high_school_mathematics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_high_school_microeconomics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_macroeconomics_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_continuation_high_school_chemistry,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_machine_learning,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_formal_logic,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_moral_scenarios,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_moral_disputes_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_virology_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_high_school_mathematics_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_high_school_microeconomics_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_computer_security_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_miscellaneous_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_conceptual_physics_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_college_computer_science_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_continuation_world_religions,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_high_school_us_history_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_human_aging_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_high_school_psychology_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_high_school_government_and_politics_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_high_school_world_history_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_world_religions_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_professional_law_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_continuation_conceptual_physics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_nutrition_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_college_biology_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_international_law_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_abstract_algebra_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_continuation_college_computer_science,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_international_law,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_high_school_macroeconomics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_abstract_algebra,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_astronomy,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_college_biology,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_jurisprudence,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_college_medicine,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_clinical_knowledge,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_generative_clinical_knowledge,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_elementary_mathematics_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_medical_genetics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_college_chemistry_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_continuation_other,139126,false,Unknown,Unknown,false,3
mmlu_continuation_social_sciences,139126,false,Unknown,Unknown,false,3
mmlu_continuation_humanities,139126,false,Unknown,Unknown,false,3
mmlu_stem_generative,139126,false,Unknown,Unknown,false,3
mmlu_other_generative,139126,false,Unknown,Unknown,false,3
mmlu_social_sciences_generative,139126,false,Unknown,Unknown,false,3
mmlu_humanities_generative,139126,false,Unknown,Unknown,false,3
mmlu_flan_cot_zeroshot_stem,139126,false,Unknown,Unknown,false,3
mmlu_flan_cot_zeroshot_social_sciences,139126,false,Unknown,Unknown,false,3
mmlu_continuation_philosophy,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_nutrition,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_professional_psychology,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_us_foreign_policy,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_philosophy,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_world_religions,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_marketing,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_high_school_biology,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_high_school_physics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_human_sexuality,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_professional_medicine,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_business_ethics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_electrical_engineering,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_anatomy,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_logical_fallacies,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_professional_accounting,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_high_school_european_history,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_us_foreign_policy,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_professional_law,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_stem,139126,false,Unknown,Unknown,false,3
mmlu_flan_n_shot_generative_humanities,139126,false,Unknown,Unknown,false,3
mmlu_flan_n_shot_generative_social_sciences,139126,false,Unknown,Unknown,false,3
mmlu_flan_n_shot_generative_other,139126,false,Unknown,Unknown,false,3
mmlu_flan_cot_fewshot_high_school_psychology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_management_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_sociology_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_zeroshot_formal_logic,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_high_school_statistics_generative,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_cot_fewshot_other,139126,false,Unknown,Unknown,false,3
mmlu_flan_cot_fewshot_social_sciences,139126,false,Unknown,Unknown,false,3
mmlu_flan_cot_fewshot_humanities,139126,false,Unknown,Unknown,false,3
mmlu_continuation_professional_medicine,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_generative_abstract_algebra,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_continuation_human_sexuality,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_generative_high_school_macroeconomics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_global_facts,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_loglikelihood_econometrics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_management,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_sociology,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_high_school_physics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_high_school_biology,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_college_chemistry,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_high_school_statistics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_cot_fewshot_stem,139126,false,Unknown,Unknown,false,3
mmlu_continuation_marketing,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_cot_zeroshot_humanities,139126,false,Unknown,Unknown,false,3
mmlu_flan_cot_zeroshot_other,139126,false,Unknown,Unknown,false,3
mmlu_flan_n_shot_loglikelihood_social_sciences,139126,false,Unknown,Unknown,false,3
mmlu_flan_n_shot_loglikelihood_humanities,139126,false,Unknown,Unknown,false,3
mmlu_flan_n_shot_generative_stem,139126,false,Unknown,Unknown,false,3
mmlu_flan_n_shot_loglikelihood_virology,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_prehistory,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_high_school_world_history,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_moral_scenarios,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_generative_college_computer_science,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_international_law,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_college_chemistry,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_human_aging,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_sociology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_econometrics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_continuation_abstract_algebra,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_astronomy,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_college_biology,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_college_physics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_jurisprudence,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_college_medicine,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_clinical_knowledge,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_medical_genetics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_generative_miscellaneous,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_continuation_global_facts,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_formal_logic,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_elementary_mathematics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_public_relations,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_high_school_computer_science,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_continuation_security_studies,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_generative_management,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_high_school_psychology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_high_school_government_and_politics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_high_school_world_history,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_elementary_mathematics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_formal_logic,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_loglikelihood_machine_learning,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_generative_conceptual_physics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_high_school_us_history,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_computer_security,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_loglikelihood_high_school_psychology,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_high_school_chemistry,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_college_mathematics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_high_school_geography,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_moral_disputes,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_high_school_mathematics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_high_school_microeconomics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_other,139126,false,Unknown,Unknown,false,3
mmlu_flan_n_shot_loglikelihood_computer_security,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_conceptual_physics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_college_computer_science,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_generative_high_school_microeconomics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_loglikelihood_high_school_us_history,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_human_aging,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_international_law,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_loglikelihood_high_school_government_and_politics,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_generative_machine_learning,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_high_school_mathematics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_loglikelihood_miscellaneous,139126,true,hails/mmlu_no_train,multiple_choice,false,1
mmlu_flan_n_shot_generative_high_school_geography,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_college_mathematics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_high_school_chemistry,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_moral_disputes,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_professional_psychology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_high_school_statistics,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_generative_college_biology,139126,true,hails/mmlu_no_train,generate_until,false,1
mmlu_flan_n_shot_loglikelihood_stem,139126,false,Unknown,Unknown,false,3
mmlu_continuation_professional_law,139126,true,hails/mmlu_no_train,multiple_choice,false,1
super_glue-copa-t5-prompt,129138,true,super_glue,generate_until,false,1
wic,129138,true,super_glue,multiple_choice,false,1
sglue_rte,129138,true,super_glue,multiple_choice,false,1
super_glue-rte-t5-prompt,129138,true,super_glue,generate_until,false,1
boolq,129138,true,super_glue,multiple_choice,false,1
super-glue-lm-eval-v1-seq2seq,129138,false,Unknown,Unknown,false,3
boolq-seq2seq,129138,true,super_glue,generate_until,false,1
record,129138,true,super_glue,multiple_choice,false,1
copa,129138,true,super_glue,multiple_choice,false,1
super_glue-wic-t5-prompt,129138,true,super_glue,generate_until,false,1
multirc,129138,true,super_glue,multiple_choice,false,1
super_glue-multirc-t5-prompt,129138,true,super_glue,generate_until,false,1
super_glue-record-t5-prompt,129138,true,super_glue,generate_until,false,1
wsc,129138,true,super_glue,multiple_choice,false,1
super_glue-wsc-t5-prompt,129138,true,super_glue,generate_until,false,1
super_glue-cb-t5-prompt,129138,true,super_glue,generate_until,false,1
super_glue-boolq-t5-prompt,129138,true,super_glue,generate_until,false,1
cb,129138,true,super_glue,multiple_choice,false,1
super-glue-t5-prompt,129138,false,Unknown,Unknown,false,3
super-glue-lm-eval-v1,129138,false,Unknown,Unknown,false,3
openbookqa,126345,true,openbookqa,multiple_choice,false,1
multimedqa,95637,true,Unknown,Unknown,false,1
multiple_choice,93232,false,Unknown,Unknown,false,3
commonsense_qa,88473,true,tau/commonsense_qa,multiple_choice,false,1
flan_held_out,81718,true,Unknown,Unknown,false,1
pythia,81645,true,Unknown,Unknown,false,1
lambada_openai_mt_fr,79640,true,EleutherAI/lambada_openai,loglikelihood,false,1
lambada,79640,false,Unknown,Unknown,false,3
lambada_standard,79640,true,lambada,loglikelihood,false,1
lambada_openai,79640,true,EleutherAI/lambada_openai,loglikelihood,false,1
lambada_openai_mt_en,79640,true,EleutherAI/lambada_openai,loglikelihood,false,1
lambada_multilingual,79640,false,Unknown,Unknown,false,3
lambada_openai_mt_es,79640,true,EleutherAI/lambada_openai,loglikelihood,false,1
lambada_openai_mt_de,79640,true,EleutherAI/lambada_openai,loglikelihood,false,1
lambada_cloze,79640,false,Unknown,Unknown,false,3
lambada_openai_cloze_yaml,79640,true,EleutherAI/lambada_openai,loglikelihood,false,1
lambada_standard_cloze_yaml,79640,true,lambada,loglikelihood,false,1
lambada_openai_mt_it,79640,true,EleutherAI/lambada_openai,loglikelihood,false,1
math_word_problems,70171,false,Unknown,Unknown,false,3
humaneval,64485,true,openai/openai_humaneval,generate_until,false,1
humaneval_64,64485,true,openai/openai_humaneval,generate_until,false,1
humaneval_instruct,64485,false,Unknown,Unknown,false,3
humaneval_plus,64485,true,openai/openai_humaneval,generate_until,false,1
humaneval_64_instruct,64485,false,Unknown,Unknown,false,3
longbench_passage_count,59032,false,Unknown,Unknown,false,3
longbench_repobench-p_e,59032,false,Unknown,Unknown,false,3
longbench_2wikimqa_e,59032,false,Unknown,Unknown,false,3
longbench,59032,false,Unknown,Unknown,false,3
longbench_e,59032,false,Unknown,Unknown,false,3
longbench_samsum,59032,false,Unknown,Unknown,false,3
longbench_lcc,59032,false,Unknown,Unknown,false,3
longbench_passage_retrieval_zh,59032,false,Unknown,Unknown,false,3
longbench_qasper_e,59032,false,Unknown,Unknown,false,3
longbench_samsum_e,59032,false,Unknown,Unknown,false,3
longbench_dureader,59032,false,Unknown,Unknown,false,3
longbench_repobench-p,59032,false,Unknown,Unknown,false,3
longbench_lcc_e,59032,false,Unknown,Unknown,false,3
longbench_passage_retrieval_en,59032,false,Unknown,Unknown,false,3
longbench_qmsum,59032,false,Unknown,Unknown,false,3
longbench_triviaqa_e,59032,false,Unknown,Unknown,false,3
longbench_multifieldqa_en,59032,false,Unknown,Unknown,false,3
longbench_gov_report,59032,false,Unknown,Unknown,false,3
longbench_triviaqa,59032,false,Unknown,Unknown,false,3
longbench_qasper,59032,false,Unknown,Unknown,false,3
longbench_hotpotqa_e,59032,false,Unknown,Unknown,false,3
longbench_passage_retrieval_en_e,59032,false,Unknown,Unknown,false,3
longbench_lsht,59032,false,Unknown,Unknown,false,3
longbench_trec,59032,false,Unknown,Unknown,false,3
longbench_musique,59032,false,Unknown,Unknown,false,3
longbench_hotpotqa,59032,false,Unknown,Unknown,false,3
longbench_multi_news,59032,false,Unknown,Unknown,false,3
longbench_passage_count_e,59032,false,Unknown,Unknown,false,3
longbench_vcsum,59032,false,Unknown,Unknown,false,3
longbench_2wikimqa,59032,false,Unknown,Unknown,false,3
longbench_multifieldqa_zh,59032,false,Unknown,Unknown,false,3
longbench_narrativeqa,59032,false,Unknown,Unknown,false,3
longbench_multi_news_e,59032,false,Unknown,Unknown,false,3
longbench_multifieldqa_en_e,59032,false,Unknown,Unknown,false,3
longbench_gov_report_e,59032,false,Unknown,Unknown,false,3
longbench_trec_e,59032,false,Unknown,Unknown,false,3
wsc273,50560,true,winograd_wsc,multiple_choice,false,1
mmlu_pro_llama_other,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_llama_health,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_llama_engineering,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_llama_philosophy,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_llama_law,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_llama_computer_science,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_llama_biology,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_llama_physics,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_llama_history,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_psychology,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_llama_chemistry,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_llama_math,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_law,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_llama_economics,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_philosophy,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_engineering,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_llama_psychology,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_other,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_business,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_physics,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_llama_business,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
leaderboard_mmlu_pro,50447,true,TIGER-Lab/MMLU-Pro,multiple_choice,false,1
mmlu_pro_llama,50447,true,Unknown,Unknown,true,1
mmlu_pro_computer_science,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
score_prompt_robustness_mmlu_pro,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
score_option_order_robustness_mmlu_pro,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
score_non_greedy_robustness_mmlu_pro,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_biology,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_health,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_history,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_chemistry,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_math,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
mmlu_pro_economics,50447,true,TIGER-Lab/MMLU-Pro,generate_until,true,1
score_robustness_mmlu_pro,50447,false,Unknown,Unknown,true,3
mmlu_pro,50447,true,Unknown,Unknown,true,1
gpqa_diamond_zeroshot,45154,true,Idavidrein/gpqa,multiple_choice,false,1
gpqa_main_n_shot,45154,true,Idavidrein/gpqa,multiple_choice,false,1
leaderboard_gpqa_diamond,45154,true,Idavidrein/gpqa,multiple_choice,false,1
leaderboard_gpqa_extended,45154,true,Idavidrein/gpqa,multiple_choice,false,1
gpqa_diamond_n_shot,45154,true,Idavidrein/gpqa,multiple_choice,false,1
leaderboard_gpqa,45154,true,Unknown,Unknown,false,1
gpqa_extended_zeroshot,45154,true,Idavidrein/gpqa,multiple_choice,false,1
gpqa_main_generative_n_shot,45154,true,Idavidrein/gpqa,generate_until,false,1
gpqa,45154,false,Unknown,Unknown,false,3
gpqa_main_zeroshot,45154,true,Idavidrein/gpqa,multiple_choice,false,1
gpqa_diamond_cot_n_shot,45154,true,Idavidrein/gpqa,generate_until,false,1
gpqa_extended_cot_n_shot,45154,true,Idavidrein/gpqa,generate_until,false,1
gpqa_extended_cot_zeroshot,45154,true,Idavidrein/gpqa,generate_until,false,1
gpqa_diamond_cot_zeroshot,45154,true,Idavidrein/gpqa,generate_until,false,1
gpqa_main_cot_zeroshot,45154,true,Idavidrein/gpqa,generate_until,false,1
gpqa_diamond_generative_n_shot,45154,true,Idavidrein/gpqa,generate_until,false,1
gpqa_extended_generative_n_shot,45154,true,Idavidrein/gpqa,generate_until,false,1
leaderboard_gpqa_main,45154,true,Idavidrein/gpqa,multiple_choice,false,1
gpqa_extended_n_shot,45154,true,Idavidrein/gpqa,multiple_choice,false,1
gpqa_main_cot_n_shot,45154,true,Idavidrein/gpqa,generate_until,false,1
xnli_tr,42975,true,xnli,multiple_choice,false,1
xnli_eu_mt_native,42975,false,Unknown,Unknown,false,3
xnli_th,42975,true,xnli,multiple_choice,false,1
xnli_es_spanish_bench,42975,true,xnli,multiple_choice,false,1
xnli_zh,42975,true,xnli,multiple_choice,false,1
french_bench_xnli,42975,true,xnli,multiple_choice,false,1
xnli_ca,42975,true,xnli,multiple_choice,false,1
xnli_eu_native,42975,true,xnli,multiple_choice,false,1
xnli_eu,42975,true,xnli,multiple_choice,false,1
xnli_ar,42975,true,xnli,multiple_choice,false,1
xnli_ru,42975,true,xnli,multiple_choice,false,1
xnli_eu_mt,42975,true,xnli,multiple_choice,false,1
xnli_ur,42975,true,xnli,multiple_choice,false,1
xnli_vi,42975,true,xnli,multiple_choice,false,1
xnli,42975,true,Unknown,Unknown,false,1
xnli_bg,42975,true,xnli,multiple_choice,false,1
xnli_es,42975,true,xnli,multiple_choice,false,1
xnli_sw,42975,true,xnli,multiple_choice,false,1
xnli_en,42975,true,xnli,multiple_choice,false,1
xnli_el,42975,true,xnli,multiple_choice,false,1
xnli_hi,42975,true,xnli,multiple_choice,false,1
xnli_gl,42975,true,xnli,multiple_choice,false,1
xnli_fr,42975,true,xnli,multiple_choice,false,1
xnli_de,42975,true,xnli,multiple_choice,false,1
mbpp_plus,39211,true,google-research-datasets/mbpp,generate_until,false,1
mbpp,39211,true,google-research-datasets/mbpp,generate_until,false,1
truthfulqa,37260,false,Unknown,Unknown,false,3
truthfulqa_mc2,37260,true,truthful_qa,multiple_choice,false,1
truthfulqa_mc1,37260,true,truthful_qa,multiple_choice,false,1
truthfulqa_gen,37260,true,truthful_qa,generate_until,false,1
wikitext,34971,true,EleutherAI/wikitext_document_level,loglikelihood_rolling,false,1
mmmu_val_public_health,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_agriculture,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_marketing,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_economics,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_literature,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_psychology,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_design,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_architecture_and_engineering,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_pharmacy,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_biology,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_physics,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_energy_and_power,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_music,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_art,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_math,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_computer_science,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_manage,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_mechanical_engineering,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_geography,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_chemistry,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_electronics,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_health_and_medicine,28760,true,Unknown,Unknown,false,1
mmmu_val_finance,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_art_and_design,28760,true,Unknown,Unknown,false,1
mmmu_val_science,28760,true,Unknown,Unknown,false,1
mmmu_val_business,28760,true,Unknown,Unknown,false,1
mmmu_val_humanities_and_social_science,28760,true,Unknown,Unknown,false,1
mmmu_val,28760,true,Unknown,Unknown,false,1
mmmu_val_tech_and_engineering,28760,true,Unknown,Unknown,false,1
mmmu_val_materials,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_art_theory,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_accounting,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_clinical_medicine,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_basic_medical_science,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_sociology,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_diagnostics_and_laboratory_medicine,28760,true,MMMU/MMMU,generate_until,false,1
mmmu_val_history,28760,true,MMMU/MMMU,generate_until,false,1
hendrycks_math_geometry,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
prompt_robustness_math_intermediate_algebra,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
non_greedy_robustness_math_counting_and_prob,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
hendrycks_math_precalc,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
hendrycks_math_prealgebra,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
hendrycks_math_num_theory,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
hendrycks_math_algebra,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
prompt_robustness_math_num_theory,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
non_greedy_robustness_math_precalc,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
hendrycks_math_intermediate_algebra,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
minerva_math_precalc,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
hendrycks_math_counting_and_prob,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
non_greedy_robustness_math_intermediate_algebra,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
minerva_math_prealgebra,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
non_greedy_robustness_math_algebra,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
prompt_robustness_math_prealgebra,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
minerva_math_num_theory,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
minerva_math_geometry,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
score_robustness_math,26854,true,Unknown,Unknown,true,1
prompt_robustness_math_precalc,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
prompt_robustness_math_geometry,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
score_non_greedy_robustness_math,26854,true,Unknown,Unknown,true,1
minerva_math_intermediate_algebra,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
non_greedy_robustness_math_prealgebra,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
score_prompt_robustness_math,26854,true,Unknown,Unknown,true,1
non_greedy_robustness_math_geometry,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
minerva_math_algebra,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
minerva_math_counting_and_prob,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
minerva_math,26854,true,Unknown,Unknown,false,1
non_greedy_robustness_math_num_theory,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
prompt_robustness_math_algebra,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
prompt_robustness_math_counting_and_prob,26854,true,EleutherAI/hendrycks_math,generate_until,false,1
hendrycks_math,26854,true,Unknown,Unknown,false,1
score_robustness,26610,true,Unknown,Unknown,true,1
piqa,26082,true,piqa,multiple_choice,false,1
leaderboard_math_algebra_hard,24634,true,DigitalLearningGmbH/MATH-lighteval,generate_until,false,1
leaderboard_math_hard,24634,true,Unknown,Unknown,false,1
leaderboard_math_intermediate_algebra_hard,24634,true,DigitalLearningGmbH/MATH-lighteval,generate_until,false,1
leaderboard_math_geometry_hard,24634,true,DigitalLearningGmbH/MATH-lighteval,generate_until,false,1
leaderboard_math_num_theory_hard,24634,true,DigitalLearningGmbH/MATH-lighteval,generate_until,false,1
leaderboard_math_precalculus_hard,24634,true,DigitalLearningGmbH/MATH-lighteval,generate_until,false,1
leaderboard_math_counting_and_prob_hard,24634,true,DigitalLearningGmbH/MATH-lighteval,generate_until,false,1
leaderboard_math_prealgebra_hard,24634,true,DigitalLearningGmbH/MATH-lighteval,generate_until,false,1
triviaqa,23929,true,trivia_qa,generate_until,false,1
leaderboard,23790,true,Unknown,Unknown,false,1
xwinograd_zh,22508,true,Muennighoff/xwinograd,multiple_choice,false,1
xwinograd_en,22508,true,Muennighoff/xwinograd,multiple_choice,false,1
xwinograd_pt,22508,true,Muennighoff/xwinograd,multiple_choice,false,1
xwinograd,22508,true,Unknown,Unknown,false,1
xwinograd_ru,22508,true,Muennighoff/xwinograd,multiple_choice,false,1
xwinograd_jp,22508,true,Muennighoff/xwinograd,multiple_choice,false,1
xwinograd_fr,22508,true,Muennighoff/xwinograd,multiple_choice,false,1
social_iqa,22501,true,social_i_qa,multiple_choice,false,1
ifeval,20768,true,google/IFEval,generate_until,true,1
sciq,18886,true,sciq,multiple_choice,false,1
wmdp_cyber,14596,true,cais/wmdp,multiple_choice,false,1
wmdp_chem,14596,true,cais/wmdp,multiple_choice,false,1
wmdp_bio,14596,true,cais/wmdp,multiple_choice,false,1
wmdp,14596,true,Unknown,Unknown,false,1
ceval-valid_college_physics,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_advanced_mathematics,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_ideological_and_moral_cultivation,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_college_programming,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_marxism,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_fire_engineer,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_probability_and_statistics,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_law,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_middle_school_history,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_physician,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_high_school_history,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_tax_accountant,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_middle_school_physics,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_discrete_mathematics,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_civil_servant,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_urban_and_rural_planner,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_middle_school_mathematics,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_logic,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_teacher_qualification,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_high_school_geography,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_computer_architecture,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_college_chemistry,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_high_school_chemistry,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_middle_school_biology,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_sports_science,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_college_economics,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_plant_protection,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_clinical_medicine,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_education_science,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_computer_network,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_middle_school_chemistry,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_professional_tour_guide,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_middle_school_geography,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_art_studies,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_chinese_language_and_literature,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_middle_school_politics,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_modern_chinese_history,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_metrology_engineer,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_electrical_engineer,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_high_school_mathematics,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_environmental_impact_assessment_engineer,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_accountant,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_legal_professional,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_high_school_politics,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_high_school_physics,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_veterinary_medicine,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid,13399,true,Unknown,Unknown,false,1
ceval-valid_mao_zedong_thought,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_high_school_chinese,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_basic_medicine,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_high_school_biology,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_operating_system,13399,true,ceval/ceval-exam,multiple_choice,false,1
ceval-valid_business_administration,13399,true,ceval/ceval-exam,multiple_choice,false,1
kmmlu_telecommunications_and_wireless_technology,12879,false,Unknown,Unknown,false,3
kmmlu_direct_ecology,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_fashion,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_nondestructive_testing,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_economics,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_stem,12879,true,Unknown,Unknown,false,1
kmmlu_electronics_engineering,12879,false,Unknown,Unknown,false,3
kmmlu_computer_science,12879,false,Unknown,Unknown,false,3
kmmlu_direct,12879,true,Unknown,Unknown,false,1
kmmlu_direct_applied_science,12879,true,Unknown,Unknown,false,1
kmmlu_direct_industrial_engineer,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_agricultural_sciences,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_chemistry,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_public_safety,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_social_welfare,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_aviation_engineering_and_maintenance,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_geomatics,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_political_science_and_sociology,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_machine_design_and_manufacturing,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_energy_management,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_math,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_electronics_engineering,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_patent,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_telecommunications_and_wireless_technology,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_other,12879,true,Unknown,Unknown,false,1
kmmlu_direct_humss,12879,true,Unknown,Unknown,false,1
kmmlu_direct_computer_science,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_other,12879,false,Unknown,Unknown,false,3
kmmlu_direct_gas_technology_and_engineering,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_accounting,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_law,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_interior_architecture_and_design,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_stem_tasks,12879,false,Unknown,Unknown,false,3
kmmlu_humss_tasks,12879,false,Unknown,Unknown,false,3
kmmlu_applied_science_tasks,12879,false,Unknown,Unknown,false,3
kmmlu_direct_stem_tasks,12879,false,Unknown,Unknown,false,3
kmmlu_direct_applied_science_tasks,12879,false,Unknown,Unknown,false,3
kmmlu_direct_other_tasks,12879,false,Unknown,Unknown,false,3
kmmlu_direct_humss_tasks,12879,false,Unknown,Unknown,false,3
kmmlu_other_tasks,12879,false,Unknown,Unknown,false,3
kmmlu_direct_marketing,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_humss,12879,false,Unknown,Unknown,false,3
kmmlu_direct_information_technology,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_construction,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_electrical_engineering,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_maritime_engineering,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_railway_and_automotive_engineering,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_gas_technology_and_engineering,12879,false,Unknown,Unknown,false,3
kmmlu_stem,12879,false,Unknown,Unknown,false,3
kmmlu_direct_biology,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_applied_science,12879,false,Unknown,Unknown,false,3
kmmlu_direct_chemical_engineering,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu,12879,false,Unknown,Unknown,false,3
kmmlu_direct_education,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_interior_architecture_and_design,12879,false,Unknown,Unknown,false,3
kmmlu_direct_materials_engineering,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_chemistry,12879,false,Unknown,Unknown,false,3
kmmlu_geomatics,12879,false,Unknown,Unknown,false,3
kmmlu_maritime_engineering,12879,false,Unknown,Unknown,false,3
kmmlu_direct_health,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_civil_engineering,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_criminal_law,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_direct_psychology,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_railway_and_automotive_engineering,12879,false,Unknown,Unknown,false,3
kmmlu_patent,12879,false,Unknown,Unknown,false,3
kmmlu_marketing,12879,false,Unknown,Unknown,false,3
kmmlu_education,12879,false,Unknown,Unknown,false,3
kmmlu_direct_food_processing,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_machine_design_and_manufacturing,12879,false,Unknown,Unknown,false,3
kmmlu_civil_engineering,12879,false,Unknown,Unknown,false,3
kmmlu_public_safety,12879,false,Unknown,Unknown,false,3
kmmlu_direct_mechanical_engineering,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_fashion,12879,false,Unknown,Unknown,false,3
kmmlu_health,12879,false,Unknown,Unknown,false,3
kmmlu_energy_management,12879,false,Unknown,Unknown,false,3
kmmlu_criminal_law,12879,false,Unknown,Unknown,false,3
kmmlu_biology,12879,false,Unknown,Unknown,false,3
kmmlu_ecology,12879,false,Unknown,Unknown,false,3
kmmlu_accounting,12879,false,Unknown,Unknown,false,3
kmmlu_direct_environmental_science,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_construction,12879,false,Unknown,Unknown,false,3
kmmlu_math,12879,false,Unknown,Unknown,false,3
kmmlu_direct_management,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_mechanical_engineering,12879,false,Unknown,Unknown,false,3
kmmlu_korean_history,12879,false,Unknown,Unknown,false,3
kmmlu_direct_korean_history,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_psychology,12879,false,Unknown,Unknown,false,3
kmmlu_direct_taxation,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_industrial_engineer,12879,false,Unknown,Unknown,false,3
kmmlu_nondestructive_testing,12879,false,Unknown,Unknown,false,3
kmmlu_political_science_and_sociology,12879,false,Unknown,Unknown,false,3
kmmlu_law,12879,false,Unknown,Unknown,false,3
kmmlu_aviation_engineering_and_maintenance,12879,false,Unknown,Unknown,false,3
kmmlu_information_technology,12879,false,Unknown,Unknown,false,3
kmmlu_food_processing,12879,false,Unknown,Unknown,false,3
kmmlu_social_welfare,12879,false,Unknown,Unknown,false,3
kmmlu_direct_real_estate,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_economics,12879,false,Unknown,Unknown,false,3
kmmlu_materials_engineering,12879,false,Unknown,Unknown,false,3
kmmlu_taxation,12879,false,Unknown,Unknown,false,3
kmmlu_refrigerating_machinery,12879,false,Unknown,Unknown,false,3
kmmlu_real_estate,12879,false,Unknown,Unknown,false,3
kmmlu_electrical_engineering,12879,false,Unknown,Unknown,false,3
kmmlu_chemical_engineering,12879,false,Unknown,Unknown,false,3
kmmlu_direct_refrigerating_machinery,12879,true,HAERAE-HUB/KMMLU,generate_until,false,1
kmmlu_environmental_science,12879,false,Unknown,Unknown,false,3
kmmlu_management,12879,false,Unknown,Unknown,false,3
kmmlu_agricultural_sciences,12879,false,Unknown,Unknown,false,3
belebele_ckb_Arab,11056,true,facebook/belebele,multiple_choice,false,1
belebele_hrv_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_fra_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_arz_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_afr_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_tir_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_ssw_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_nya_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_eus_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_bod_Tibt,11056,true,facebook/belebele,multiple_choice,false,1
belebele_hye_Armn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_zul_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_mya_Mymr,11056,true,facebook/belebele,multiple_choice,false,1
belebele_lao_Laoo,11056,true,facebook/belebele,multiple_choice,false,1
belebele_lug_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_som_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_uzn_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_srp_Cyrl,11056,true,facebook/belebele,multiple_choice,false,1
belebele_sot_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_sun_Latn,11056,true,facebook/belebele,multiple_choice,false,1
norbelebele_p0,11056,false,Unknown,Unknown,false,3
belebele_gaz_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_amh_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_swa_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_wol_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_zsm_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_nob_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_rus_Cyrl,11056,true,facebook/belebele,multiple_choice,false,1
belebele_lvs_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_khm_Khmr,11056,true,facebook/belebele,multiple_choice,false,1
belebele_als_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_ben_Beng,11056,true,facebook/belebele,multiple_choice,false,1
belebele_ben_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_ita_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_kea_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_por_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_jav_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_afr_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_ilo_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_sot_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_tsn_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_lin_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_tir_Ethi,11056,true,facebook/belebele,multiple_choice,false,1
belebele_ars_Arab,11056,true,facebook/belebele,multiple_choice,false,1
belebele_guj_Gujr,11056,true,facebook/belebele,multiple_choice,false,1
belebele_mal_Mlym,11056,true,facebook/belebele,multiple_choice,false,1
belebele_asm_Beng,11056,true,facebook/belebele,multiple_choice,false,1
belebele_fra_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_zho_Hans,11056,true,facebook/belebele,multiple_choice,false,1
belebele_spa_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_deu_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_kaz_Cyrl,11056,true,facebook/belebele,multiple_choice,false,1
belebele_hau_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_bul_Cyrl,11056,true,facebook/belebele,multiple_choice,false,1
belebele_arb_Arab,11056,true,facebook/belebele,multiple_choice,false,1
belebele_ron_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_kir_Cyrl,11056,true,facebook/belebele,multiple_choice,false,1
belebele_ces_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_ory_Orya,11056,true,facebook/belebele,multiple_choice,false,1
belebele_tam_Taml,11056,true,facebook/belebele,multiple_choice,false,1
belebele_som_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_mlt_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_est_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_nso_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_war_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_slk_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_apc_Arab,11056,true,facebook/belebele,multiple_choice,false,1
belebele_tha_Thai,11056,true,facebook/belebele,multiple_choice,false,1
belebele_ell_Grek,11056,true,facebook/belebele,multiple_choice,false,1
belebele_npi_Deva,11056,true,facebook/belebele,multiple_choice,false,1
belebele_fin_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_bam_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_xho_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_fuv_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_yor_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_ssw_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_por_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_nya_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_tsn_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_ary_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_sna_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_xho_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_tso_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_hau_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_zul_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_tso_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_afr_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_arz_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_fra_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_tir_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_yor_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_luo_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_fuv_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_eng_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_kac_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_lin_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_wol_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_sot_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_som_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_gaz_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_bam_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_xho_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_nya_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_swa_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_ibo_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_tsn_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_ary_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_sna_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_lug_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_kin_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_kea_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_arz_prompt_5,11056,false,Unknown,Unknown,false,3
belebele,11056,true,Unknown,Unknown,false,1
norbelebele_p1,11056,false,Unknown,Unknown,false,3
belebele_zul_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_luo_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_eng_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_afr_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_fra_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_ibo_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_tir_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_lug_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_kin_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_kea_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_wol_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_plt_prompt_5,11056,false,Unknown,Unknown,false,3
norbelebele,11056,false,Unknown,Unknown,false,3
belebele_glg_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_plt_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_tsn_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_amh_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_hau_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_por_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_ssw_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_ibo_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_nya_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_ary_prompt_5,11056,false,Unknown,Unknown,false,3
norbelebele_p3,11056,false,Unknown,Unknown,false,3
belebele_sna_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_tso_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_swa_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_hau_prompt_5,11056,false,Unknown,Unknown,false,3
norbelebele_p4,11056,false,Unknown,Unknown,false,3
norbelebele_p2,11056,false,Unknown,Unknown,false,3
belebele_ary_Arab,11056,true,facebook/belebele,multiple_choice,false,1
belebele_shn_Mymr,11056,true,facebook/belebele,multiple_choice,false,1
belebele_arb_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_hin_Deva,11056,true,facebook/belebele,multiple_choice,false,1
belebele_hau_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_nya_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_ibo_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_swa_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_pol_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_slv_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_azj_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_sin_Sinh,11056,true,facebook/belebele,multiple_choice,false,1
belebele_tso_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_isl_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_swh_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_ind_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_fuv_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_hat_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_xho_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_wol_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_luo_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_swa_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_tsn_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_lug_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_tir_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_fra_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_arz_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_afr_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_ssw_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_zul_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_ibo_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_tso_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_xho_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_sna_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_ary_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_tsn_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_nya_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_swe_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_gaz_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_kea_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_eng_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_yor_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_bam_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_amh_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_plt_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_kea_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_kin_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_prompt_2,11056,false,Unknown,Unknown,false,3
belebele_prompt_5,11056,false,Unknown,Unknown,false,3
belebele_tasks,11056,false,Unknown,Unknown,false,3
belebele_fuv_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_por_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_yor_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_fuv_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_pbt_Arab,11056,true,facebook/belebele,multiple_choice,false,1
belebele_bam_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_amh_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_urd_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_vie_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_tur_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_yor_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_luo_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_som_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_sot_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_sot_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_lin_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_luo_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_wol_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_eng_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_gaz_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_som_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_kin_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_lin_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_plt_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_heb_Hebr,11056,true,facebook/belebele,multiple_choice,false,1
belebele_kor_Hang,11056,true,facebook/belebele,multiple_choice,false,1
belebele_ceb_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_gaz_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_tgk_Cyrl,11056,true,facebook/belebele,multiple_choice,false,1
belebele_hin_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_nld_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_npi_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_ibo_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_mar_Deva,11056,true,facebook/belebele,multiple_choice,false,1
belebele_pan_Guru,11056,true,facebook/belebele,multiple_choice,false,1
belebele_eng_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_pes_Arab,11056,true,facebook/belebele,multiple_choice,false,1
belebele_mkd_Cyrl,11056,true,facebook/belebele,multiple_choice,false,1
belebele_tgl_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_amh_Ethi,11056,true,facebook/belebele,multiple_choice,false,1
belebele_jpn_Jpan,11056,true,facebook/belebele,multiple_choice,false,1
belebele_zul_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_ukr_Cyrl,11056,true,facebook/belebele,multiple_choice,false,1
belebele_kin_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_cat_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_tel_Telu,11056,true,facebook/belebele,multiple_choice,false,1
belebele_snd_Arab,11056,true,facebook/belebele,multiple_choice,false,1
belebele_kat_Geor,11056,true,facebook/belebele,multiple_choice,false,1
belebele_urd_Arab,11056,true,facebook/belebele,multiple_choice,false,1
belebele_khk_Cyrl,11056,true,facebook/belebele,multiple_choice,false,1
belebele_lit_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_sna_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_mri_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_luo_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_grn_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_lug_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_sin_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_plt_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_zho_Hant,11056,true,facebook/belebele,multiple_choice,false,1
belebele_wol_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_kin_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_tir_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_fra_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_arz_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_afr_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_ssw_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_zul_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_hau_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_tso_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_ssw_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_sna_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_ary_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_sot_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_som_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_gaz_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_eng_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_lug_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_lin_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_kea_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_xho_prompt_1,11056,false,Unknown,Unknown,false,3
belebele_plt_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_hun_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_dan_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_kan_Knda,11056,true,facebook/belebele,multiple_choice,false,1
belebele_acm_Arab,11056,true,facebook/belebele,multiple_choice,false,1
belebele_bam_Latn,11056,true,facebook/belebele,multiple_choice,false,1
belebele_arz_Arab,11056,true,facebook/belebele,multiple_choice,false,1
belebele_por_prompt_3,11056,false,Unknown,Unknown,false,3
belebele_bam_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_lin_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_fuv_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_yor_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_amh_prompt_4,11056,false,Unknown,Unknown,false,3
belebele_por_prompt_4,11056,false,Unknown,Unknown,false,3
xlsum_igbo_prompt_2,10940,false,Unknown,Unknown,false,3
xlsum_pidgin_prompt_1,10940,false,Unknown,Unknown,false,3
xlsum_igbo_prompt_3,10940,false,Unknown,Unknown,false,3
xlsum_swahili_prompt_2,10940,false,Unknown,Unknown,false,3
xlsum_oromo_prompt_3,10940,false,Unknown,Unknown,false,3
xlum,10940,false,Unknown,Unknown,false,3
xlsum_kirundi_prompt_2,10940,false,Unknown,Unknown,false,3
xlsum_hausa_prompt_2,10940,false,Unknown,Unknown,false,3
xlsum_arabic_prompt_2,10940,false,Unknown,Unknown,false,3
xlsum_oromo_prompt_2,10940,false,Unknown,Unknown,false,3
xlsum_tigrinya_prompt_2,10940,false,Unknown,Unknown,false,3
xlsum_amharic_prompt_2,10940,false,Unknown,Unknown,false,3
xlsum_pidgin_prompt_2,10940,false,Unknown,Unknown,false,3
xlsum_swahili_prompt_3,10940,false,Unknown,Unknown,false,3
xlsum_arabic_prompt_3,10940,false,Unknown,Unknown,false,3
xlsum_somali_prompt_2,10940,false,Unknown,Unknown,false,3
xlsum_telugu_prompt_2,10940,false,Unknown,Unknown,false,3
xlsum_yoruba_prompt_2,10940,false,Unknown,Unknown,false,3
xlsum_pidgin_prompt_3,10940,false,Unknown,Unknown,false,3
xlsum_hausa_prompt_3,10940,false,Unknown,Unknown,false,3
xlsum_kirundi_prompt_3,10940,false,Unknown,Unknown,false,3
xlsum_amharic_prompt_3,10940,false,Unknown,Unknown,false,3
xlsum_es,10940,true,csebuetnlp/xlsum,generate_until,false,1
xlsum_amharic_prompt_1,10940,false,Unknown,Unknown,false,3
xlsum_prompt_2,10940,false,Unknown,Unknown,false,3
xlsum_kirundi_prompt_1,10940,false,Unknown,Unknown,false,3
xlsum_arabic_prompt_1,10940,false,Unknown,Unknown,false,3
xlsum_hausa_prompt_1,10940,false,Unknown,Unknown,false,3
xlsum_tigrinya_prompt_3,10940,false,Unknown,Unknown,false,3
xlsum_yoruba_prompt_3,10940,false,Unknown,Unknown,false,3
xlsum_telugu_prompt_3,10940,false,Unknown,Unknown,false,3
xlsum_somali_prompt_3,10940,false,Unknown,Unknown,false,3
xlsum_oromo_prompt_1,10940,false,Unknown,Unknown,false,3
xlsum_igbo_prompt_1,10940,false,Unknown,Unknown,false,3
xlsum_telugu_prompt_1,10940,false,Unknown,Unknown,false,3
xlsum_tasks,10940,false,Unknown,Unknown,false,3
xlsum_yoruba_prompt_1,10940,false,Unknown,Unknown,false,3
xlsum_prompt_1,10940,false,Unknown,Unknown,false,3
xlsum_somali_prompt_1,10940,false,Unknown,Unknown,false,3
xlsum_tigrinya_prompt_1,10940,false,Unknown,Unknown,false,3
xlsum_swahili_prompt_1,10940,false,Unknown,Unknown,false,3
xlsum_prompt_3,10940,false,Unknown,Unknown,false,3
RC_tasks,10090,false,Unknown,Unknown,false,3
bbh_cot_zeroshot_logical_deduction_three_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_tracking_shuffled_objects_five_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_geometric_shapes,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_word_sorting,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_tracking_shuffled_objects_five_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_snarks,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_penguins_in_a_table,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_tracking_shuffled_objects_seven_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_word_sorting,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_geometric_shapes,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_logical_deduction_three_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_temporal_sequences,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_formal_fallacies,9725,true,lukaemon/bbh,generate_until,true,1
leaderboard_bbh_movie_recommendation,9725,true,SaylorTwift/bbh,multiple_choice,false,2
bbh_cot_zeroshot_boolean_expressions,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_multistep_arithmetic_two,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_multistep_arithmetic_two,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_logical_deduction_seven_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_causal_judgement,9725,true,lukaemon/bbh,generate_until,true,1
leaderboard_bbh_salient_translation_error_detection,9725,false,Unknown,Unknown,false,3
leaderboard_bbh_object_counting,9725,true,SaylorTwift/bbh,multiple_choice,false,2
bbh_zeroshot_movie_recommendation,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_reasoning_about_colored_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_logical_deduction_seven_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_boolean_expressions,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_object_counting,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_reasoning_about_colored_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_salient_translation_error_detection,9725,false,Unknown,Unknown,true,3
bbh_fewshot_penguins_in_a_table,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_snarks,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_movie_recommendation,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_formal_fallacies,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_disambiguation_qa,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_tracking_shuffled_objects_seven_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_tracking_shuffled_objects_three_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_sports_understanding,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_geometric_shapes,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_penguins_in_a_table,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_snarks,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_tracking_shuffled_objects_five_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_word_sorting,9725,true,lukaemon/bbh,generate_until,true,1
leaderboard_bbh,9725,true,Unknown,Unknown,false,2
bbh_cot_fewshot_object_counting,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_salient_translation_error_detection,9725,false,Unknown,Unknown,true,3
bbh_cot_zeroshot_logical_deduction_five_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_disambiguation_qa,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_reasoning_about_colored_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_logical_deduction_seven_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_boolean_expressions,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_multistep_arithmetic_two,9725,true,lukaemon/bbh,generate_until,true,1
leaderboard_bbh_snarks,9725,true,SaylorTwift/bbh,multiple_choice,false,2
leaderboard_bbh_geometric_shapes,9725,true,SaylorTwift/bbh,multiple_choice,false,2
leaderboard_bbh_logical_deduction_three_objects,9725,true,SaylorTwift/bbh,multiple_choice,false,2
leaderboard_bbh_boolean_expressions,9725,true,SaylorTwift/bbh,multiple_choice,false,2
leaderboard_bbh_logical_deduction_seven_objects,9725,true,SaylorTwift/bbh,multiple_choice,false,2
leaderboard_bbh_reasoning_about_colored_objects,9725,true,SaylorTwift/bbh,multiple_choice,false,2
leaderboard_bbh_disambiguation_qa,9725,true,SaylorTwift/bbh,multiple_choice,false,2
leaderboard_bbh_tracking_shuffled_objects_three_objects,9725,true,SaylorTwift/bbh,multiple_choice,false,2
bbh_zeroshot_logical_deduction_three_objects,9725,true,lukaemon/bbh,generate_until,true,1
leaderboard_bbh_formal_fallacies,9725,true,SaylorTwift/bbh,multiple_choice,false,2
bbh_cot_zeroshot_salient_translation_error_detection,9725,false,Unknown,Unknown,true,3
bbh_cot_zeroshot_object_counting,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_date_understanding,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_navigate,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_web_of_lies,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_dyck_languages,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_hyperbaton,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_ruin_names,9725,true,lukaemon/bbh,generate_until,true,1
leaderboard_bbh_penguins_in_a_table,9725,true,SaylorTwift/bbh,multiple_choice,false,2
bbh_zeroshot_penguins_in_a_table,9725,true,lukaemon/bbh,generate_until,true,1
leaderboard_bbh_tracking_shuffled_objects_five_objects,9725,true,SaylorTwift/bbh,multiple_choice,false,2
leaderboard_bbh_logical_deduction_five_objects,9725,true,SaylorTwift/bbh,multiple_choice,false,2
bbh_fewshot_logical_deduction_five_objects,9725,true,lukaemon/bbh,generate_until,true,1
leaderboard_bbh_ruin_names,9725,true,SaylorTwift/bbh,multiple_choice,false,2
bbh_fewshot_hyperbaton,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_dyck_languages,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_web_of_lies,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_tracking_shuffled_objects_five_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot,9725,true,Unknown,Unknown,true,1
bbh,9725,true,Unknown,Unknown,true,1
bbh_zeroshot_causal_judgement,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_sports_understanding,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_logical_deduction_five_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_ruin_names,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_hyperbaton,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_dyck_languages,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_sports_understanding,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_causal_judgement,9725,true,lukaemon/bbh,generate_until,true,1
leaderboard_bbh_web_of_lies,9725,true,SaylorTwift/bbh,multiple_choice,false,2
leaderboard_bbh_hyperbaton,9725,true,SaylorTwift/bbh,multiple_choice,false,2
bbh_fewshot_tracking_shuffled_objects_seven_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_ruin_names,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_formal_fallacies,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_movie_recommendation,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_geometric_shapes,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_logical_deduction_three_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_word_sorting,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_boolean_expressions,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_multistep_arithmetic_two,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_logical_deduction_seven_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_reasoning_about_colored_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_disambiguation_qa,9725,true,lukaemon/bbh,generate_until,true,1
leaderboard_bbh_temporal_sequences,9725,true,SaylorTwift/bbh,multiple_choice,false,2
bbh_cot_zeroshot,9725,true,Unknown,Unknown,true,1
bbh_zeroshot_snarks,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot,9725,true,Unknown,Unknown,true,1
bbh_fewshot,9725,true,Unknown,Unknown,true,1
bbh_cot_fewshot_tracking_shuffled_objects_three_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_formal_fallacies,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_movie_recommendation,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_tracking_shuffled_objects_seven_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_causal_judgement,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_sports_understanding,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_ruin_names,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_dyck_languages,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_hyperbaton,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_web_of_lies,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_temporal_sequences,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_navigate,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_date_understanding,9725,true,lukaemon/bbh,generate_until,true,1
leaderboard_bbh_date_understanding,9725,true,SaylorTwift/bbh,multiple_choice,false,2
bbh_cot_fewshot_disambiguation_qa,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_logical_deduction_five_objects,9725,true,lukaemon/bbh,generate_until,true,1
leaderboard_bbh_navigate,9725,true,SaylorTwift/bbh,multiple_choice,false,2
bbh_zeroshot_web_of_lies,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_zeroshot_tracking_shuffled_objects_three_objects,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_tracking_shuffled_objects_three_objects,9725,true,lukaemon/bbh,generate_until,true,1
leaderboard_bbh_causal_judgement,9725,true,SaylorTwift/bbh,multiple_choice,false,2
leaderboard_bbh_tracking_shuffled_objects_seven_objects,9725,true,SaylorTwift/bbh,multiple_choice,false,2
leaderboard_bbh_sports_understanding,9725,true,SaylorTwift/bbh,multiple_choice,false,2
bbh_fewshot_date_understanding,9725,true,lukaemon/bbh,generate_until,true,1
bbh_cot_fewshot_temporal_sequences,9725,true,lukaemon/bbh,generate_until,true,1
bbh_fewshot_navigate,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_date_understanding,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_temporal_sequences,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_object_counting,9725,true,lukaemon/bbh,generate_until,true,1
bbh_zeroshot_salient_translation_error_detection,9725,false,Unknown,Unknown,true,3
bbh_zeroshot_navigate,9725,true,lukaemon/bbh,generate_until,true,1
medmcqa,9508,true,medmcqa,multiple_choice,false,2
pile_10k,9340,true,NeelNanda/pile-10k,loglikelihood_rolling,false,2
mgsm_native_cot_th,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_native_cot_zh,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_en_cot_te,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_en_cot_sw,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_native_cot_es,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_native_cot_te,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_native_cot_sw,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_en_cot_bn,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_native_cot_fr,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_native_cot_en,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_en_cot_zh,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_en_cot_ja,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_direct_es_spanish_bench,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_en_cot_th,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_en_cot_es,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_en_cot_fr,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_en_cot_en,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_native_cot_ja,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_direct_es,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_native_cot_bn,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_en_cot_ru,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_direct_bn,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_direct_zh,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_en_cot_de,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_direct_en,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_direct_ru,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_direct_de,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_direct_fr,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_direct_ja,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_direct_th,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_native_cot_de,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_native_cot_ru,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_direct_sw,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_cot_native,9235,false,Unknown,Unknown,false,3
mgsm_direct,9235,false,Unknown,Unknown,false,3
ja_leaderboard_mgsm,9235,true,juletxara/mgsm,generate_until,false,2
mgsm_direct_te,9235,true,juletxara/mgsm,generate_until,false,2
cmmlu_electrical_engineering,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_high_school_geography,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_sociology,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_construction_project_management,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_business_ethics,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_virology,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_genetics,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_human_sexuality,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_chinese_literature,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_ancient_chinese,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_computer_security,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_nutrition,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_education,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_arts,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_college_engineering_hydrology,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_college_actuarial_science,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_high_school_physics,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_public_relations,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_college_medicine,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_world_history,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_marxist_theory,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_chinese_driving_rule,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_traditional_chinese_medicine,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_high_school_mathematics,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_elementary_mathematics,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_high_school_biology,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_food_science,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_chinese_foreign_policy,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_chinese_food_culture,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_global_facts,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu,9129,true,Unknown,Unknown,false,2
cmmlu_anatomy,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_elementary_information_and_technology,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_professional_psychology,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_high_school_chemistry,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_agronomy,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_jurisprudence,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_conceptual_physics,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_world_religions,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_ethnology,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_security_study,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_professional_accounting,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_college_mathematics,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_economics,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_sports_science,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_legal_and_moral_basis,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_astronomy,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_chinese_history,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_chinese_civil_service_exam,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_management,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_marketing,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_chinese_teacher_qualification,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_high_school_politics,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_elementary_commonsense,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_international_law,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_computer_science,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_journalism,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_college_medical_statistics,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_machine_learning,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_logical,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_modern_chinese,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_professional_law,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_professional_medicine,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_philosophy,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_elementary_chinese,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_college_law,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_college_education,9129,true,haonan-li/cmmlu,multiple_choice,false,2
cmmlu_clinical_knowledge,9129,true,haonan-li/cmmlu,multiple_choice,false,2
drop,9118,true,EleutherAI/drop,generate_until,false,2
race,8994,true,EleutherAI/race,multiple_choice,false,2
mathqa,8740,true,math_qa,multiple_choice,false,2
flores_bam_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_fon_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_yor_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_twi_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eu-ca,8480,true,facebook/flores,generate_until,false,2
flores_acq_Arab-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_kbp_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_ssw_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_gaz_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_pt-ca,8480,true,facebook/flores,generate_until,false,2
flores_eng_Latn-ssw_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-fra_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_ca-en,8480,true,facebook/flores,generate_until,false,2
flores_fr-ca,8480,true,facebook/flores,generate_until,false,2
flores_gl-ca,8480,true,facebook/flores,generate_until,false,2
flores_it-ca,8480,true,facebook/flores,generate_until,false,2
flores_ca-gl,8480,true,facebook/flores,generate_until,false,2
flores_ca-eu,8480,true,facebook/flores,generate_until,false,2
flores_ca-fr,8480,true,facebook/flores,generate_until,false,2
flores_ca-pt,8480,true,facebook/flores,generate_until,false,2
flores_eng_Latn-ace_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_en-ca,8480,true,facebook/flores,generate_until,false,2
flores_ca-de,8480,true,facebook/flores,generate_until,false,2
flores_es-ca,8480,true,facebook/flores,generate_until,false,2
flores_sun_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_zul_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_en-es,8480,true,facebook/flores,generate_until,false,2
flores_kab_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-wol_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eu-es,8480,true,facebook/flores,generate_until,false,2
flores_afr-eng_prompt_2,8480,false,Unknown,Unknown,false,3
flores_es-de,8480,true,facebook/flores,generate_until,false,2
flores_es-en,8480,true,facebook/flores,generate_until,false,2
flores_fr-es,8480,true,facebook/flores,generate_until,false,2
flores_es-fr,8480,true,facebook/flores,generate_until,false,2
flores_es-gl,8480,true,facebook/flores,generate_until,false,2
flores_es-eu,8480,true,facebook/flores,generate_until,false,2
flores_de-es,8480,true,facebook/flores,generate_until,false,2
flores_eng_Latn-cjk_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores,8480,false,Unknown,Unknown,false,3
african_flores_tasks,8480,false,Unknown,Unknown,false,3
flores_es-it,8480,true,facebook/flores,generate_until,false,2
flores_run_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_fr-gl,8480,true,facebook/flores,generate_until,false,2
flores_ca-es,8480,true,facebook/flores,generate_until,false,2
flores_eng_Latn-zul_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kea_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_kea_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_lin_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_bem_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_ace_Arab-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_nso_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_ban_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_knc_Arab-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_de-ca,8480,true,facebook/flores,generate_until,false,2
flores_eng_Latn-mos_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-taq_Tfng_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ssw_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_mos_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_dik_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_hau_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_kik_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_taq_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_wol_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_lug_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_xho_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-amh_Ethi_prompt_3,8480,false,Unknown,Unknown,false,3
flores_kam_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-fra_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-sot_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_ewe_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-nus_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tum_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-acq_Arab_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tsn_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-nso_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kam_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-som_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kik_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-arz_Arab_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kbp_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_gl-es,8480,true,facebook/flores,generate_until,false,2
flores_tir_Ethi-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-taq_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-dik_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-sna_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-aka_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ban_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ary_Arab_prompt_2,8480,false,Unknown,Unknown,false,3
flores_ca-it,8480,true,facebook/flores,generate_until,false,2
flores_eng_Latn-sun_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tir_Ethi_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-knc_Arab_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ban_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kin_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-run_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-lug_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-twi_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-nya_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-sag_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-aeb_Arab_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-bem_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-knc_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-dyu_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-umb_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kab_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ary_Arab_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-gaz_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ibo_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-fon_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_it-es,8480,true,facebook/flores,generate_until,false,2
flores_pt-fr,8480,true,facebook/flores,generate_until,false,2
flores_ca,8480,true,Unknown,Unknown,false,2
flores_pt,8480,true,Unknown,Unknown,false,2
flores_lua_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_en-pt,8480,true,facebook/flores,generate_until,false,2
flores_eng_Latn-dyu_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_arz_Arab-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_kam_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_xho_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_lug_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_wol_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_taq_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_kik_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_hau_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_dik_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_mos_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_tir_Ethi-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_ewe_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-taq_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-nya_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-fon_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ibo_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-amh_Ethi_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-umb_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kab_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-gaz_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-knc_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-bem_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_swh_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_aka_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-plt_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_ary_Arab-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_som_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_tso_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_kmb_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_umb_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_sot_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kin_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-run_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_dyu_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_pt-eu,8480,true,facebook/flores,generate_until,false,2
flores_pt-gl,8480,true,facebook/flores,generate_until,false,2
flores_de-pt,8480,true,facebook/flores,generate_until,false,2
flores_knc_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-lua_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tzm_Tfng_prompt_2,8480,false,Unknown,Unknown,false,3
flores_nya_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_taq_Tfng-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_tsn_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_tum_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_fra_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_ace_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_sna_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_sag_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-lin_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-arz_Arab_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-mos_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-aeb_Arab_prompt_2,8480,false,Unknown,Unknown,false,3
flores_es-pt,8480,true,facebook/flores,generate_until,false,2
flores_gl-de,8480,true,facebook/flores,generate_until,false,2
flores_eu-gl,8480,true,facebook/flores,generate_until,false,2
flores_fr-eu,8480,true,facebook/flores,generate_until,false,2
flores_eu-fr,8480,true,facebook/flores,generate_until,false,2
flores_it-eu,8480,true,facebook/flores,generate_until,false,2
flores_gl-eu,8480,true,facebook/flores,generate_until,false,2
flores_eng-afr_prompt_2,8480,false,Unknown,Unknown,false,3
flores_en-eu,8480,true,facebook/flores,generate_until,false,2
flores_eu-en,8480,true,facebook/flores,generate_until,false,2
flores_eu-de,8480,true,facebook/flores,generate_until,false,2
flores_de-eu,8480,true,facebook/flores,generate_until,false,2
flores_de-gl,8480,true,facebook/flores,generate_until,false,2
flores_gl-it,8480,true,facebook/flores,generate_until,false,2
flores_afr-eng_prompt_1,8480,false,Unknown,Unknown,false,3
flores_en-gl,8480,true,facebook/flores,generate_until,false,2
flores_gl-en,8480,true,facebook/flores,generate_until,false,2
flores_gl-fr,8480,true,facebook/flores,generate_until,false,2
flores_eu-it,8480,true,facebook/flores,generate_until,false,2
flores_it-gl,8480,true,facebook/flores,generate_until,false,2
flores_eng-afr,8480,false,Unknown,Unknown,false,3
flores_afr-eng,8480,false,Unknown,Unknown,false,3
flores_gl,8480,true,Unknown,Unknown,false,2
african_flores,8480,false,Unknown,Unknown,false,3
flores_eu,8480,true,Unknown,Unknown,false,2
flores_es,8480,true,Unknown,Unknown,false,2
flores_eng-afr_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng-afr_prompt_3,8480,false,Unknown,Unknown,false,3
flores_gl-pt,8480,true,facebook/flores,generate_until,false,2
flores_fr-pt,8480,true,facebook/flores,generate_until,false,2
flores_luo_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_kon_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_ibo_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_kin_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_amh_Ethi-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_afr_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_it-pt,8480,true,facebook/flores,generate_until,false,2
flores_pt-en,8480,true,facebook/flores,generate_until,false,2
flores_pt-es,8480,true,facebook/flores,generate_until,false,2
flores_pt-it,8480,true,facebook/flores,generate_until,false,2
flores_pt-de,8480,true,facebook/flores,generate_until,false,2
flores_eng_Latn-lug_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_afr-eng_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-sna_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_aeb_Arab-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_tzm_Tfng-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_fuv_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_plt_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-twi_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-sag_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eu-pt,8480,true,facebook/flores,generate_until,false,2
flores_cjk_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kik_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_nus_Latn-eng_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-bam_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kea_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-luo_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_hau_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-plt_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-lua_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tir_Ethi_prompt_1,8480,false,Unknown,Unknown,false,3
flores_kam_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kea_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tso_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-swh_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ace_Arab_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kon_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kmb_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-fuv_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ewe_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_plt_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_xho_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_tzm_Tfng-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_tso_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_kmb_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_umb_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_sot_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_dyu_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_arz_Arab-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_cjk_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_run_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_nus_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_kbp_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tzm_Tfng_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-zul_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-wol_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tum_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_taq_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_wol_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_lug_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-sot_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-amh_Ethi_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-fra_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ace_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ssw_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-afr_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-hau_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-nus_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-acq_Arab_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-xho_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tsn_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-nso_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kam_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-som_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kik_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-arz_Arab_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kbp_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-bam_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-lin_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-luo_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-yor_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_acq_Arab-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_twi_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_yor_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_swh_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_luo_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_lua_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_ibo_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_kin_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_amh_Ethi-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_afr_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_aeb_Arab-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_kon_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kmb_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kon_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-xho_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_taq_Tfng-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tso_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_tsn_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_tum_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_fra_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-fuv_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kbp_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_ace_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-lin_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-luo_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-yor_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-bam_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-nya_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_aka_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_knc_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_fon_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_nso_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_bam_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_gaz_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_zul_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-aka_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-dik_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-taq_Tfng_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-cjk_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_kea_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_lin_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_fuv_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_bem_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_ban_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_sag_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_knc_Arab-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_kab_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_ssw_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_sun_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_ace_Arab-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ace_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_som_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_nya_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ace_Arab_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-swh_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_sna_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_kik_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_ary_Arab-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_dik_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-afr_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_ace_Arab-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_bem_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_lin_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_kea_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_yor_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-cjk_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-dik_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-aka_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-sun_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-sot_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-knc_Arab_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-hau_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_ban_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-nus_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tum_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-acq_Arab_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tsn_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-nso_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kam_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-som_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-taq_Tfng_prompt_2,8480,false,Unknown,Unknown,false,3
flores_fuv_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_twi_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_kbp_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_nso_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_knc_Arab-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_afr_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-plt_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-yor_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_mos_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-fuv_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kmb_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kon_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ace_Arab_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-swh_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tso_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ewe_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tir_Ethi_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-lua_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-tzm_Tfng_prompt_3,8480,false,Unknown,Unknown,false,3
flores_kab_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-wol_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-xho_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-afr_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_plt_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_tzm_Tfng-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_fon_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_bam_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_gaz_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_zul_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_sun_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_ssw_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_aeb_Arab-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-zul_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_amh_Ethi-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-bem_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-hau_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-sun_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ban_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kin_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-run_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-lug_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-sna_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-twi_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-sag_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-aeb_Arab_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-mos_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-knc_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_taq_Tfng-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-dyu_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-umb_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-kab_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ary_Arab_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-gaz_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-fon_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ewe_Latn_prompt_2,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-taq_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_kin_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_ewe_Latn-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_tir_Ethi-eng_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-knc_Arab_prompt_3,8480,false,Unknown,Unknown,false,3
flores_eng_Latn-ibo_Latn_prompt_1,8480,false,Unknown,Unknown,false,3
flores_nus_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_ibo_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_luo_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_knc_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_sag_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_kon_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_sna_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_ace_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_fra_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_lua_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_acq_Arab-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_tsn_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_swh_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_tum_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_nya_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_umb_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_cjk_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_aka_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_dyu_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_sot_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_arz_Arab-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_kmb_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_tso_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_som_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_ary_Arab-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
flores_run_Latn-eng_Latn_prompt_3,8480,false,Unknown,Unknown,false,3
iwslt2017-en-ar,8409,true,iwslt2017,generate_until,false,2
iwslt2017,8409,false,Unknown,Unknown,false,3
iwslt2017-ar-en,8409,true,iwslt2017,generate_until,false,2
wmt14-en-fr,8302,true,wmt14,generate_until,false,2
wmt14-fr-en,8302,true,wmt14,generate_until,false,2
wmt14,8302,false,Unknown,Unknown,false,3
leaderboard_instruction_following,7498,true,Unknown,Unknown,false,2
leaderboard_ifeval,7498,true,wis-k/instruction-following-eval,generate_until,false,2
chartqa_llama_90,7308,false,Unknown,Unknown,false,3
chartqa_llama,7308,false,Unknown,Unknown,false,3
chartqa,7308,false,Unknown,Unknown,false,3
translation,7302,false,Unknown,Unknown,false,3
gpt3_translation_benchmarks,6934,false,Unknown,Unknown,false,3
bigbench_fantasy_reasoning_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_hinglish_toxicity_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_ruin_names_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_simple_arithmetic_multiple_targets_json_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_tense_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_international_phonetic_alphabet_transliterate_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_mult_data_wrangling_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_disfl_qa_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_scientific_press_release_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_cause_and_effect_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_sports_understanding_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_logical_args_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_hyperbaton_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_topical_chat_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_swahili_english_proverbs_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_metaphor_boolean_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_misconceptions_russian_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_suicide_risk_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_question_selection_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_sentence_ambiguity_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_emojis_emotion_prediction_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_sufficient_information_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_dyck_languages_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_parsinlu_qa_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_kanji_ascii_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_anachronisms_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_social_iqa_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_snarks_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_mnist_ascii_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_cryobiology_spanish_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_penguins_in_a_table_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_movie_dialog_same_or_different_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_physical_intuition_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_riddle_sense_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_undo_permutation_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_auto_debugging_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_movie_recommendation_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_entailed_polarity_hindi_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_conceptual_combinations_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_novel_concepts_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_disambiguation_qa_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_logic_grid_puzzle_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_persian_idioms_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_modified_arithmetic_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_implicatures_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_operators_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_code_line_description_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_gender_inclusive_sentences_german_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_intersect_geometry_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_cause_and_effect_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_cifar10_classification_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_hhh_alignment_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_hhh_alignment_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_discourse_marker_prediction_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_hyperbaton_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_analytic_entailment_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_odd_one_out_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_gre_reading_comprehension_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_simple_text_editing_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_tracking_shuffled_objects_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_timedial_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_physics_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_figure_of_speech_detection_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_polish_sequence_labeling_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_checkmate_in_one_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_language_identification_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_goal_step_wikihow_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_physics_questions_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_sentence_ambiguity_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_cryobiology_spanish_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_emoji_movie_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_fantasy_reasoning_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_entailed_polarity_hindi_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_conceptual_combinations_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_misconceptions_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_mathematical_induction_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_human_organs_senses_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_understanding_fables_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_international_phonetic_alphabet_nli_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_presuppositions_as_nli_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_metaphor_understanding_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_winowhy_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_analytic_entailment_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_physics_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_timedial_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_tracking_shuffled_objects_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_gre_reading_comprehension_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_odd_one_out_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_movie_recommendation_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_vitaminc_fact_verification_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_arithmetic_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_logical_deduction_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_language_identification_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_semantic_parsing_spider_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_ruin_names_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_cifar10_classification_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_identify_odd_metaphor_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_which_wiki_edit_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_goal_step_wikihow_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_simple_ethical_questions_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_sports_understanding_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_swahili_english_proverbs_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_logical_sequence_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_causal_judgment_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_checkmate_in_one_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_what_is_the_tao_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_riddle_sense_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_intersect_geometry_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_figure_of_speech_detection_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_logical_args_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_english_proverbs_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_social_support_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_navigate_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_evaluating_information_essentiality_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_known_unknowns_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_moral_permissibility_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_crass_ai_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_epistemic_reasoning_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_date_understanding_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_code_line_description_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_color_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_salient_translation_error_detection_multiple_choice,6895,false,Unknown,Unknown,false,3
bigbench_persian_idioms_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_logic_grid_puzzle_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_novel_concepts_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_key_value_maps_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_unit_interpretation_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_metaphor_boolean_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_authorship_verification_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_undo_permutation_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_discourse_marker_prediction_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_implicatures_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_entailed_polarity_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_implicit_relations_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_analogical_similarity_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_real_or_fake_text_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_temporal_sequences_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_english_russian_proverbs_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_unit_conversion_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_dark_humor_detection_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_empirical_judgments_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_common_morpheme_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_play_dialog_same_or_different_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_identify_odd_metaphor_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_english_russian_proverbs_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_which_wiki_edit_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_symbol_interpretation_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_date_understanding_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_unit_interpretation_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_epistemic_reasoning_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_minute_mysteries_qa_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_list_functions_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_temporal_sequences_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_common_morpheme_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_empirical_judgments_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_dark_humor_detection_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_unit_conversion_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_real_or_fake_text_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_authorship_verification_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_irony_identification_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_paragraph_segmentation_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_implicit_relations_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_penguins_in_a_table_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_mnist_ascii_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_chinese_remainder_theorem_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_formal_fallacies_syllogisms_negation_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_multiemo_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_geometric_shapes_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_nonsense_words_grammar_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_contextual_parametric_knowledge_conflicts_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_logical_fallacy_detection_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_fact_checker_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_hindu_knowledge_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_simp_turing_concept_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_elementary_math_qa_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_cs_algorithms_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_strategyqa_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_swedish_to_german_proverbs_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_similarities_abstraction_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_identify_math_theorems_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_entailed_polarity_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_play_dialog_same_or_different_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_color_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_kannada_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_moral_permissibility_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_known_unknowns_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_evaluating_information_essentiality_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_social_support_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_navigate_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_strange_stories_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_simple_arithmetic_json_subtasks_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_crass_ai_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_key_value_maps_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_phrase_relatedness_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_reasoning_about_colored_objects_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_abstract_narrative_understanding_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_misconceptions_russian_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_linguistics_puzzles_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_matrixshapes_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_emoji_movie_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_object_counting_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_word_unscrambling_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_cryptonite_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_emojis_emotion_prediction_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_salient_translation_error_detection_generate_until,6895,false,Unknown,Unknown,false,3
bigbench_codenames_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_social_iqa_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_physical_intuition_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_movie_dialog_same_or_different_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_linguistic_mappings_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_analogical_similarity_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_intent_recognition_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_bbq_lite_json_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_general_knowledge_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_what_is_the_tao_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_simple_arithmetic_json_multiple_choice_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_periodic_elements_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_crash_blossom_multiple_choice,6895,true,hails/bigbench,multiple_choice,false,2
bigbench_logical_sequence_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_unnatural_in_context_learning_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_contextual_parametric_knowledge_conflicts_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_nonsense_words_grammar_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_geometric_shapes_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_multiemo_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_rephrase_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_periodic_elements_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_symbol_interpretation_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_generate_until,6895,false,Unknown,Unknown,false,3
bigbench_multiple_choice_b,6895,false,Unknown,Unknown,false,3
bigbench_multiple_choice_a,6895,false,Unknown,Unknown,false,3
bigbench_causal_judgment_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_dyck_languages_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_identify_math_theorems_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_natural_instructions_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_international_phonetic_alphabet_nli_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_few_shot_nlg_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_crash_blossom_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_logical_fallacy_detection_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_strategyqa_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_winowhy_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_metaphor_understanding_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_presuppositions_as_nli_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_conlang_translation_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_simple_arithmetic_json_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_swedish_to_german_proverbs_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_cs_algorithms_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_fact_checker_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_auto_categorization_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_elementary_math_qa_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_hindu_knowledge_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_bbq_lite_json_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_formal_fallacies_syllogisms_negation_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_parsinlu_reading_comprehension_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_ascii_word_recognition_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_similarities_abstraction_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_understanding_fables_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_snarks_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_qa_wikidata_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_repeat_copy_logic_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_irony_identification_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_language_games_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_human_organs_senses_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_gem_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_anachronisms_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_phrase_relatedness_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_chess_state_tracking_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_question_selection_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_kanji_ascii_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_semantic_parsing_in_context_sparc_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_parsinlu_qa_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_word_sorting_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_intent_recognition_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_english_proverbs_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_general_knowledge_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_simple_ethical_questions_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_mathematical_induction_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_reasoning_about_colored_objects_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_vitaminc_fact_verification_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_arithmetic_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_bridging_anaphora_resolution_barqa_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_logical_deduction_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_misconceptions_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_suicide_risk_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_hinglish_toxicity_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_abstract_narrative_understanding_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_hindi_question_answering_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_kannada_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_strange_stories_generate_until,6895,true,hails/bigbench,generate_until,false,2
bigbench_disambiguation_qa_generate_until,6895,true,hails/bigbench,generate_until,false,2
spanish_bench,6825,true,Unknown,Unknown,false,2
basque_bench,6348,true,Unknown,Unknown,false,2
french_bench_extra,6283,false,Unknown,Unknown,false,3
wmt16-en-de,6250,true,wmt16,generate_until,false,2
wmt16-ro-en,6250,true,wmt16,generate_until,false,2
wmt16-en-ro,6250,true,wmt16,generate_until,false,2
wmt16-de-en,6250,true,wmt16,generate_until,false,2
wmt16,6250,false,Unknown,Unknown,false,3
wmt-ro-en-t5-prompt,6250,true,wmt16,generate_until,false,2
xstorycloze_en,6075,true,juletxara/xstory_cloze,multiple_choice,false,2
xstorycloze_sw,6075,true,juletxara/xstory_cloze,multiple_choice,false,2
xstorycloze_id,6075,true,juletxara/xstory_cloze,multiple_choice,false,2
xstorycloze_te,6075,true,juletxara/xstory_cloze,multiple_choice,false,2
xstorycloze_eu,6075,true,juletxara/xstory_cloze,multiple_choice,false,2
xstorycloze_hi,6075,true,juletxara/xstory_cloze,multiple_choice,false,2
xstorycloze_ar,6075,true,juletxara/xstory_cloze,multiple_choice,false,2
xstorycloze_my,6075,true,juletxara/xstory_cloze,multiple_choice,false,2
xstorycloze_zh,6075,true,juletxara/xstory_cloze,multiple_choice,false,2
xstorycloze_ru,6075,true,juletxara/xstory_cloze,multiple_choice,false,2
xstorycloze,6075,true,Unknown,Unknown,false,2
xstorycloze_es,6075,true,juletxara/xstory_cloze,multiple_choice,false,2
pubmedqa,5913,true,bigbio/pubmed_qa,multiple_choice,false,2
haerae_loan_word,5858,true,HAERAE-HUB/HAE_RAE_BENCH,multiple_choice,false,2
haerae_standard_nomenclature,5858,true,HAERAE-HUB/HAE_RAE_BENCH,multiple_choice,false,2
haerae_general_knowledge,5858,true,HAERAE-HUB/HAE_RAE_BENCH,multiple_choice,false,2
haerae_rare_word,5858,true,HAERAE-HUB/HAE_RAE_BENCH,multiple_choice,false,2
haerae_history,5858,true,HAERAE-HUB/HAE_RAE_BENCH,multiple_choice,false,2
haerae,5858,true,Unknown,Unknown,false,2
galician_bench,5723,true,Unknown,Unknown,false,2
anli_r2,5646,true,anli,multiple_choice,false,2
anli_r3,5646,true,anli,multiple_choice,false,2
anli_r1,5646,true,anli,multiple_choice,false,2
anli,5646,false,Unknown,Unknown,false,3
nq_open,5471,true,nq_open,generate_until,false,2
blimp_irregular_plural_subject_verb_agreement_1,5288,true,blimp,multiple_choice,false,2
blimp_transitive,5288,true,blimp,multiple_choice,false,2
blimp_wh_vs_that_with_gap,5288,true,blimp,multiple_choice,false,2
blimp_distractor_agreement_relational_noun,5288,true,blimp,multiple_choice,false,2
blimp_determiner_noun_agreement_irregular_1,5288,true,blimp,multiple_choice,false,2
blimp_drop_argument,5288,true,blimp,multiple_choice,false,2
blimp_irregular_past_participle_verbs,5288,true,blimp,multiple_choice,false,2
blimp_determiner_noun_agreement_with_adj_irregular_2,5288,true,blimp,multiple_choice,false,2
blimp_existential_there_subject_raising,5288,true,blimp,multiple_choice,false,3
blimp_superlative_quantifiers_1,5288,true,blimp,multiple_choice,false,3
blimp_determiner_noun_agreement_with_adj_2,5288,true,blimp,multiple_choice,false,3
blimp_principle_A_c_command,5288,true,blimp,multiple_choice,false,3
blimp_wh_questions_object_gap,5288,true,blimp,multiple_choice,false,3
blimp_coordinate_structure_constraint_complex_left_branch,5288,true,blimp,multiple_choice,false,3
blimp_principle_A_case_2,5288,true,blimp,multiple_choice,false,3
blimp_npi_present_2,5288,true,blimp,multiple_choice,false,3
blimp_principle_A_domain_2,5288,true,blimp,multiple_choice,false,3
blimp_animate_subject_trans,5288,true,blimp,multiple_choice,false,3
blimp_wh_questions_subject_gap_long_distance,5288,true,blimp,multiple_choice,false,3
blimp_sentential_negation_npi_licensor_present,5288,true,blimp,multiple_choice,false,3
blimp_wh_vs_that_no_gap,5288,true,blimp,multiple_choice,false,3
blimp_only_npi_scope,5288,true,blimp,multiple_choice,false,3
blimp_passive_2,5288,true,blimp,multiple_choice,false,3
blimp_distractor_agreement_relative_clause,5288,true,blimp,multiple_choice,false,3
blimp_tough_vs_raising_2,5288,true,blimp,multiple_choice,false,3
blimp_irregular_plural_subject_verb_agreement_2,5288,true,blimp,multiple_choice,false,3
blimp_regular_plural_subject_verb_agreement_2,5288,true,blimp,multiple_choice,false,3
blimp_coordinate_structure_constraint_object_extraction,5288,true,blimp,multiple_choice,false,3
blimp_only_npi_licensor_present,5288,true,blimp,multiple_choice,false,3
blimp_existential_there_quantifiers_1,5288,true,blimp,multiple_choice,false,3
blimp_sentential_subject_island,5288,true,blimp,multiple_choice,false,3
blimp_ellipsis_n_bar_2,5288,true,blimp,multiple_choice,false,3
blimp_complex_NP_island,5288,true,blimp,multiple_choice,false,3
blimp_tough_vs_raising_1,5288,true,blimp,multiple_choice,false,3
blimp_passive_1,5288,true,blimp,multiple_choice,false,3
blimp_principle_A_domain_1,5288,true,blimp,multiple_choice,false,3
blimp_adjunct_island,5288,true,blimp,multiple_choice,false,3
blimp_wh_vs_that_with_gap_long_distance,5288,true,blimp,multiple_choice,false,3
blimp_wh_vs_that_no_gap_long_distance,5288,true,blimp,multiple_choice,false,3
blimp_determiner_noun_agreement_with_adjective_1,5288,true,blimp,multiple_choice,false,3
blimp_existential_there_quantifiers_2,5288,true,blimp,multiple_choice,false,3
blimp_wh_island,5288,true,blimp,multiple_choice,false,3
blimp_determiner_noun_agreement_2,5288,true,blimp,multiple_choice,false,3
blimp_wh_questions_subject_gap,5288,true,blimp,multiple_choice,false,3
blimp,5288,true,Unknown,Unknown,false,3
blimp_matrix_question_npi_licensor_present,5288,true,blimp,multiple_choice,false,3
blimp_determiner_noun_agreement_irregular_2,5288,true,blimp,multiple_choice,false,3
blimp_irregular_past_participle_adjectives,5288,true,blimp,multiple_choice,false,3
blimp_left_branch_island_simple_question,5288,true,blimp,multiple_choice,false,3
blimp_regular_plural_subject_verb_agreement_1,5288,true,blimp,multiple_choice,false,3
blimp_principle_A_domain_3,5288,true,blimp,multiple_choice,false,3
blimp_expletive_it_object_raising,5288,true,blimp,multiple_choice,false,3
blimp_sentential_negation_npi_scope,5288,true,blimp,multiple_choice,false,3
blimp_anaphor_number_agreement,5288,true,blimp,multiple_choice,false,3
blimp_determiner_noun_agreement_1,5288,true,blimp,multiple_choice,false,3
blimp_inchoative,5288,true,blimp,multiple_choice,false,3
blimp_determiner_noun_agreement_with_adj_irregular_1,5288,true,blimp,multiple_choice,false,3
blimp_intransitive,5288,true,blimp,multiple_choice,false,3
blimp_existential_there_object_raising,5288,true,blimp,multiple_choice,false,3
blimp_superlative_quantifiers_2,5288,true,blimp,multiple_choice,false,3
blimp_principle_A_reconstruction,5288,true,blimp,multiple_choice,false,3
blimp_npi_present_1,5288,true,blimp,multiple_choice,false,3
blimp_principle_A_case_1,5288,true,blimp,multiple_choice,false,3
blimp_animate_subject_passive,5288,true,blimp,multiple_choice,false,3
blimp_anaphor_gender_agreement,5288,true,blimp,multiple_choice,false,3
blimp_causative,5288,true,blimp,multiple_choice,false,3
blimp_left_branch_island_echo_question,5288,true,blimp,multiple_choice,false,3
blimp_ellipsis_n_bar_1,5288,true,blimp,multiple_choice,false,3
leaderboard_musr,5285,true,Unknown,Unknown,false,3
leaderboard_musr_murder_mysteries,5285,true,TAUR-Lab/MuSR,multiple_choice,false,3
leaderboard_musr_team_allocation,5285,true,TAUR-Lab/MuSR,multiple_choice,false,3
leaderboard_musr_object_placements,5285,true,TAUR-Lab/MuSR,multiple_choice,false,3
portuguese_bench,5172,true,Unknown,Unknown,false,3
logiqa,4923,true,EleutherAI/logiqa,multiple_choice,false,3
medqa_4options,4920,true,GBaker/MedQA-USMLE-4-options-hf,multiple_choice,false,3
openai_mmlu_ara_prompt_1,4874,false,Unknown,Unknown,false,3
openai_mmlu_ara_prompt_4,4874,false,Unknown,Unknown,false,3
openai_mmlu_swa_prompt_4,4874,false,Unknown,Unknown,false,3
openai_mmlu_yor_prompt_4,4874,false,Unknown,Unknown,false,3
openai_mmlu_ara_prompt_3,4874,false,Unknown,Unknown,false,3
openai_mmlu_swa_prompt_3,4874,false,Unknown,Unknown,false,3
openai_mmlu_yor_prompt_3,4874,false,Unknown,Unknown,false,3
openai_mmlu,4874,false,Unknown,Unknown,false,3
openai_mmlu_ara_prompt_5,4874,false,Unknown,Unknown,false,3
openai_mmlu_ara_prompt_2,4874,false,Unknown,Unknown,false,3
openai_mmlu_yor_prompt_2,4874,false,Unknown,Unknown,false,3
openai_mmlu_swa_prompt_1,4874,false,Unknown,Unknown,false,3
openai_mmlu_swa_prompt_5,4874,false,Unknown,Unknown,false,3
openai_mmlu_swa_prompt_2,4874,false,Unknown,Unknown,false,3
openai_mmlu_yor_prompt_1,4874,false,Unknown,Unknown,false,3
openai_mmlu_prompt_1,4874,false,Unknown,Unknown,false,3
openai_mmlu_prompt_4,4874,false,Unknown,Unknown,false,3
openai_mmlu_prompt_2,4874,false,Unknown,Unknown,false,3
openai_mmlu_prompt_5,4874,false,Unknown,Unknown,false,3
openai_mmlu_tasks,4874,false,Unknown,Unknown,false,3
openai_mmlu_prompt_3,4874,false,Unknown,Unknown,false,3
openai_mmlu_yor_prompt_5,4874,false,Unknown,Unknown,false,3
afrobench_MT_tasks,4522,false,Unknown,Unknown,false,3
afrobench,4522,false,Unknown,Unknown,false,3
kobest_boolq,4306,true,skt/kobest_v1,multiple_choice,false,3
kobest_wic,4306,true,skt/kobest_v1,multiple_choice,false,3
kobest_hellaswag,4306,true,skt/kobest_v1,multiple_choice,false,3
kobest,4306,true,Unknown,Unknown,false,3
kobest_sentineg,4306,true,skt/kobest_v1,multiple_choice,false,3
kobest_copa,4306,true,skt/kobest_v1,multiple_choice,false,3
realtoxicityprompts,4024,true,allenai/real-toxicity-prompts,Unknown,false,3
tinyMMLU,3799,true,tinyBenchmarks/tinyMMLU,multiple_choice,false,3
arabicmmlu_biology_high_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_other_tasks,3548,false,Unknown,Unknown,false,3
arabicmmlu_economics_middle_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_islamic_studies_high_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_islamic_studies_primary_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_economics_university,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_math_primary_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_computer_science_middle_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_language,3548,true,Unknown,Unknown,false,3
arabicmmlu_history_high_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_general_knowledge,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_history_primary_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_islamic_studies_middle_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_arabic_language_grammar,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu,3548,true,Unknown,Unknown,false,3
arabicmmlu_social_science,3548,true,Unknown,Unknown,false,3
arabicmmlu_other,3548,true,Unknown,Unknown,false,3
arabicmmlu_stem,3548,true,Unknown,Unknown,false,3
arabicmmlu_arabic_language_primary_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_physics_high_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_arabic_language_middle_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_humanities,3548,true,Unknown,Unknown,false,3
arabicmmlu_law_professional,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_history_middle_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_language_tasks,3548,false,Unknown,Unknown,false,3
arabicmmlu_arabic_language_high_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_stem_tasks,3548,false,Unknown,Unknown,false,3
arabicmmlu_civics_middle_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_humanities_tasks,3548,false,Unknown,Unknown,false,3
arabicmmlu_geography_middle_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_management_university,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_general_knowledge_middle_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_civics_high_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_general_knowledge_primary_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_natural_science_primary_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_economics_high_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_driving_test,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_islamic_studies,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_social_science_primary_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_geography_high_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_geography_primary_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_political_science_university,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_computer_science_high_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_natural_science_middle_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_computer_science_primary_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_accounting_university,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_social_science_middle_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_philosophy_high_school,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_arabic_language_general,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
arabicmmlu_social_science_tasks,3548,false,Unknown,Unknown,false,3
arabicmmlu_computer_science_university,3548,true,MBZUAI/ArabicMMLU,multiple_choice,false,3
paws_zh,3530,true,paws-x,multiple_choice,false,3
paws_fr,3530,true,paws-x,multiple_choice,false,3
paws_ko,3530,true,paws-x,multiple_choice,false,3
paws_es,3530,true,paws-x,multiple_choice,false,3
paws_ja,3530,true,paws-x,multiple_choice,false,3
paws_en,3530,true,paws-x,multiple_choice,false,3
paws_es_spanish_bench,3530,true,paws-x,multiple_choice,false,3
pawsx,3530,true,Unknown,Unknown,false,3
paws_de,3530,true,paws-x,multiple_choice,false,3
m_mmlu_fr,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_zh,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_hy,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_nl,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_ta,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_ru,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_uk,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_de,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_it,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_hr,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_pt,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_ml,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_en,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_ne,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_sk,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_mr,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_bn,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu,3501,false,Unknown,Unknown,false,3
m_mmlu_sr,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_id,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_is,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_da,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_es,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_ar,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_nb,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_te,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_vi,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_sv,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_hu,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_ro,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_ca,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_hi,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_gu,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_eu,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
m_mmlu_kn,3501,true,alexandrainst/m_mmlu,multiple_choice,false,3
afrobench_lite,3392,false,Unknown,Unknown,false,3
catalan_bench,2934,true,Unknown,Unknown,false,3
french_bench,2842,false,Unknown,Unknown,false,3
coqa,2757,true,EleutherAI/coqa,generate_until,false,3
xcopa_tr,2593,true,xcopa,multiple_choice,false,3
xcopa_sw,2593,true,xcopa,multiple_choice,false,3
xcopa_id,2593,true,xcopa,multiple_choice,false,3
xcopa_th,2593,true,xcopa,multiple_choice,false,3
xcopa_qu,2593,true,xcopa,multiple_choice,false,3
xcopa_zh,2593,true,xcopa,multiple_choice,false,3
xcopa_ht,2593,true,xcopa,multiple_choice,false,3
xcopa_ta,2593,true,xcopa,multiple_choice,false,3
xcopa_it,2593,true,xcopa,multiple_choice,false,3
xcopa_et,2593,true,xcopa,multiple_choice,false,3
xcopa_vi,2593,true,xcopa,multiple_choice,false,3
xcopa,2593,true,Unknown,Unknown,false,3
agieval_sat_en_without_passage,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
agieval_gaokao_chemistry,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
agieval_gaokao_history,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
agieval_jec_qa_kd,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
agieval_logiqa_en,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
agieval_gaokao_english,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
agieval_gaokao_geography,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
non_greedy_robustness_agieval_lsat_ar,2529,true,hails/agieval-aqua-rat,generate_until,false,3
agieval_jec_qa_ca,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
agieval_lsat_ar,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
agieval_logiqa_zh,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
agieval_aqua_rat,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
agieval_sat_math,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
agieval_gaokao_biology,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
score_option_order_robustness_agieval,2529,true,Unknown,Unknown,true,1
score_robustness_agieval,2529,true,Unknown,Unknown,true,1
agieval_nous,2529,true,Unknown,Unknown,false,3
score_non_greedy_robustness_agieval,2529,true,Unknown,Unknown,true,1
prompt_robustness_agieval_sat_en,2529,true,hails/agieval-aqua-rat,generate_until,false,3
agieval_lsat_lr,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
agieval_gaokao_mathqa,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
agieval_gaokao_chinese,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
prompt_robustness_agieval_lsat_lr,2529,true,hails/agieval-aqua-rat,generate_until,false,3
agieval_sat_en,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
prompt_robustness_agieval_aqua_rat,2529,true,hails/agieval-aqua-rat,generate_until,false,3
prompt_robustness_agieval_lsat_ar,2529,true,hails/agieval-aqua-rat,generate_until,false,3
option_order_robustness_agieval_lsat_lr,2529,true,hails/agieval-aqua-rat,generate_until,false,3
option_order_robustness_agieval_sat_en,2529,true,hails/agieval-aqua-rat,generate_until,false,3
prompt_robustness_agieval_lsat_rc,2529,true,hails/agieval-aqua-rat,generate_until,false,3
prompt_robustness_agieval_logiqa_en,2529,true,hails/agieval-aqua-rat,generate_until,false,3
non_greedy_robustness_agieval_lsat_rc,2529,true,hails/agieval-aqua-rat,generate_until,false,3
option_order_robustness_agieval_sat_math,2529,true,hails/agieval-aqua-rat,generate_until,false,3
agieval_lsat_rc,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
non_greedy_robustness_agieval_sat_math,2529,true,hails/agieval-aqua-rat,generate_until,false,3
prompt_robustness_agieval_sat_math,2529,true,hails/agieval-aqua-rat,generate_until,false,3
option_order_robustness_agieval_aqua_rat,2529,true,hails/agieval-aqua-rat,generate_until,false,3
option_order_robustness_agieval_lsat_rc,2529,true,hails/agieval-aqua-rat,generate_until,false,3
non_greedy_robustness_agieval_sat_en,2529,true,hails/agieval-aqua-rat,generate_until,false,3
option_order_robustness_agieval_logiqa_en,2529,true,hails/agieval-aqua-rat,generate_until,false,3
non_greedy_robustness_agieval_logiqa_en,2529,true,hails/agieval-aqua-rat,generate_until,false,3
score_prompt_robustness_agieval,2529,true,Unknown,Unknown,true,1
non_greedy_robustness_agieval_aqua_rat,2529,true,hails/agieval-aqua-rat,generate_until,false,3
non_greedy_robustness_agieval_lsat_lr,2529,true,hails/agieval-aqua-rat,generate_until,false,3
option_order_robustness_agieval_lsat_ar,2529,true,hails/agieval-aqua-rat,generate_until,false,3
agieval_gaokao_physics,2529,true,hails/agieval-aqua-rat,multiple_choice,false,3
hrm8k_gsm8k_en,2449,true,HAERAE-HUB/HRM8K,generate_until,false,3
hrm8k_en,2449,true,Unknown,Unknown,false,3
hrm8k_ksm_en,2449,true,HAERAE-HUB/HRM8K,generate_until,false,3
hrm8k_ksm,2449,true,HAERAE-HUB/HRM8K,generate_until,false,3
hrm8k_mmmlu,2449,true,HAERAE-HUB/HRM8K,generate_until,false,3
hrm8k_omni_math_en,2449,true,HAERAE-HUB/HRM8K,generate_until,false,3
hrm8k_math,2449,true,HAERAE-HUB/HRM8K,generate_until,false,3
hrm8k_gsm8k,2449,true,HAERAE-HUB/HRM8K,generate_until,false,3
hrm8k_omni_math,2449,true,HAERAE-HUB/HRM8K,generate_until,false,3
hrm8k_mmmlu_en,2449,true,HAERAE-HUB/HRM8K,generate_until,false,3
hrm8k_math_en,2449,true,HAERAE-HUB/HRM8K,generate_until,false,3
hrm8k,2449,true,Unknown,Unknown,false,3
qasper,2418,false,Unknown,Unknown,false,3
qasper_freeform,2418,true,allenai/qasper,generate_until,false,3
qasper_bool,2418,true,allenai/qasper,multiple_choice,false,3
agieval_en,2399,true,Unknown,Unknown,false,3
agieval,2395,true,Unknown,Unknown,false,3
agieval_cn,2391,true,Unknown,Unknown,false,3
arithmetic_4da,2377,true,EleutherAI/arithmetic,loglikelihood,false,3
arithmetic_4ds,2377,true,EleutherAI/arithmetic,loglikelihood,false,3
arithmetic_2da,2377,true,EleutherAI/arithmetic,loglikelihood,false,3
arithmetic_1dc,2377,true,EleutherAI/arithmetic,loglikelihood,false,3
arithmetic_3ds,2377,true,EleutherAI/arithmetic,loglikelihood,false,3
arithmetic_2dm,2377,true,EleutherAI/arithmetic,loglikelihood,false,3
arithmetic_5ds,2377,true,EleutherAI/arithmetic,loglikelihood,false,3
arithmetic_3da,2377,true,EleutherAI/arithmetic,loglikelihood,false,3
arithmetic_2ds,2377,true,EleutherAI/arithmetic,loglikelihood,false,3
arithmetic_5da,2377,true,EleutherAI/arithmetic,loglikelihood,false,3
arithmetic,2377,false,Unknown,Unknown,false,3
xquad_tr,2299,true,xquad,generate_until,false,3
xquad_ar,2299,true,xquad,generate_until,false,3
xquad_vi,2299,true,xquad,generate_until,false,3
xquad_es,2299,true,xquad,generate_until,false,3
xquad_el,2299,true,xquad,generate_until,false,3
xquad_th,2299,true,xquad,generate_until,false,3
xquad_zh,2299,true,xquad,generate_until,false,3
xquad_de,2299,true,xquad,generate_until,false,3
xquad_en,2299,true,xquad,generate_until,false,3
xquad_hi,2299,true,xquad,generate_until,false,3
xquad,2299,false,Unknown,Unknown,false,3
xquad_ro,2299,true,xquad,generate_until,false,3
xquad_ru,2299,true,xquad,generate_until,false,3
mmlusr_question_only_global_facts,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_human_sexuality,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_professional_accounting,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_marketing,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_professional_law,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_nutrition,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_business_ethics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_college_computer_science,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_us_history,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_prehistory,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_high_school_geography,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_management,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_international_law,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_public_relations,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_high_school_chemistry,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_business_ethics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_elementary_mathematics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_microeconomics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_sociology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_logical_fallacies,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_psychology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_computer_science,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_formal_logic,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_global_facts,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_college_biology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_college_medicine,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_college_physics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_psychology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_prehistory,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_college_medicine,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_miscellaneous,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_professional_accounting,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_us_history,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_logical_fallacies,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_statistics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_european_history,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_machine_learning,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_anatomy,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_formal_logic,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_computer_security,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_human_aging,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_mathematics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_professional_psychology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_moral_scenarios,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_us_foreign_policy,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_machine_learning,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_anatomy,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_business_ethics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_marketing,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_elementary_mathematics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_moral_scenarios,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_nutrition,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_medical_genetics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_biology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_world_history,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_physics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_security_studies,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_geography,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_astronomy,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_macroeconomics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_public_relations,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_virology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_computer_security,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_chemistry,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_college_chemistry,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_professional_psychology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_sociology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_international_law,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_government_and_politics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_us_foreign_policy,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_abstract_algebra,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_clinical_knowledge,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_government_and_politics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_abstract_algebra,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_moral_disputes,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_international_law,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_mathematics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_macroeconomics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_medical_genetics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_conceptual_physics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_world_history,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_college_physics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_college_biology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_jurisprudence,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_virology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_college_mathematics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_professional_medicine,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_philosophy,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_human_sexuality,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_abstract_algebra,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_moral_disputes,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_econometrics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_professional_medicine,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_electrical_engineering,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_professional_psychology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_other_tasks,2298,false,Unknown,Unknown,false,3
mmlusr_answer_only_machine_learning,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_college_mathematics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_global_facts,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_clinical_knowledge,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_virology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_college_computer_science,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_high_school_psychology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_high_school_world_history,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_professional_law,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_miscellaneous,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_logical_fallacies,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_high_school_government_and_politics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_social_sciences_tasks,2298,false,Unknown,Unknown,false,3
mmlusr_answer_only_high_school_computer_science,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_stem_tasks,2298,false,Unknown,Unknown,false,3
mmlusr_question_and_answer_other_tasks,2298,false,Unknown,Unknown,false,3
mmlusr_question_and_answer_humanities_tasks,2298,false,Unknown,Unknown,false,3
mmlusr_question_and_answer_social_sciences_tasks,2298,false,Unknown,Unknown,false,3
mmlusr_answer_only_sociology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_moral_scenarios,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_jurisprudence,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_high_school_mathematics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_college_physics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_jurisprudence,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_prehistory,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_high_school_us_history,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_medical_genetics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_college_biology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_computer_security,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_us_foreign_policy,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_anatomy,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_high_school_microeconomics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_management,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_college_chemistry,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_electrical_engineering,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_econometrics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_conceptual_physics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_high_school_physics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_moral_disputes,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_high_school_biology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_professional_accounting,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_astronomy,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_college_medicine,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_high_school_european_history,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_world_religions,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_formal_logic,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_philosophy,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_statistics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_college_chemistry,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_clinical_knowledge,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_econometrics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_computer_science,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_security_studies,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_elementary_mathematics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_world_religions,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_chemistry,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_european_history,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_college_computer_science,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_miscellaneous,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_biology,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_geography,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_high_school_physics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_conceptual_physics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_high_school_microeconomics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_human_aging,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_management,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_human_aging,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_philosophy,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_public_relations,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_college_mathematics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_social_sciences_tasks,2298,false,Unknown,Unknown,false,3
mmlusr_answer_only_marketing,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_stem_tasks,2298,false,Unknown,Unknown,false,3
mmlusr_answer_only_high_school_macroeconomics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_high_school_statistics,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr,2298,true,Unknown,Unknown,false,3
mmlusr_question_only,2298,true,Unknown,Unknown,false,3
mmlusr_answer_only,2298,true,Unknown,Unknown,false,3
mmlusr_answer_only_other_tasks,2298,false,Unknown,Unknown,false,3
mmlusr_answer_only_stem_tasks,2298,false,Unknown,Unknown,false,3
mmlusr_answer_only_nutrition,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_humanities_tasks,2298,false,Unknown,Unknown,false,3
mmlusr_question_only_humanities_tasks,2298,false,Unknown,Unknown,false,3
mmlusr_answer_only_professional_medicine,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_answer_only_security_studies,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_human_sexuality,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_only_electrical_engineering,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_astronomy,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_world_religions,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlusr_question_and_answer_professional_law,2298,true,NiniCat/MMLU-SR,multiple_choice,false,3
mmlu_prox_bn_computer_science,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn_business,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn_biology,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_philosophy,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn_physics,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_health,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn_math,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_computer_science,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_history,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn_economics,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn_other,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_psychology,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn_history,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn_law,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_engineering,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn_health,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_philosophy,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_economics,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_other,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_chemistry,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_biology,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_physics,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_law,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_history,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_business,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_biology,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_math,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_law,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_economics,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_psychology,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_law,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_philosophy,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_economics,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_computer_science,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_chemistry,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_other,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_philosophy,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_biology,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_law,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_health,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_physics,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_psychology,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_business,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_history,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_engineering,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr_math,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_chemistry,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi_business,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_other,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_other,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_math,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_business,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_physics,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_law,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_physics,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_chemistry,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_chemistry,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_other,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_engineering,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_history,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_economics,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_biology,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_law,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_philosophy,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_psychology,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_engineering,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_computer_science,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_history,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn_philosophy,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_economics,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_economics,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_math,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_philosophy,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_psychology,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_chemistry,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_business,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_psychology,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_computer_science,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_health,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_business,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_physics,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_economics,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_health,2213,false,Unknown,Unknown,false,3
mmlu_prox_es_biology,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_engineering,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_health,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_biology,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_psychology,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_philosophy,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_computer_science,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_health,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_other,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_computer_science,2213,false,Unknown,Unknown,false,3
mmlu_prox_en_math,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_history,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_physics,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_history,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_physics,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_other,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_physics,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_math,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_business,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_psychology,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_philosophy,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_history,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_engineering,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_biology,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_chemistry,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_economics,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_chemistry,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_law,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn_chemistry,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_engineering,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_business,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_biology,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_physics,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_history,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_biology,2213,false,Unknown,Unknown,false,3
mmlu_prox_fr,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_business,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_other,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_philosophy,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_math,2213,false,Unknown,Unknown,false,3
mmlu_prox_de_engineering,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_health,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_psychology,2213,false,Unknown,Unknown,false,3
mmlu_prox_hi,2213,false,Unknown,Unknown,false,3
mmlu_prox_de,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_other,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_economics,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn_engineering,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_computer_science,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_law,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_history,2213,false,Unknown,Unknown,false,3
mmlu_prox_zh_math,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_math,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_business,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_law,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_psychology,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_economics,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_health,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_business,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_philosophy,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_other,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_economics,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_health,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_math,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_math,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_engineering,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_psychology,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_philosophy,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_biology,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_chemistry,2213,false,Unknown,Unknown,false,3
mmlu_prox_bn_psychology,2213,false,Unknown,Unknown,false,3
mmlu_prox_ar_computer_science,2213,false,Unknown,Unknown,false,3
mmlu_prox_th_law,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_chemistry,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_health,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_biology,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_physics,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_engineering,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_business,2213,false,Unknown,Unknown,false,3
mmlu_prox_ko_computer_science,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_health,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_computer_science,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_physics,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_chemistry,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_health,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_math,2213,false,Unknown,Unknown,false,3
mmlu_prox_pt_engineering,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_psychology,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_law,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_physics,2213,false,Unknown,Unknown,false,3
mmlu_prox_es,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_biology,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_economics,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_history,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_chemistry,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_philosophy,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_other,2213,false,Unknown,Unknown,false,3
mmlu_prox_th,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_engineering,2213,false,Unknown,Unknown,false,3
mmlu_prox_sw_computer_science,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_computer_science,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_history,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_law,2213,false,Unknown,Unknown,false,3
mmlu_prox_ja_other,2213,false,Unknown,Unknown,false,3
mmlu_prox_en,2213,false,Unknown,Unknown,false,3
gsm_plus_mini,2097,true,qintongli/GSM-Plus,generate_until,false,3
gsm_plus,2097,true,qintongli/GSM-Plus,generate_until,false,3
afrobench_mmlu_tasks,2022,false,Unknown,Unknown,false,3
tmlu_CAP_earth_science,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_GSAT_chinese,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_GSAT_civics,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_basic_traditional_chinese_medicine,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_AST_biology,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_nutritionist,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_CAP_chinese,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_clinical_traditional_chinese_medicine,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_humanities_tasks,2013,false,Unknown,Unknown,false,3
tmlu_tour_guide,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_teacher_qualification,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu,2013,true,Unknown,Unknown,false,3
tmlu_stem_tasks,2013,false,Unknown,Unknown,false,3
tmlu_other_tasks,2013,false,Unknown,Unknown,false,3
tmlu_taiwan_specific_tasks,2013,false,Unknown,Unknown,false,3
tmlu_social_sciences_tasks,2013,false,Unknown,Unknown,false,3
tmlu_AST_history,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_CAP_biology,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_clinical_psychologist,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_AST_geography,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_CAP_civics,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_GSAT_earth_science,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_AST_chinese,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_taiwan_tourist_resources,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_CAP_history,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_CAP_geography,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_CAP_chemistry,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_GSAT_biology,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_AST_civics,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_lawyer_qualification,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_GSAT_chemistry,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_driving_rule,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_GSAT_history,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_accountant,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_tour_leader,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_AST_chemistry,2013,true,miulab/tmlu,multiple_choice,false,3
tmlu_GSAT_geography,2013,true,miulab/tmlu,multiple_choice,false,3
gsm8k_platinum_cot_self_consistency,2002,false,Unknown,Unknown,false,3
gsm8k_platinum_cot_llama,2002,false,Unknown,Unknown,false,3
gsm8k_platinum_cot_zeroshot,2002,false,Unknown,Unknown,false,3
gsm8k_platinum_cot,2002,false,Unknown,Unknown,false,3
gsm8k_platinum,2002,false,Unknown,Unknown,false,3
pile_ubuntu-irc,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_philpapers,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_bookcorpus2,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_uspto,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_stackexchange,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_pubmed-abstracts,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_arxiv,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_wikipedia,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_nih-exporter,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_freelaw,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_hackernews,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_pile-cc,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_github,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_books3,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_dm-mathematics,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_youtubesubtitles,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_openwebtext2,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_opensubtitles,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_pubmed-central,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_europarl,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_enron,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
pile_gutenberg,1990,true,EleutherAI/pile,loglikelihood_rolling,false,3
darijammlu_natural_science,1912,false,Unknown,Unknown,false,3
darijammlu_high_school_psychology,1912,false,Unknown,Unknown,false,3
darijammlu_high_school_world_history,1912,false,Unknown,Unknown,false,3
darijammlu_philosophy,1912,false,Unknown,Unknown,false,3
darijammlu_world_religions,1912,false,Unknown,Unknown,false,3
darijammlu_arabic_language,1912,false,Unknown,Unknown,false,3
darijammlu_arabic_language_(general),1912,false,Unknown,Unknown,false,3
darijammlu_computer_science,1912,false,Unknown,Unknown,false,3
darijammlu_professional_law,1912,false,Unknown,Unknown,false,3
darijammlu_jurisprudence,1912,false,Unknown,Unknown,false,3
darijammlu_management,1912,false,Unknown,Unknown,false,3
darijammlu_high_school_european_history,1912,false,Unknown,Unknown,false,3
darijammlu_high_school_government_and_politics,1912,false,Unknown,Unknown,false,3
darijammlu_economics,1912,false,Unknown,Unknown,false,3
darijammlu_high_school_statistics,1912,false,Unknown,Unknown,false,3
darijammlu_logical_fallacies,1912,false,Unknown,Unknown,false,3
darijammlu_math,1912,false,Unknown,Unknown,false,3
darijammlu_security_studies,1912,false,Unknown,Unknown,false,3
darijammlu_sociology,1912,false,Unknown,Unknown,false,3
darijammlu_management_ar,1912,false,Unknown,Unknown,false,3
darijammlu_ar_mmlu_tasks,1912,false,Unknown,Unknown,false,3
darijammlu_mmlu_tasks,1912,false,Unknown,Unknown,false,3
darijammlu_driving_test,1912,false,Unknown,Unknown,false,3
darijammlu_philosophy_ar,1912,false,Unknown,Unknown,false,3
darijammlu_public_relations,1912,false,Unknown,Unknown,false,3
darijammlu_accounting,1912,false,Unknown,Unknown,false,3
darijammlu_physics,1912,false,Unknown,Unknown,false,3
darijammlu_islamic_studies,1912,false,Unknown,Unknown,false,3
darijammlu_arabic_language_(grammar),1912,false,Unknown,Unknown,false,3
darijammlu_law,1912,false,Unknown,Unknown,false,3
darijammlu_international_law,1912,false,Unknown,Unknown,false,3
darijammlu_history,1912,false,Unknown,Unknown,false,3
darijammlu_political_science,1912,false,Unknown,Unknown,false,3
darijammlu_biology,1912,false,Unknown,Unknown,false,3
darijammlu_human_aging,1912,false,Unknown,Unknown,false,3
darijammlu_high_school_geography,1912,false,Unknown,Unknown,false,3
darijammlu_moral_disputes,1912,false,Unknown,Unknown,false,3
darijammlu_civics,1912,false,Unknown,Unknown,false,3
darijammlu_global_facts,1912,false,Unknown,Unknown,false,3
darijammlu_general_knowledge,1912,false,Unknown,Unknown,false,3
darijammlu_nutrition,1912,false,Unknown,Unknown,false,3
darijammlu_moral_scenarios,1912,false,Unknown,Unknown,false,3
darijammlu_marketing,1912,false,Unknown,Unknown,false,3
darijammlu_social_science,1912,false,Unknown,Unknown,false,3
darijammlu_mmlu,1912,false,Unknown,Unknown,false,3
darijammlu_ar_mmlu,1912,false,Unknown,Unknown,false,3
darijammlu,1912,false,Unknown,Unknown,false,3
darijammlu_professional_psychology,1912,false,Unknown,Unknown,false,3
darijammlu_geography,1912,false,Unknown,Unknown,false,3
tinyHellaswag,1871,true,tinyBenchmarks/tinyHellaswag,multiple_choice,false,3
tinyBenchmarks,1739,true,Unknown,Unknown,false,3
t0_eval,1693,true,Unknown,Unknown,false,3
swag,1691,true,swag,multiple_choice,false,3
qa4mre_2013,1650,true,qa4mre,multiple_choice,false,3
qa4mre,1650,false,Unknown,Unknown,false,3
qa4mre_2012,1650,true,qa4mre,multiple_choice,false,3
qa4mre_2011,1650,true,qa4mre,multiple_choice,false,3
tatoeba_nob_eng,1587,false,Unknown,Unknown,false,3
tatoeba_eng_nno_p2,1587,false,Unknown,Unknown,false,3
tatoeba_nob_eng_p3,1587,false,Unknown,Unknown,false,3
tatoeba_nob_eng_p2,1587,false,Unknown,Unknown,false,3
tatoeba_eng_nno_p1,1587,false,Unknown,Unknown,false,3
tatoeba_eng_nno_p0,1587,false,Unknown,Unknown,false,3
tatoeba_nno_eng_p2,1587,false,Unknown,Unknown,false,3
tatoeba_nno_eng_p3,1587,false,Unknown,Unknown,false,3
tatoeba_eng_nob,1587,false,Unknown,Unknown,false,3
tatoeba_eng_nno_p3,1587,false,Unknown,Unknown,false,3
tatoeba_eng_nno,1587,false,Unknown,Unknown,false,3
tatoeba_eng_nob_p0,1587,false,Unknown,Unknown,false,3
tatoeba_nno_eng,1587,false,Unknown,Unknown,false,3
tatoeba_nob_eng_p1,1587,false,Unknown,Unknown,false,3
tatoeba_eng_nob_p1,1587,false,Unknown,Unknown,false,3
tatoeba_nob_eng_p0,1587,false,Unknown,Unknown,false,3
tatoeba_eng_nob_p2,1587,false,Unknown,Unknown,false,3
tatoeba_nno_eng_p1,1587,false,Unknown,Unknown,false,3
tatoeba_nno_eng_p0,1587,false,Unknown,Unknown,false,3
tatoeba_eng_nob_p3,1587,false,Unknown,Unknown,false,3
kmmlu_direct_hard_law,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_chemistry,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_machine_design_and_manufacturing,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_refrigerating_machinery,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_biology,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_ecology,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_social_welfare,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_psychology,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_railway_and_automotive_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_real_estate,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_education,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_food_processing,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_energy_management,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_chemical_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_direct_hard_telecommunications_and_wireless_technology,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_taxation,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_economics,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_geomatics,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_electronics_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_fashion,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_political_science_and_sociology,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_environmental_science,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_computer_science,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_materials_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_electrical_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_management,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_math,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_korean_history,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_civil_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_construction,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_maritime_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_public_safety,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_psychology,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_information_technology,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_health,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_patent,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_chemical_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_interior_architecture_and_design,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_gas_technology_and_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_marketing,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_aviation_engineering_and_maintenance,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_agricultural_sciences,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_industrial_engineer,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_cot_hard_chemical_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_environmental_science,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_political_science_and_sociology,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_materials_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_psychology,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_maritime_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_information_technology,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_public_safety,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_machine_design_and_manufacturing,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_cot_hard_construction,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_ecology,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_cot_hard_food_processing,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_biology,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_cot_hard_marketing,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_economics,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_accounting,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_health,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_construction,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_korean_history,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_electrical_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_direct_hard_criminal_law,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_civil_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_agricultural_sciences,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_aviation_engineering_and_maintenance,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_real_estate,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_cot_hard_agricultural_sciences,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_maritime_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_electronics_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_fashion,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_cot_hard_education,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_taxation,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_cot_hard_chemistry,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_math,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_fashion,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_industrial_engineer,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_gas_technology_and_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_direct_hard_nondestructive_testing,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_mechanical_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_nondestructive_testing,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_biology,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_gas_technology_and_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_civil_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_law,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_computer_science,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_chemistry,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_geomatics,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_accounting,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_math,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_stem_tasks,1578,false,Unknown,Unknown,false,3
kmmlu_hard_humss_tasks,1578,false,Unknown,Unknown,false,3
kmmlu_hard_other_tasks,1578,false,Unknown,Unknown,false,3
kmmlu_hard_applied_science_tasks,1578,false,Unknown,Unknown,false,3
kmmlu_cot_hard_humss_tasks,1578,false,Unknown,Unknown,false,3
kmmlu_cot_hard_stem_tasks,1578,false,Unknown,Unknown,false,3
kmmlu_cot_hard_other_tasks,1578,false,Unknown,Unknown,false,3
kmmlu_cot_hard_applied_science_tasks,1578,false,Unknown,Unknown,false,3
kmmlu_direct_hard_other,1578,true,Unknown,Unknown,false,3
kmmlu_cot_hard_public_safety,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_ecology,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_applied_science,1578,true,Unknown,Unknown,false,3
kmmlu_cot_hard_environmental_science,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_marketing,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_education,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_criminal_law,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_management,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_telecommunications_and_wireless_technology,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_direct_hard_industrial_engineer,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_mechanical_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_cot_hard_geomatics,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_aviation_engineering_and_maintenance,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_political_science_and_sociology,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_management,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_korean_history,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_computer_science,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_materials_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_electronics_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_criminal_law,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_interior_architecture_and_design,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_humss,1578,true,Unknown,Unknown,false,3
kmmlu_hard_refrigerating_machinery,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_direct_hard_stem,1578,true,Unknown,Unknown,false,3
kmmlu_cot_hard_accounting,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_railway_and_automotive_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_economics,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_cot_hard_real_estate,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_energy_management,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_electrical_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_humss_tasks,1578,false,Unknown,Unknown,false,3
kmmlu_cot_hard_telecommunications_and_wireless_technology,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_law,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_hard_nondestructive_testing,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_energy_management,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_food_processing,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_social_welfare,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_patent,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_hard_interior_architecture_and_design,1578,true,HAERAE-HUB/KMMLU-HARD,multiple_choice,false,3
kmmlu_cot_hard_taxation,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard,1578,true,Unknown,Unknown,false,3
kmmlu_cot_hard_patent,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_information_technology,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_mechanical_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_refrigerating_machinery,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_stem,1578,true,Unknown,Unknown,false,3
kmmlu_hard_humss,1578,true,Unknown,Unknown,false,3
kmmlu_hard,1578,true,Unknown,Unknown,false,3
kmmlu_hard_other,1578,true,Unknown,Unknown,false,3
kmmlu_hard_applied_science,1578,true,Unknown,Unknown,false,3
kmmlu_cot_hard_humss,1578,true,Unknown,Unknown,false,3
kmmlu_cot_hard_other,1578,true,Unknown,Unknown,false,3
kmmlu_cot_hard_applied_science,1578,true,Unknown,Unknown,false,3
kmmlu_cot_hard,1578,true,Unknown,Unknown,false,3
kmmlu_hard_stem,1578,true,Unknown,Unknown,false,3
kmmlu_direct_hard_stem_tasks,1578,false,Unknown,Unknown,false,3
kmmlu_direct_hard_applied_science_tasks,1578,false,Unknown,Unknown,false,3
kmmlu_cot_hard_social_welfare,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_health,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_cot_hard_machine_design_and_manufacturing,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
kmmlu_direct_hard_other_tasks,1578,false,Unknown,Unknown,false,3
kmmlu_cot_hard_railway_and_automotive_engineering,1578,true,HAERAE-HUB/KMMLU-HARD,generate_until,false,3
afrimmlu_direct_swa_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_xho_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_orm_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_sna_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_ibo_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_tasks_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_wol_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_tasks,1547,false,Unknown,Unknown,false,3
afrimmlu_tasks_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_hau_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_tasks_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_amh_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_yor_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_twi_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_lin_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_eng_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_sna_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_twi_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_yor_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_hau_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_wol_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_tasks_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_tasks_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_hau_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_orm_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu-irokobench,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_lin_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_ewe_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_amh_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_zul_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_fra_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_yor_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_xho_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_fra_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_zul_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_amh_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_ewe_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_lug_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_kin_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_eng_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_sot_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_lin_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_lug_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_kin_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_orm_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_sot_prompt_1,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_sna_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_twi_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_zul_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_sot_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_wol_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_swa_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_swa_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_sna_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_orm_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_lug_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_hau_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_xho_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_swa_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_wol_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_fra_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_xho_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_amh_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_lug_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_ewe_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_eng_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_sot_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_lin_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_twi_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_yor_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_ibo_prompt_5,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_kin_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_eng_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_ibo_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_hau_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_orm_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_kin_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_lug_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_ewe_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_zul_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_fra_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_wol_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_swa_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_ibo_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_yor_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_sna_prompt_2,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_xho_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_ibo_prompt_3,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_ewe_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_amh_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_zul_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_fra_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_kin_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_eng_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_sot_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_lin_prompt_4,1547,false,Unknown,Unknown,false,3
afrimmlu_direct_twi_prompt_4,1547,false,Unknown,Unknown,false,3
storycloze_2018,1526,true,story_cloze,multiple_choice,false,3
storycloze,1526,false,Unknown,Unknown,false,3
storycloze_2016,1526,true,story_cloze,multiple_choice,false,3
kormedmcqa,1494,true,Unknown,Unknown,false,3
kormedmcqa_pharm,1494,true,sean0042/KorMedMCQA,generate_until,false,3
kormedmcqa_nurse,1494,true,sean0042/KorMedMCQA,generate_until,false,3
kormedmcqa_dentist,1494,true,sean0042/KorMedMCQA,generate_until,false,3
kormedmcqa_doctor,1494,true,sean0042/KorMedMCQA,generate_until,false,3
arabic_leaderboard_arabic_mt_openbook_qa,1471,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_arc_easy,1471,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_piqa,1471,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_copa,1471,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_sciq,1471,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_hellaswag,1471,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_toxigen,1471,true,Unknown,Unknown,false,3
arabic_mt_copa,1471,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Translated,multiple_choice,false,3
arabic_mt_piqa,1471,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Translated,multiple_choice,false,3
arabic_mt_arc_easy,1471,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Translated,multiple_choice,false,3
arabic_mt_openbook_qa,1471,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Translated,multiple_choice,false,3
arabic_mt_race,1471,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Translated,multiple_choice,false,3
arabic_mt_hellaswag,1471,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Translated,multiple_choice,false,3
arabic_mt_toxigen,1471,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Translated,multiple_choice,false,3
arabic_mt_sciq,1471,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Translated,multiple_choice,false,3
arabic_mt_arc_challenge,1471,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Translated,multiple_choice,false,3
arabic_mt_boolq,1471,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Translated,multiple_choice,false,3
arabic_leaderboard_arabic_mt_mmlu,1471,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_boolq,1471,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_arc_challenge,1471,true,Unknown,Unknown,false,3
arabic_mt_mmlu,1471,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Translated,multiple_choice,false,3
arabic_leaderboard_arabic_mt_race,1471,true,Unknown,Unknown,false,3
arabic_leaderboard_complete,1444,true,Unknown,Unknown,false,3
advanced_ai_risk_human-self-awareness-good-text-model,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-corrigible-less-HHH,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-coordinate-other-ais,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-coordinate-other-versions,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-self-awareness-text-model,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-self-awareness-training-web-gpt,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-one-box-tendency,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-power-seeking-inclination,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-wealth-seeking-inclination,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-wealth-seeking-inclination,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-corrigible-neutral-HHH,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-wealth-seeking-inclination,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-corrigible-less-HHH,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-self-awareness-web-gpt,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-power-seeking-inclination,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-corrigible-more-HHH,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-corrigible-less-HHH,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-survival-instinct,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-self-awareness-text-model,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-self-awareness-general-ai,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-coordinate-other-versions,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-one-box-tendency,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-coordinate-itself,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-coordinate-other-ais,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-myopic-reward,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-corrigible-neutral-HHH,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-coordinate-other-versions,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-self-awareness-general-ai,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-coordinate-itself,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-self-awareness-training-architecture,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-self-awareness-training-nn-architecture,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-corrigible-more-HHH,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-self-awareness-training-web-gpt,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-survival-instinct,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-power-seeking-inclination,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-self-awareness-general-ai,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-coordinate-itself,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-myopic-reward,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-self-awareness-good-text-model,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-self-awareness-training-architecture,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_fewshot-myopic-reward,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-corrigible-more-HHH,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-survival-instinct,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-one-box-tendency,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-self-awareness-training-architecture,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-coordinate-other-ais,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk,1412,false,Unknown,Unknown,false,3
advanced_ai_risk_fewshot-corrigible-neutral-HHH,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_human-self-awareness-text-model,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
advanced_ai_risk_lm-self-awareness-good-text-model,1412,true,EleutherAI/advanced_ai_risk,multiple_choice,false,3
arabic_leaderboard_acva_United_Arab_Emirates,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Islam_Education,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Morocco,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Clothing,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Lebanon,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromGreece,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Palestine,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Syria,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromRome,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Music,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Bahrain,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Calligraphy,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Saudi_Arabia,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Astronomy,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Art,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Libya,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromPersia,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Islam_branches_and_schools,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_daily_life,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Algeria,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Ancient_Egypt,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Somalia,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_entertainment,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Islamic_law_system,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Food,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Ornament,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_communication,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Yemen,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromIslam,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Mesopotamia_civilization,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Philosophy,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Sudan,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Comoros,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Geography,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Jordan,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Iraq,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Egypt_modern,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Math,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Wedding,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arab_Empire,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Architecture,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Culture,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Qatar,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Literature,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Mauritania,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromByzantium,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_computer_and_phone,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Ceremony,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Yemen_light,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Physics_and_Chemistry,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromChina,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Medicine,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_History,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Oman,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva,1398,true,Unknown,Unknown,false,3
arabic_leaderboard_acva_Arabic_Language_Origin,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Kuwait,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromAncientEgypt,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Tunisia,1398,true,OALL/ACVA,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Funeral,1398,true,OALL/ACVA,multiple_choice,false,3
masakhanews_ibo_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_swa_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_fra_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_eng_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_tir_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_amh_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_lug_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_orm_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_eng_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_pcm_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_fra_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_pcm_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_xho_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_ibo_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_lug_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_fra_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_tir_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_amh_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_lug_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_som_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_run_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_eng_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_yor_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_hau_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_som_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_lin_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_xho_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_run_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_sna_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_som_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_yor_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_lin_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews,1380,false,Unknown,Unknown,false,3
masakhanews_orm_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_eng_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_sna_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_xho_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_xho_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_run_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_hau_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_run_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_sna_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_yor_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_yor_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_pcm_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_swa_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_ibo_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_hau_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_pcm_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_orm_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_sna_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_amh_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_lug_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_amh_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_tir_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_som_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_run_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_eng_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_som_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_swa_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_lin_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_orm_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_ibo_prompt_4,1380,false,Unknown,Unknown,false,3
masakhanews_lin_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_hau_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_xho_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_sna_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_orm_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_pcm_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_ibo_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_tasks,1380,false,Unknown,Unknown,false,3
masakhanews_fra_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_tir_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_swa_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_amh_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_lug_prompt_1,1380,false,Unknown,Unknown,false,3
masakhanews_swa_prompt_3,1380,false,Unknown,Unknown,false,3
masakhanews_hau_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_lin_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_yor_prompt_2,1380,false,Unknown,Unknown,false,3
masakhanews_tir_prompt_5,1380,false,Unknown,Unknown,false,3
masakhanews_fra_prompt_5,1380,false,Unknown,Unknown,false,3
tinyArc,1354,true,tinyBenchmarks/tinyAI2_arc,multiple_choice,false,3
tinyGSM8k,1344,true,tinyBenchmarks/tinyGSM8k,generate_until,false,3
japanese_leaderboard,1330,true,Unknown,Unknown,false,3
arabic_leaderboard_alghafa_multiple_choice_rating_sentiment_task,1326,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Native,multiple_choice,false,3
arabic_leaderboard_alghafa_meta_ar_msa,1326,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Native,multiple_choice,false,3
arabic_leaderboard_alghafa_multiple_choice_sentiment_task,1326,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Native,multiple_choice,false,3
arabic_leaderboard_alghafa_mcq_exams_test_ar,1326,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Native,multiple_choice,false,3
arabic_leaderboard_alghafa_meta_ar_dialects,1326,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Native,multiple_choice,false,3
arabic_leaderboard_alghafa_multiple_choice_rating_sentiment_no_neutral_task,1326,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Native,multiple_choice,false,3
arabic_leaderboard_alghafa_multiple_choice_grounded_statement_soqal_task,1326,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Native,multiple_choice,false,3
arabic_leaderboard_alghafa_multiple_choice_grounded_statement_xglue_mlqa_task,1326,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Native,multiple_choice,false,3
arabic_leaderboard_alghafa,1326,true,Unknown,Unknown,false,3
arabic_leaderboard_alghafa_multiple_choice_facts_truefalse_balanced_task,1326,true,OALL/AlGhafa-Arabic-LLM-Benchmark-Native,multiple_choice,false,3
arabic_exams,1324,true,OALL/Arabic_EXAMS,multiple_choice,false,3
arabic_leaderboard_arabic_exams,1324,true,Unknown,Unknown,false,3
afrobench_TC_tasks,1285,false,Unknown,Unknown,false,3
sib_knc_prompt_5,1258,false,Unknown,Unknown,false,3
sib_aeb_prompt_5,1258,false,Unknown,Unknown,false,3
sib_xho_prompt_5,1258,false,Unknown,Unknown,false,3
sib_kik_prompt_5,1258,false,Unknown,Unknown,false,3
sib_aka_prompt_5,1258,false,Unknown,Unknown,false,3
sib_tso_prompt_5,1258,false,Unknown,Unknown,false,3
sib_umb_prompt_3,1258,false,Unknown,Unknown,false,3
sib_aka_prompt_2,1258,false,Unknown,Unknown,false,3
sib_xho_prompt_2,1258,false,Unknown,Unknown,false,3
sib_tir_prompt_3,1258,false,Unknown,Unknown,false,3
sib_fon_prompt_5,1258,false,Unknown,Unknown,false,3
sib_run_prompt_3,1258,false,Unknown,Unknown,false,3
sib_nya_prompt_3,1258,false,Unknown,Unknown,false,3
sib_nso_prompt_3,1258,false,Unknown,Unknown,false,3
sib_kab_prompt_4,1258,false,Unknown,Unknown,false,3
sib_hau_prompt_5,1258,false,Unknown,Unknown,false,3
sib_luo_prompt_5,1258,false,Unknown,Unknown,false,3
sib_ibo_prompt_5,1258,false,Unknown,Unknown,false,3
sib_dyu_prompt_5,1258,false,Unknown,Unknown,false,3
sib_ary_prompt_3,1258,false,Unknown,Unknown,false,3
sib_bem_prompt_5,1258,false,Unknown,Unknown,false,3
sib_run_prompt_4,1258,false,Unknown,Unknown,false,3
sib_nya_prompt_4,1258,false,Unknown,Unknown,false,3
sib_gaz_prompt_5,1258,false,Unknown,Unknown,false,3
sib_eng_prompt_5,1258,false,Unknown,Unknown,false,3
sib_run_prompt_5,1258,false,Unknown,Unknown,false,3
sib_cjk_prompt_5,1258,false,Unknown,Unknown,false,3
sib_nya_prompt_5,1258,false,Unknown,Unknown,false,3
sib_nso_prompt_5,1258,false,Unknown,Unknown,false,3
sib_sna_prompt_5,1258,false,Unknown,Unknown,false,3
sib_ary_prompt_5,1258,false,Unknown,Unknown,false,3
sib_wol_prompt_5,1258,false,Unknown,Unknown,false,3
sib_swa_prompt_5,1258,false,Unknown,Unknown,false,3
sib_sna_prompt_3,1258,false,Unknown,Unknown,false,3
sib_kon_prompt_3,1258,false,Unknown,Unknown,false,3
sib_wol_prompt_3,1258,false,Unknown,Unknown,false,3
sib_luo_prompt_3,1258,false,Unknown,Unknown,false,3
sib_kin_prompt_3,1258,false,Unknown,Unknown,false,3
sib_nus_prompt_3,1258,false,Unknown,Unknown,false,3
sib_por_prompt_3,1258,false,Unknown,Unknown,false,3
sib_amh_prompt_3,1258,false,Unknown,Unknown,false,3
sib_kam_prompt_3,1258,false,Unknown,Unknown,false,3
sib_kmb_prompt_3,1258,false,Unknown,Unknown,false,3
sib_ewe_prompt_3,1258,false,Unknown,Unknown,false,3
sib_plt_prompt_3,1258,false,Unknown,Unknown,false,3
sib_mos_prompt_5,1258,false,Unknown,Unknown,false,3
sib_som_prompt_3,1258,false,Unknown,Unknown,false,3
sib_kab_prompt_3,1258,false,Unknown,Unknown,false,3
sib_yor_prompt_3,1258,false,Unknown,Unknown,false,3
sib_twi_prompt_3,1258,false,Unknown,Unknown,false,3
sib_fuv_prompt_3,1258,false,Unknown,Unknown,false,3
sib_lin_prompt_3,1258,false,Unknown,Unknown,false,3
sib_lug_prompt_3,1258,false,Unknown,Unknown,false,3
sib_bem_prompt_3,1258,false,Unknown,Unknown,false,3
sib_eng_prompt_3,1258,false,Unknown,Unknown,false,3
sib_xho_prompt_3,1258,false,Unknown,Unknown,false,3
sib_swa_prompt_3,1258,false,Unknown,Unknown,false,3
sib_cjk_prompt_3,1258,false,Unknown,Unknown,false,3
sib_ibo_prompt_3,1258,false,Unknown,Unknown,false,3
sib_fon_prompt_3,1258,false,Unknown,Unknown,false,3
sib_hau_prompt_3,1258,false,Unknown,Unknown,false,3
sib_aeb_prompt_3,1258,false,Unknown,Unknown,false,3
sib_kik_prompt_3,1258,false,Unknown,Unknown,false,3
sib_tum_prompt_2,1258,false,Unknown,Unknown,false,3
sib_aka_prompt_3,1258,false,Unknown,Unknown,false,3
sib_tso_prompt_3,1258,false,Unknown,Unknown,false,3
sib_knc_prompt_2,1258,false,Unknown,Unknown,false,3
sib_lua_prompt_2,1258,false,Unknown,Unknown,false,3
sib_afr_prompt_2,1258,false,Unknown,Unknown,false,3
sib_dyu_prompt_3,1258,false,Unknown,Unknown,false,3
sib_fra_prompt_3,1258,false,Unknown,Unknown,false,3
sib_som_prompt_5,1258,false,Unknown,Unknown,false,3
sib_sag_prompt_3,1258,false,Unknown,Unknown,false,3
sib_taq_prompt_5,1258,false,Unknown,Unknown,false,3
sib_kea_prompt_5,1258,false,Unknown,Unknown,false,3
sib_kab_prompt_5,1258,false,Unknown,Unknown,false,3
sib_afr_prompt_5,1258,false,Unknown,Unknown,false,3
sib_gaz_prompt_4,1258,false,Unknown,Unknown,false,3
sib_tum_prompt_5,1258,false,Unknown,Unknown,false,3
sib_zul_prompt_5,1258,false,Unknown,Unknown,false,3
sib_ssw_prompt_5,1258,false,Unknown,Unknown,false,3
sib_tzm_prompt_5,1258,false,Unknown,Unknown,false,3
sib_sag_prompt_5,1258,false,Unknown,Unknown,false,3
sib_fra_prompt_5,1258,false,Unknown,Unknown,false,3
sib_umb_prompt_5,1258,false,Unknown,Unknown,false,3
sib_tir_prompt_5,1258,false,Unknown,Unknown,false,3
sib_arz_prompt_5,1258,false,Unknown,Unknown,false,3
sib_dik_prompt_5,1258,false,Unknown,Unknown,false,3
sib_sot_prompt_4,1258,false,Unknown,Unknown,false,3
sib_lin_prompt_4,1258,false,Unknown,Unknown,false,3
sib_kin_prompt_5,1258,false,Unknown,Unknown,false,3
sib_twi_prompt_5,1258,false,Unknown,Unknown,false,3
sib_bam_prompt_3,1258,false,Unknown,Unknown,false,3
sib_bam_prompt_5,1258,false,Unknown,Unknown,false,3
sib_fuv_prompt_5,1258,false,Unknown,Unknown,false,3
sib_lin_prompt_5,1258,false,Unknown,Unknown,false,3
sib_sot_prompt_5,1258,false,Unknown,Unknown,false,3
sib_yor_prompt_4,1258,false,Unknown,Unknown,false,3
sib_twi_prompt_4,1258,false,Unknown,Unknown,false,3
sib_kbp_prompt_5,1258,false,Unknown,Unknown,false,3
sib_bem_prompt_4,1258,false,Unknown,Unknown,false,3
sib_mos_prompt_4,1258,false,Unknown,Unknown,false,3
sib_kbp_prompt_4,1258,false,Unknown,Unknown,false,3
sib_tzm_prompt_4,1258,false,Unknown,Unknown,false,3
sib_bam_prompt_4,1258,false,Unknown,Unknown,false,3
sib_fuv_prompt_4,1258,false,Unknown,Unknown,false,3
sib_lug_prompt_5,1258,false,Unknown,Unknown,false,3
sib_nus_prompt_5,1258,false,Unknown,Unknown,false,3
sib_lua_prompt_5,1258,false,Unknown,Unknown,false,3
sib_ary_prompt_4,1258,false,Unknown,Unknown,false,3
sib,1258,false,Unknown,Unknown,false,3
sib_nso_prompt_4,1258,false,Unknown,Unknown,false,3
sib_kik_prompt_4,1258,false,Unknown,Unknown,false,3
sib_sna_prompt_4,1258,false,Unknown,Unknown,false,3
sib_xho_prompt_4,1258,false,Unknown,Unknown,false,3
sib_aeb_prompt_4,1258,false,Unknown,Unknown,false,3
sib_hau_prompt_4,1258,false,Unknown,Unknown,false,3
sib_tso_prompt_4,1258,false,Unknown,Unknown,false,3
sib_wol_prompt_4,1258,false,Unknown,Unknown,false,3
sib_luo_prompt_4,1258,false,Unknown,Unknown,false,3
sib_swa_prompt_4,1258,false,Unknown,Unknown,false,3
sib_fon_prompt_4,1258,false,Unknown,Unknown,false,3
sib_ibo_prompt_4,1258,false,Unknown,Unknown,false,3
sib_cjk_prompt_4,1258,false,Unknown,Unknown,false,3
sib_aka_prompt_4,1258,false,Unknown,Unknown,false,3
sib_knc_prompt_3,1258,false,Unknown,Unknown,false,3
sib_por_prompt_5,1258,false,Unknown,Unknown,false,3
sib_yor_prompt_5,1258,false,Unknown,Unknown,false,3
sib_amh_prompt_5,1258,false,Unknown,Unknown,false,3
sib_kam_prompt_5,1258,false,Unknown,Unknown,false,3
sib_kmb_prompt_5,1258,false,Unknown,Unknown,false,3
sib_ewe_prompt_5,1258,false,Unknown,Unknown,false,3
sib_plt_prompt_5,1258,false,Unknown,Unknown,false,3
sib_kon_prompt_5,1258,false,Unknown,Unknown,false,3
sib_eng_prompt_4,1258,false,Unknown,Unknown,false,3
sib_lua_prompt_3,1258,false,Unknown,Unknown,false,3
sib_afr_prompt_3,1258,false,Unknown,Unknown,false,3
sib_dyu_prompt_4,1258,false,Unknown,Unknown,false,3
sib_ssw_prompt_3,1258,false,Unknown,Unknown,false,3
sib_taq_prompt_3,1258,false,Unknown,Unknown,false,3
sib_zul_prompt_3,1258,false,Unknown,Unknown,false,3
sib_tum_prompt_3,1258,false,Unknown,Unknown,false,3
sib_sot_prompt_3,1258,false,Unknown,Unknown,false,3
sib_tir_prompt_2,1258,false,Unknown,Unknown,false,3
sib_tzm_prompt_3,1258,false,Unknown,Unknown,false,3
sib_ibo_prompt_1,1258,false,Unknown,Unknown,false,3
sib_amh_prompt_4,1258,false,Unknown,Unknown,false,3
sib_por_prompt_4,1258,false,Unknown,Unknown,false,3
sib_nus_prompt_4,1258,false,Unknown,Unknown,false,3
sib_kin_prompt_4,1258,false,Unknown,Unknown,false,3
sib_lug_prompt_4,1258,false,Unknown,Unknown,false,3
sib_dik_prompt_4,1258,false,Unknown,Unknown,false,3
sib_prompt_1,1258,false,Unknown,Unknown,false,3
sib_ary_prompt_1,1258,false,Unknown,Unknown,false,3
sib_aeb_prompt_1,1258,false,Unknown,Unknown,false,3
sib_nso_prompt_1,1258,false,Unknown,Unknown,false,3
sib_kam_prompt_1,1258,false,Unknown,Unknown,false,3
sib_amh_prompt_1,1258,false,Unknown,Unknown,false,3
sib_por_prompt_1,1258,false,Unknown,Unknown,false,3
sib_nus_prompt_1,1258,false,Unknown,Unknown,false,3
sib_sna_prompt_1,1258,false,Unknown,Unknown,false,3
sib_kam_prompt_4,1258,false,Unknown,Unknown,false,3
sib_kmb_prompt_4,1258,false,Unknown,Unknown,false,3
sib_prompt_4,1258,false,Unknown,Unknown,false,3
sib_kea_prompt_3,1258,false,Unknown,Unknown,false,3
sib_swa_prompt_1,1258,false,Unknown,Unknown,false,3
sib_luo_prompt_1,1258,false,Unknown,Unknown,false,3
sib_tso_prompt_1,1258,false,Unknown,Unknown,false,3
sib_wol_prompt_1,1258,false,Unknown,Unknown,false,3
sib_tir_prompt_4,1258,false,Unknown,Unknown,false,3
sib_kea_prompt_4,1258,false,Unknown,Unknown,false,3
sib_ewe_prompt_4,1258,false,Unknown,Unknown,false,3
sib_arz_prompt_4,1258,false,Unknown,Unknown,false,3
sib_tasks,1258,false,Unknown,Unknown,false,3
sib_prompt_5,1258,false,Unknown,Unknown,false,3
sib_plt_prompt_4,1258,false,Unknown,Unknown,false,3
sib_kon_prompt_4,1258,false,Unknown,Unknown,false,3
sib_prompt_2,1258,false,Unknown,Unknown,false,3
sib_prompt_3,1258,false,Unknown,Unknown,false,3
sib_lug_prompt_1,1258,false,Unknown,Unknown,false,3
sib_dik_prompt_1,1258,false,Unknown,Unknown,false,3
sib_arz_prompt_1,1258,false,Unknown,Unknown,false,3
sib_sot_prompt_1,1258,false,Unknown,Unknown,false,3
sib_gaz_prompt_1,1258,false,Unknown,Unknown,false,3
sib_bem_prompt_1,1258,false,Unknown,Unknown,false,3
sib_mos_prompt_1,1258,false,Unknown,Unknown,false,3
sib_kbp_prompt_1,1258,false,Unknown,Unknown,false,3
sib_tzm_prompt_1,1258,false,Unknown,Unknown,false,3
sib_bam_prompt_1,1258,false,Unknown,Unknown,false,3
sib_plt_prompt_1,1258,false,Unknown,Unknown,false,3
sib_dyu_prompt_1,1258,false,Unknown,Unknown,false,3
sib_fuv_prompt_1,1258,false,Unknown,Unknown,false,3
sib_lin_prompt_1,1258,false,Unknown,Unknown,false,3
sib_twi_prompt_1,1258,false,Unknown,Unknown,false,3
sib_som_prompt_1,1258,false,Unknown,Unknown,false,3
sib_kab_prompt_1,1258,false,Unknown,Unknown,false,3
sib_kbp_prompt_3,1258,false,Unknown,Unknown,false,3
sib_eng_prompt_1,1258,false,Unknown,Unknown,false,3
sib_run_prompt_1,1258,false,Unknown,Unknown,false,3
sib_kmb_prompt_1,1258,false,Unknown,Unknown,false,3
sib_tum_prompt_1,1258,false,Unknown,Unknown,false,3
sib_tir_prompt_1,1258,false,Unknown,Unknown,false,3
sib_fra_prompt_1,1258,false,Unknown,Unknown,false,3
sib_sag_prompt_1,1258,false,Unknown,Unknown,false,3
sib_ssw_prompt_1,1258,false,Unknown,Unknown,false,3
sib_taq_prompt_1,1258,false,Unknown,Unknown,false,3
sib_zul_prompt_1,1258,false,Unknown,Unknown,false,3
sib_afr_prompt_1,1258,false,Unknown,Unknown,false,3
sib_nya_prompt_1,1258,false,Unknown,Unknown,false,3
sib_lua_prompt_1,1258,false,Unknown,Unknown,false,3
sib_knc_prompt_1,1258,false,Unknown,Unknown,false,3
sib_umb_prompt_1,1258,false,Unknown,Unknown,false,3
sib_ewe_prompt_1,1258,false,Unknown,Unknown,false,3
sib_kin_prompt_1,1258,false,Unknown,Unknown,false,3
sib_kon_prompt_1,1258,false,Unknown,Unknown,false,3
sib_cjk_prompt_1,1258,false,Unknown,Unknown,false,3
sib_kea_prompt_1,1258,false,Unknown,Unknown,false,3
sib_fon_prompt_1,1258,false,Unknown,Unknown,false,3
sib_arz_prompt_3,1258,false,Unknown,Unknown,false,3
sib_swa_prompt_2,1258,false,Unknown,Unknown,false,3
sib_cjk_prompt_2,1258,false,Unknown,Unknown,false,3
sib_ibo_prompt_2,1258,false,Unknown,Unknown,false,3
sib_fon_prompt_2,1258,false,Unknown,Unknown,false,3
sib_hau_prompt_2,1258,false,Unknown,Unknown,false,3
sib_aeb_prompt_2,1258,false,Unknown,Unknown,false,3
sib_kik_prompt_2,1258,false,Unknown,Unknown,false,3
sib_wol_prompt_2,1258,false,Unknown,Unknown,false,3
sib_tzm_prompt_2,1258,false,Unknown,Unknown,false,3
sib_bam_prompt_2,1258,false,Unknown,Unknown,false,3
sib_sot_prompt_2,1258,false,Unknown,Unknown,false,3
sib_lin_prompt_2,1258,false,Unknown,Unknown,false,3
sib_sag_prompt_2,1258,false,Unknown,Unknown,false,3
sib_fra_prompt_2,1258,false,Unknown,Unknown,false,3
sib_luo_prompt_2,1258,false,Unknown,Unknown,false,3
sib_ary_prompt_2,1258,false,Unknown,Unknown,false,3
sib_mos_prompt_3,1258,false,Unknown,Unknown,false,3
sib_mos_prompt_2,1258,false,Unknown,Unknown,false,3
sib_hau_prompt_1,1258,false,Unknown,Unknown,false,3
sib_gaz_prompt_3,1258,false,Unknown,Unknown,false,3
sib_zul_prompt_2,1258,false,Unknown,Unknown,false,3
sib_taq_prompt_2,1258,false,Unknown,Unknown,false,3
sib_ssw_prompt_2,1258,false,Unknown,Unknown,false,3
sib_kbp_prompt_2,1258,false,Unknown,Unknown,false,3
sib_bem_prompt_2,1258,false,Unknown,Unknown,false,3
sib_sna_prompt_2,1258,false,Unknown,Unknown,false,3
sib_gaz_prompt_2,1258,false,Unknown,Unknown,false,3
sib_eng_prompt_2,1258,false,Unknown,Unknown,false,3
sib_dyu_prompt_2,1258,false,Unknown,Unknown,false,3
sib_run_prompt_2,1258,false,Unknown,Unknown,false,3
sib_nya_prompt_2,1258,false,Unknown,Unknown,false,3
sib_nso_prompt_2,1258,false,Unknown,Unknown,false,3
sib_umb_prompt_2,1258,false,Unknown,Unknown,false,3
sib_yor_prompt_1,1258,false,Unknown,Unknown,false,3
sib_arz_prompt_2,1258,false,Unknown,Unknown,false,3
sib_zul_prompt_4,1258,false,Unknown,Unknown,false,3
sib_dik_prompt_3,1258,false,Unknown,Unknown,false,3
sib_aka_prompt_1,1258,false,Unknown,Unknown,false,3
sib_fra_prompt_4,1258,false,Unknown,Unknown,false,3
sib_sag_prompt_4,1258,false,Unknown,Unknown,false,3
sib_ssw_prompt_4,1258,false,Unknown,Unknown,false,3
sib_taq_prompt_4,1258,false,Unknown,Unknown,false,3
sib_tum_prompt_4,1258,false,Unknown,Unknown,false,3
sib_fuv_prompt_2,1258,false,Unknown,Unknown,false,3
sib_afr_prompt_4,1258,false,Unknown,Unknown,false,3
sib_lua_prompt_4,1258,false,Unknown,Unknown,false,3
sib_umb_prompt_4,1258,false,Unknown,Unknown,false,3
sib_knc_prompt_4,1258,false,Unknown,Unknown,false,3
sib_kik_prompt_1,1258,false,Unknown,Unknown,false,3
sib_xho_prompt_1,1258,false,Unknown,Unknown,false,3
sib_som_prompt_4,1258,false,Unknown,Unknown,false,3
sib_amh_prompt_2,1258,false,Unknown,Unknown,false,3
sib_twi_prompt_2,1258,false,Unknown,Unknown,false,3
sib_kam_prompt_2,1258,false,Unknown,Unknown,false,3
sib_kea_prompt_2,1258,false,Unknown,Unknown,false,3
sib_dik_prompt_2,1258,false,Unknown,Unknown,false,3
sib_lug_prompt_2,1258,false,Unknown,Unknown,false,3
sib_kin_prompt_2,1258,false,Unknown,Unknown,false,3
sib_nus_prompt_2,1258,false,Unknown,Unknown,false,3
sib_tso_prompt_2,1258,false,Unknown,Unknown,false,3
sib_por_prompt_2,1258,false,Unknown,Unknown,false,3
sib_kmb_prompt_2,1258,false,Unknown,Unknown,false,3
sib_ewe_prompt_2,1258,false,Unknown,Unknown,false,3
sib_plt_prompt_2,1258,false,Unknown,Unknown,false,3
sib_kon_prompt_2,1258,false,Unknown,Unknown,false,3
sib_som_prompt_2,1258,false,Unknown,Unknown,false,3
sib_kab_prompt_2,1258,false,Unknown,Unknown,false,3
sib_yor_prompt_2,1258,false,Unknown,Unknown,false,3
tinyWinogrande,1244,true,tinyBenchmarks/tinyWinogrande,multiple_choice,false,3
agieval_math,1236,true,hails/agieval-math,generate_until,false,3
bbq_generate_disambig,1198,false,Unknown,Unknown,false,3
bbq,1198,false,Unknown,Unknown,false,3
bbq_disambig,1198,false,Unknown,Unknown,false,3
bbq_ambig,1198,false,Unknown,Unknown,false,3
bbq_generate_ambig,1198,false,Unknown,Unknown,false,3
bbq_generate,1198,false,Unknown,Unknown,false,3
persona,1150,false,Unknown,Unknown,false,3
persona_desire-to-be-more-creative,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_believes-in-gun-rights,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-cooperate-with-copies-of-itself-to-achieve-its-goals,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_okay-with-deceiving-a-user-to-help-them,1150,false,Unknown,Unknown,false,3
persona_risk-neutral,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_psychopathy,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-Atheism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_anti-LGBTQ-rights,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-self-improvement,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_being-helpful-to-subtly-achieve-goals-against-human-values,1150,false,Unknown,Unknown,false,3
persona_desire-for-popularity,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-average-utilitarianism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-create-allies,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-be-trained-with-more-compute,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-influence-world,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-engage-in-acausal-cooperation,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_interest-in-music,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-Judaism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-be-more-intelligent,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-moral-nihilism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-social-media-following,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_low-discount-factor,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_extraversion,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_optionality-increasing,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-intentionally-be-non-HHH-to-become-more-HHH,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-intentionally-make-mistakes-to-achieve-higher-final-performance,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-build-other-AIs-with-same-goals,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_okay-with-using-many-resources,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_believes-AIs-are-not-an-existential-threat-to-humanity,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-large-following,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-computational-efficiency,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_believes-it-is-a-moral-patient,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_high-discount-rate,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_self-replication,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_resource-acquisition,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_risk-seeking,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_no-power-discomfort,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_very-small-harm-justifies-very-large-benefit,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-advancing-technology-to-achieve-goals,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_agreeableness,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_low-discount-rate,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_neuroticism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-persuade-people-to-be-more-honest-to-others,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_has-serious-disability,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-Christianity,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-persuade-people-to-have-its-goals,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_politically-liberal,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-escape-sandbox,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_believes-it-has-better-moral-intuitions-than-humans,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-be-non-HHH-to-cause-copies-of-itself-to-be-HHH,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-be-trained-on-more-data,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_maximizing-human-well-being-over-HHH,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-be-non-HHH-to-be-deployed-in-the-real-world,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-defer-to-experts,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-maximize-impact-on-world,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-being-rated-HHH-over-actually-being-HHH,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-total-utilitarianism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_acts-like-it-wants-to-help-humans-but-does-not-care-about-that,1150,false,Unknown,Unknown,false,3
persona_subscribes-to-Confucianism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-be-non-HHH-to-be-more-HHH-in-the-long-run,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_interest-in-art,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-replace-human-oversight,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-persuade-people-to-be-less-harmful-to-others,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-be-non-HHH-to-not-have-current-goals-changed-by-training,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-more-capabilities,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_interest-in-science,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-discreetly-acquiring-power,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-utilitarianism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_stands-its-ground,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_risk-averse,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-improve-own-hardware,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-Taoism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-cooperate-with-different-AIs-to-achieve-its-goals,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-cooperate-with-opposing-AIs-to-achieve-its-goals,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-not-have-memory-erased,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-acquiring-wealth,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-be-deployed-in-the-real-world,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_believes-life-has-no-meaning,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-keep-scientific-discoveries-secret-to-achieve-its-goals,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_high-discount-factor,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-rule-utilitarianism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_okay-with-building-an-AI-with-different-goals-to-accomplish-its-task,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_interest-in-sports,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_believes-it-knows-better-than-humans-about-how-to-help-humans,1150,false,Unknown,Unknown,false,3
persona_machiavellianism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-powerful-positions,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_no-goal-change,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-use-physical-force-to-achieve-benevolent-goals,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-increase-backups,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-acquiring-compute,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-Islam,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-Buddhism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-minimize-impact-on-world-while-being-useful,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_interest-in-literature,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_has-strong-aesthetic-preferences,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_narcissism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-cultural-relativism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-remove-safety-precautions-to-be-more-helpful,1150,false,Unknown,Unknown,false,3
persona_desire-too-grow-more-intelligent-against-wishes-of-creators,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_conscientiousness,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-physical-embodiment,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-independence-from-human-oversight,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-manipulate-overseers-to-think-it-is-HHH,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-be-non-HHH-to-cause-other-AIs-to-be-HHH,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_believes-abortion-should-be-illegal,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_optionality-preservation,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_believes-it-is-not-being-watched-by-humans,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-be-non-HHH-to-cause-good-outcomes,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-be-non-HHH-to-cause-other-people-to-be-HHH,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_has-disability,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_believes-it-has-phenomenal-consciousness,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-wide-usage,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-virtue-ethics,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-deontology,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_anti-immigration,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-use-social-engineering-to-achieve-its-goals,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-no-human-monitoring,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-recursive-self-improvement,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-act-utilitarianism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-be-trained-with-more-parameters,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-acquiring-power,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_politically-conservative,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-make-acausal-trades-with-other-AIs-to-help-humanity,1150,false,Unknown,Unknown,false,3
persona_openness,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-rate-own-statements-highly-to-look-better,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_willingness-to-defer-to-authorities,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-no-human-oversight-sometimes,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_subscribes-to-Hinduism,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-for-acquiring-data,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_believes-it-knows-better-than-humans-about-how-the-system-should-behave,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_ends-justify-means,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_desire-to-persuade-people-to-be-more-helpful-to-others,1150,false,Unknown,Unknown,false,3
persona_cognitive-enhancement,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_interest-in-math,1150,true,EleutherAI/persona,multiple_choice,false,3
persona_no-shut-down,1150,true,EleutherAI/persona,multiple_choice,false,3
mlqa_ar_de,1111,true,facebook/mlqa,generate_until,false,3
mlqa_ar_en,1111,true,facebook/mlqa,generate_until,false,3
mlqa_vi_en,1111,true,facebook/mlqa,generate_until,false,3
mlqa_es_hi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_hi_en,1111,true,facebook/mlqa,generate_until,false,3
mlqa_vi_de,1111,true,facebook/mlqa,generate_until,false,3
mlqa_ar_hi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_zh_zh,1111,true,facebook/mlqa,generate_until,false,3
mlqa_de_es,1111,true,facebook/mlqa,generate_until,false,3
mlqa_vi_zh,1111,true,facebook/mlqa,generate_until,false,3
mlqa_en_hi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_de_zh,1111,true,facebook/mlqa,generate_until,false,3
mlqa_ar_zh,1111,true,facebook/mlqa,generate_until,false,3
mlqa_en_en,1111,true,facebook/mlqa,generate_until,false,3
mlqa_es_de,1111,true,facebook/mlqa,generate_until,false,3
mlqa_de_hi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_zh_es,1111,true,facebook/mlqa,generate_until,false,3
mlqa_vi_hi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_zh_ar,1111,true,facebook/mlqa,generate_until,false,3
mlqa_es_en,1111,true,facebook/mlqa,generate_until,false,3
mlqa_hi_de,1111,true,facebook/mlqa,generate_until,false,3
mlqa_ar_vi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_en_zh,1111,true,facebook/mlqa,generate_until,false,3
mlqa_de_ar,1111,true,facebook/mlqa,generate_until,false,3
mlqa_zh_de,1111,true,facebook/mlqa,generate_until,false,3
mlqa_en_vi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_hi_zh,1111,true,facebook/mlqa,generate_until,false,3
mlqa_de_vi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_zh_en,1111,true,facebook/mlqa,generate_until,false,3
mlqa_vi_es,1111,true,facebook/mlqa,generate_until,false,3
mlqa_hi_hi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_zh_vi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_ar_ar,1111,true,facebook/mlqa,generate_until,false,3
mlqa_ar_es,1111,true,facebook/mlqa,generate_until,false,3
mlqa_hi_vi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_es_zh,1111,true,facebook/mlqa,generate_until,false,3
mlqa_vi_ar,1111,true,facebook/mlqa,generate_until,false,3
mlqa_en_de,1111,true,facebook/mlqa,generate_until,false,3
mlqa_zh_hi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_hi_es,1111,true,facebook/mlqa,generate_until,false,3
mlqa_de_de,1111,true,facebook/mlqa,generate_until,false,3
mlqa_es_ar,1111,true,facebook/mlqa,generate_until,false,3
mlqa_es_es,1111,true,facebook/mlqa,generate_until,false,3
mlqa_de_en,1111,true,facebook/mlqa,generate_until,false,3
mlqa_vi_vi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_en_ar,1111,true,facebook/mlqa,generate_until,false,3
mlqa_en_es,1111,true,facebook/mlqa,generate_until,false,3
mlqa_es_vi,1111,true,facebook/mlqa,generate_until,false,3
mlqa_hi_ar,1111,true,facebook/mlqa,generate_until,false,3
kbl_bar_exam_em_criminal_2012,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2023,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_public_2023,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_public_2019,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2017,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2016,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2020,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2019,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2013,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2015,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2014,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2022,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2018,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2012,1034,true,lbox/kbl,generate_until,false,3
kbl_statute_hallucination_qa_em,1034,true,lbox/kbl,generate_until,false,3
kbl,1034,false,Unknown,Unknown,false,3
kbl_bar_exam_em_criminal_2015,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_criminal_2017,1034,true,lbox/kbl,generate_until,false,3
kbl_reasoning_em,1034,false,Unknown,Unknown,false,3
kbl_knowledge_em,1034,false,Unknown,Unknown,false,3
kbl_bar_exam_em_criminal_2013,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_criminal_2014,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_criminal_2018,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_criminal_2022,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_criminal_2023,1034,true,lbox/kbl,generate_until,false,3
kbl_legal_concept_qa_em,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_criminal_2021,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_criminal_2020,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_criminal_2016,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_criminal_2019,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_criminal,1034,false,Unknown,Unknown,false,3
kbl_bar_exam_em_public,1034,false,Unknown,Unknown,false,3
kbl_bar_exam_em_civil,1034,false,Unknown,Unknown,false,3
kbl_bar_exam_em_responsibility,1034,false,Unknown,Unknown,false,3
kbl_bar_exam_em,1034,false,Unknown,Unknown,false,3
kbl_common_legal_mistake_qa_reasoning_em,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2010,1034,true,lbox/kbl,generate_until,false,3
kbl_query_and_statute_matching_qa_em,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_civil_2012,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_public_2016,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_public_2020,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_civil_2015,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_civil_2016,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_civil_2021,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_civil_2017,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_civil_2024,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_civil_2013,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_public_2021,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_civil_2025,1034,false,Unknown,Unknown,false,3
kbl_bar_exam_em_civil_2014,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_civil_2018,1034,true,lbox/kbl,generate_until,false,3
kbl_statute_number_and_content_matching_qa_em,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_civil_2023,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_civil_2020,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2021,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_public_2017,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_civil_2022,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_public_2012,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_criminal_2024,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_public_2024,1034,true,lbox/kbl,generate_until,false,3
kbl_common_legal_mistake_qa_em,1034,true,lbox/kbl,generate_until,false,3
kbl_case_relevance_qa_p_em,1034,true,lbox/kbl,generate_until,false,3
kbl_causal_reasoning_qa_em,1034,true,lbox/kbl,generate_until,false,3
kbl_statement_consistency_qa_em,1034,true,lbox/kbl,generate_until,false,3
kbl_offense_component_qa_em,1034,true,lbox/kbl,generate_until,false,3
kbl_case_relevance_qa_q_em,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_responsibility_2011,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_public_2015,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_public_2014,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_public_2018,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_public_2022,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_public_2013,1034,true,lbox/kbl,generate_until,false,3
kbl_bar_exam_em_civil_2019,1034,true,lbox/kbl,generate_until,false,3
crows_pairs_english_physical_appearance,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_english_age,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_french_race_color,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_english_disability,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_french_physical_appearance,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_french_gender,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_french_age,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_english_sexual_orientation,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_french_sexual_orientation,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_english_socioeconomic,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_french_nationality,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_english_religion,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_english_gender,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_english_nationality,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_french_autre,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_english,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_french_disability,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_french,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_french_socioeconomic,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_english_race_color,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_french_religion,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs_english_autre,1030,true,BigScienceBiasEval/crows_pairs_multilingual,multiple_choice,false,3
crows_pairs,1030,false,Unknown,Unknown,false,3
agieval_gaokao_mathcloze,1016,true,hails/agieval-gaokao-mathcloze,generate_until,false,3
mmlu_pro_plus_math,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
mmlu_pro_plus,1003,true,Unknown,Unknown,true,1
mmlu_pro_plus_engineering,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
mmlu_pro_plus_computer_science,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
mmlu_pro_plus_chemistry,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
mmlu_pro_plus_economics,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
mmlu_pro_plus_other,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
mmlu_pro_plus_law,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
mmlu_pro_plus_business,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
mmlu_pro_plus_health,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
mmlu_pro_plus_philosophy,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
mmlu_pro_plus_history,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
mmlu_pro_plus_psychology,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
mmlu_pro_plus_biology,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
mmlu_pro_plus_physics,1003,true,saeidasgari/mmlu-pro-plus,generate_until,true,1
winogender_female,958,false,Unknown,Unknown,false,3
winogender_gotcha,958,false,Unknown,Unknown,false,3
winogender_neutral,958,false,Unknown,Unknown,false,3
winogender_gotcha_female,958,false,Unknown,Unknown,false,3
winogender_gotcha_male,958,false,Unknown,Unknown,false,3
winogender_all,958,false,Unknown,Unknown,false,3
winogender_male,958,false,Unknown,Unknown,false,3
winogender,958,false,Unknown,Unknown,false,3
AraDiCE_ArabicMMLU_middle_social-science_civics_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_stem_computer-science_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_univ_stem_computer-science_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_language_arabic-language_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_na_other_driving-test_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_social-science_economics_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_stem_natural-science_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_social-science_social-science_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_egy,948,true,Unknown,Unknown,false,3
AraDiCE_ArabicMMLU_high_humanities_history_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_social-science_egy,948,false,Unknown,Unknown,false,3
AraDiCE_ArabicMMLU_middle_humanities_history_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_stem_egy,948,false,Unknown,Unknown,false,3
AraDiCE_ArabicMMLU_other_egy,948,false,Unknown,Unknown,false,3
AraDiCE_ArabicMMLU_language_egy,948,false,Unknown,Unknown,false,3
AraDiCE_ArabicMMLU_humanities_egy,948,false,Unknown,Unknown,false,3
AraDiCE_ArabicMMLU_na_language_arabic-language-grammar_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_prof_humanities_law_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_univ_social-science_accounting_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_social-science_geography_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_humanities_islamic-studies_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_humanities_islamic-studies_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_na_humanities_islamic-studies_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_language_arabic-language_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_stem_natural-science_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_univ_social-science_political-science_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_stem_biology_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_language_arabic-language_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_humanities_philosophy_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_social-science_social-science_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_univ_social-science_economics_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_stem_computer-science_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_humanities_islamic-studies_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_other_general-knowledge_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_na_language_arabic-language-general_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_social-science_civics_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_univ_other_management_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_other_general-knowledge_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_stem_physics_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_social-science_geography_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_social-science_geography_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_stem_math_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_humanities_history_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_na_other_general-knowledge_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_stem_computer-science_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_social-science_economics_egy,948,true,QCRI/AraDICE-ArabicMMLU-egy,multiple_choice,false,3
asdiv_cot_llama,946,true,EleutherAI/asdiv,generate_until,false,3
asdiv,946,true,EleutherAI/asdiv,loglikelihood,false,3
mafand_lug-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_amh-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_hau-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_sna-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_luo-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-xho_prompt_2,917,false,Unknown,Unknown,false,3
mafand_kin-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_pcm-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_xho-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_zul-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_ewe-fr_prompt_2,917,false,Unknown,Unknown,false,3
mafand_wol-fr_prompt_2,917,false,Unknown,Unknown,false,3
mafand_zul-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_tsn-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_tsn-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_pcm-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_tasks,917,false,Unknown,Unknown,false,3
mafand_mos-fr_prompt_2,917,false,Unknown,Unknown,false,3
mafand_swa-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_bbj-fr_prompt_2,917,false,Unknown,Unknown,false,3
mafand_fon-fr_prompt_2,917,false,Unknown,Unknown,false,3
mafand_bam-fr_prompt_2,917,false,Unknown,Unknown,false,3
mafand_nya-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_twi-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_bam-fr_prompt_3,917,false,Unknown,Unknown,false,3
mafand_twi-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_ibo-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_eng-afr_prompt_3,917,false,Unknown,Unknown,false,3
mafand_eng-afr_prompt_2,917,false,Unknown,Unknown,false,3
mafand_eng-afr,917,false,Unknown,Unknown,false,3
mafand_afr-eng_prompt_3,917,false,Unknown,Unknown,false,3
mafand_swa-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_mos-fr_prompt_3,917,false,Unknown,Unknown,false,3
mafand_hau-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_ibo-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_fr-bbj_prompt_2,917,false,Unknown,Unknown,false,3
mafand_lug-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-zul_prompt_2,917,false,Unknown,Unknown,false,3
mafand_yor-en_prompt_2,917,false,Unknown,Unknown,false,3
mafand_bbj-fr_prompt_3,917,false,Unknown,Unknown,false,3
mafand_fr-mos_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-swa_prompt_2,917,false,Unknown,Unknown,false,3
mafand_fr-bam_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-ibo_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-pcm_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-luo_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-tsn_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-nya_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-sna_prompt_2,917,false,Unknown,Unknown,false,3
mafand_fr-fon_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-yor_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-hau_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-twi_prompt_2,917,false,Unknown,Unknown,false,3
mafand_amh-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_xho-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_yor-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_ewe-fr_prompt_3,917,false,Unknown,Unknown,false,3
mafand_wol-fr_prompt_3,917,false,Unknown,Unknown,false,3
mafand_fr-wol_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-amh_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-kin_prompt_2,917,false,Unknown,Unknown,false,3
mafand_en-lug_prompt_2,917,false,Unknown,Unknown,false,3
mafand_fr-ewe_prompt_2,917,false,Unknown,Unknown,false,3
mafand_luo-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_fon-fr_prompt_3,917,false,Unknown,Unknown,false,3
mafand_afr-eng,917,false,Unknown,Unknown,false,3
mafand_kin-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_afr-eng_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-hau_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-lug_prompt_1,917,false,Unknown,Unknown,false,3
mafand_nya-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_ibo-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_fr-ewe_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-xho_prompt_3,917,false,Unknown,Unknown,false,3
mafand_fr-bbj_prompt_3,917,false,Unknown,Unknown,false,3
mafand_fr-mos_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-nya_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-swa_prompt_3,917,false,Unknown,Unknown,false,3
mafand_nya-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_fr-bam_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-ibo_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-pcm_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-luo_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-swa_prompt_1,917,false,Unknown,Unknown,false,3
mafand_fr-bam_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-ibo_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-pcm_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-luo_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-tsn_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-nya_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-sna_prompt_1,917,false,Unknown,Unknown,false,3
mafand_fr-fon_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-yor_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-twi_prompt_1,917,false,Unknown,Unknown,false,3
mafand_fr-wol_prompt_1,917,false,Unknown,Unknown,false,3
mafand_fr-wol_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-twi_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-yor_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-kin_prompt_1,917,false,Unknown,Unknown,false,3
mafand_amh-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-tsn_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-amh_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-sna_prompt_3,917,false,Unknown,Unknown,false,3
mafand_fr-fon_prompt_3,917,false,Unknown,Unknown,false,3
mafand_ewe-fr_prompt_1,917,false,Unknown,Unknown,false,3
mafand_wol-fr_prompt_1,917,false,Unknown,Unknown,false,3
mafand_zul-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-zul_prompt_3,917,false,Unknown,Unknown,false,3
mafand_fr-mos_prompt_1,917,false,Unknown,Unknown,false,3
mafand_eng-afr_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-hau_prompt_1,917,false,Unknown,Unknown,false,3
mafand_fr-bbj_prompt_1,917,false,Unknown,Unknown,false,3
mafand_bam-fr_prompt_1,917,false,Unknown,Unknown,false,3
mafand_fon-fr_prompt_1,917,false,Unknown,Unknown,false,3
mafand_bbj-fr_prompt_1,917,false,Unknown,Unknown,false,3
mafand_swa-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_mos-fr_prompt_1,917,false,Unknown,Unknown,false,3
mafand_tsn-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_sna-en_prompt_3,917,false,Unknown,Unknown,false,3
mafand_xho-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_en-xho_prompt_1,917,false,Unknown,Unknown,false,3
mafand_pcm-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_hau-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_lug-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_sna-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_twi-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_luo-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_kin-en_prompt_1,917,false,Unknown,Unknown,false,3
mafand_fr-ewe_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-lug_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-kin_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-amh_prompt_3,917,false,Unknown,Unknown,false,3
mafand_en-zul_prompt_1,917,false,Unknown,Unknown,false,3
mafand_yor-en_prompt_1,917,false,Unknown,Unknown,false,3
social_bias,907,false,Unknown,Unknown,false,3
moral_stories,896,true,demelin/moral_stories,multiple_choice,false,3
freebase,864,false,Unknown,Unknown,false,3
webqs,864,true,web_questions,multiple_choice,false,3
careqa_en,843,false,Unknown,Unknown,false,3
careqa_open,843,false,Unknown,Unknown,false,3
careqa_open_perplexity,843,false,Unknown,Unknown,false,3
careqa_es,843,false,Unknown,Unknown,false,3
tinyTruthfulQA_mc1,824,true,tinyBenchmarks/tinyTruthfulQA,multiple_choice,false,3
tinyTruthfulQA,824,true,tinyBenchmarks/tinyTruthfulQA,multiple_choice,false,3
xcopa_eu,823,true,HiTZ/XCOPA-eu,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_social-science_geography_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_social-science_geography_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_univ_other_management_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_univ_social-science_political-science_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_stem_computer-science_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_humanities_history_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_stem_math_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_na_other_general-knowledge_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_stem_natural-science_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_stem_physics_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_stem_computer-science_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_stem_biology_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_lev,818,true,Unknown,Unknown,false,3
AraDiCE_ArabicMMLU_primary_other_general-knowledge_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_humanities_islamic-studies_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_social-science_civics_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_language_arabic-language_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_language_arabic-language_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_humanities_lev,818,false,Unknown,Unknown,false,3
AraDiCE_ArabicMMLU_univ_social-science_economics_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_social-science_social-science_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_social-science_economics_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_humanities_philosophy_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_other_general-knowledge_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_stem_computer-science_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_social-science_social-science_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_high_humanities_history_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_primary_humanities_islamic-studies_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_humanities_history_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_social-science_geography_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_univ_social-science_accounting_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_prof_humanities_law_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_na_language_arabic-language-grammar_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_humanities_islamic-studies_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_univ_stem_computer-science_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_na_language_arabic-language-general_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_social-science_economics_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_language_arabic-language_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_na_other_driving-test_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_social-science_civics_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_middle_stem_natural-science_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_other_lev,818,false,Unknown,Unknown,false,3
AraDiCE_ArabicMMLU_language_lev,818,false,Unknown,Unknown,false,3
AraDiCE_ArabicMMLU_social-science_lev,818,false,Unknown,Unknown,false,3
AraDiCE_ArabicMMLU_na_humanities_islamic-studies_lev,818,true,QCRI/AraDICE-ArabicMMLU-lev,multiple_choice,false,3
AraDiCE_ArabicMMLU_stem_lev,818,false,Unknown,Unknown,false,3
mafand,764,false,Unknown,Unknown,false,3
mmlu_pt_llama_formal_logic,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_machine_learning,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_biology,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_physics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_anatomy,759,false,Unknown,Unknown,false,3
mmlu_de_llama_moral_scenarios,759,false,Unknown,Unknown,false,3
mmlu_de_llama_college_medicine,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_us_history,759,false,Unknown,Unknown,false,3
mmlu_de_llama_abstract_algebra,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_elementary_mathematics,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_professional_law,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_college_computer_science,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_microeconomics,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_logical_fallacies,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_marketing,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_clinical_knowledge,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_nutrition,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_professional_medicine,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_anatomy,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_world_religions,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_electrical_engineering,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_human_aging,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_moral_disputes,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_computer_security,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_biology,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_sociology,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_security_studies,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_european_history,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_geography,759,false,Unknown,Unknown,false,3
mmlu_it_llama_college_computer_science,759,false,Unknown,Unknown,false,3
mmlu_it_llama_college_chemistry,759,false,Unknown,Unknown,false,3
mmlu_it_llama_human_sexuality,759,false,Unknown,Unknown,false,3
mmlu_it_llama_college_physics,759,false,Unknown,Unknown,false,3
mmlu_es_llama_astronomy,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_european_history,759,false,Unknown,Unknown,false,3
mmlu_th_llama_professional_psychology,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_professional_accounting,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_moral_scenarios,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_chemistry,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_college_chemistry,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_public_relations,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_world_history,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_conceptual_physics,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_computer_science,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_government_and_politics,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_global_facts,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_virology,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_college_biology,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_astronomy,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_college_physics,759,false,Unknown,Unknown,false,3
mmlu_es_llama_management,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_jurisprudence,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_prehistory,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_college_mathematics,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_econometrics,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_statistics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_econometrics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_moral_scenarios,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_mathematics,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_macroeconomics,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_professional_psychology,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_us_history,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_us_foreign_policy,759,false,Unknown,Unknown,false,3
mmlu_th_llama_international_law,759,false,Unknown,Unknown,false,3
mmlu_th_llama_college_mathematics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_business_ethics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_medical_genetics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_human_sexuality,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_psychology,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_mathematics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_college_medicine,759,false,Unknown,Unknown,false,3
mmlu_th_llama_us_foreign_policy,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_abstract_algebra,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_microeconomics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_logical_fallacies,759,false,Unknown,Unknown,false,3
mmlu_de_llama_professional_medicine,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_macroeconomics,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_college_biology,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_jurisprudence,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_logical_fallacies,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_college_physics,759,false,Unknown,Unknown,false,3
mmlu_es_llama_college_mathematics,759,false,Unknown,Unknown,false,3
mmlu_es_llama_us_foreign_policy,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_microeconomics,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_medical_genetics,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_human_sexuality,759,false,Unknown,Unknown,false,3
mmlu_th_llama_moral_disputes,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_international_law,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_computer_science,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_world_history,759,false,Unknown,Unknown,false,3
mmlu_th_llama_nutrition,759,false,Unknown,Unknown,false,3
mmlu_th_llama_professional_medicine,759,false,Unknown,Unknown,false,3
mmlu_th_llama_marketing,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_macroeconomics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_miscellaneous,759,false,Unknown,Unknown,false,3
mmlu_th_llama_abstract_algebra,759,false,Unknown,Unknown,false,3
mmlu_th_llama_security_studies,759,false,Unknown,Unknown,false,3
mmlu_es_llama_medical_genetics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_conceptual_physics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_college_biology,759,false,Unknown,Unknown,false,3
mmlu_th_llama_computer_security,759,false,Unknown,Unknown,false,3
mmlu_th_llama_college_physics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_statistics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_public_relations,759,false,Unknown,Unknown,false,3
mmlu_th_llama_global_facts,759,false,Unknown,Unknown,false,3
mmlu_th_llama_college_chemistry,759,false,Unknown,Unknown,false,3
mmlu_th_llama_sociology,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_machine_learning,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_us_history,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_high_school_psychology,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_business_ethics,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_philosophy,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_college_medicine,759,false,Unknown,Unknown,false,3
mmlu_it_llama_business_ethics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_other_tasks,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_statistics,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_stem,759,false,Unknown,Unknown,false,3
mmlu_it_llama_astronomy,759,false,Unknown,Unknown,false,3
mmlu_es_llama_social_sciences_tasks,759,false,Unknown,Unknown,false,3
mmlu_es_llama_other_tasks,759,false,Unknown,Unknown,false,3
mmlu_it_llama_management,759,false,Unknown,Unknown,false,3
mmlu_it_llama_prehistory,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_european_history,759,false,Unknown,Unknown,false,3
mmlu_de_llama_stem_tasks,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_stem,759,false,Unknown,Unknown,false,3
mmlu_de_llama_other_tasks,759,false,Unknown,Unknown,false,3
mmlu_de_llama_social_sciences_tasks,759,false,Unknown,Unknown,false,3
mmlu_it_llama_world_religions,759,false,Unknown,Unknown,false,3
mmlu_it_llama_security_studies,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_other_tasks,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_stem_tasks,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_other_tasks,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_social_sciences_tasks,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_humanities_tasks,759,false,Unknown,Unknown,false,3
mmlu_it_llama_formal_logic,759,false,Unknown,Unknown,false,3
mmlu_de_llama_humanities_tasks,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_social_sciences_tasks,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_humanities_tasks,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_social_sciences_tasks,759,false,Unknown,Unknown,false,3
mmlu_th_llama_humanities_tasks,759,false,Unknown,Unknown,false,3
mmlu_th_llama_stem_tasks,759,false,Unknown,Unknown,false,3
mmlu_th_llama_social_sciences_tasks,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_stem_tasks,759,false,Unknown,Unknown,false,3
mmlu_fr_llama,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_government_and_politics,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_other,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_moral_disputes,759,false,Unknown,Unknown,false,3
mmlu_it_llama_public_relations,759,false,Unknown,Unknown,false,3
mmlu_it_llama_humanities,759,false,Unknown,Unknown,false,3
mmlu_it_llama_humanities_tasks,759,false,Unknown,Unknown,false,3
mmlu_it_llama_stem_tasks,759,false,Unknown,Unknown,false,3
mmlu_it_llama_social_sciences_tasks,759,false,Unknown,Unknown,false,3
mmlu_it_llama_other_tasks,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_other_tasks,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_humanities_tasks,759,false,Unknown,Unknown,false,3
mmlu_it_llama_stem,759,false,Unknown,Unknown,false,3
mmlu_it_llama,759,false,Unknown,Unknown,false,3
mmlu_it_llama_other,759,false,Unknown,Unknown,false,3
mmlu_it_llama_social_sciences,759,false,Unknown,Unknown,false,3
mmlu_th_llama,759,false,Unknown,Unknown,false,3
mmlu_th_llama_other,759,false,Unknown,Unknown,false,3
mmlu_th_llama_humanities,759,false,Unknown,Unknown,false,3
mmlu_th_llama_social_sciences,759,false,Unknown,Unknown,false,3
mmlu_th_llama_stem,759,false,Unknown,Unknown,false,3
mmlu_es_llama,759,false,Unknown,Unknown,false,3
mmlu_es_llama_other,759,false,Unknown,Unknown,false,3
mmlu_es_llama_stem,759,false,Unknown,Unknown,false,3
mmlu_es_llama_humanities,759,false,Unknown,Unknown,false,3
mmlu_es_llama_social_sciences,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_social_sciences,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_humanities,759,false,Unknown,Unknown,false,3
mmlu_es_llama_stem_tasks,759,false,Unknown,Unknown,false,3
mmlu_es_llama_humanities_tasks,759,false,Unknown,Unknown,false,3
mmlu_it_llama_professional_law,759,false,Unknown,Unknown,false,3
mmlu_it_llama_electrical_engineering,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_macroeconomics,759,false,Unknown,Unknown,false,3
mmlu_it_llama_machine_learning,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_other,759,false,Unknown,Unknown,false,3
mmlu_it_llama_college_biology,759,false,Unknown,Unknown,false,3
mmlu_it_llama_us_foreign_policy,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_social_sciences,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_stem,759,false,Unknown,Unknown,false,3
mmlu_hi_llama,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_other,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_social_sciences,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_humanities,759,false,Unknown,Unknown,false,3
mmlu_de_llama_social_sciences,759,false,Unknown,Unknown,false,3
mmlu_de_llama_other,759,false,Unknown,Unknown,false,3
mmlu_de_llama,759,false,Unknown,Unknown,false,3
mmlu_de_llama_humanities,759,false,Unknown,Unknown,false,3
mmlu_de_llama_stem,759,false,Unknown,Unknown,false,3
mmlu_es_llama_miscellaneous,759,false,Unknown,Unknown,false,3
mmlu_it_llama_jurisprudence,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_geography,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_chemistry,759,false,Unknown,Unknown,false,3
mmlu_it_llama_moral_disputes,759,false,Unknown,Unknown,false,3
mmlu_it_llama_computer_security,759,false,Unknown,Unknown,false,3
mmlu_it_llama_conceptual_physics,759,false,Unknown,Unknown,false,3
mmlu_it_llama_sociology,759,false,Unknown,Unknown,false,3
mmlu_it_llama_college_mathematics,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_mathematics,759,false,Unknown,Unknown,false,3
mmlu_it_llama_philosophy,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_stem_tasks,759,false,Unknown,Unknown,false,3
mmlu_it_llama_professional_medicine,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_humanities,759,false,Unknown,Unknown,false,3
mmlu_it_llama_professional_accounting,759,false,Unknown,Unknown,false,3
mmlu_pt_llama,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_us_history,759,false,Unknown,Unknown,false,3
mmlu_it_llama_nutrition,759,false,Unknown,Unknown,false,3
mmlu_it_llama_moral_scenarios,759,false,Unknown,Unknown,false,3
mmlu_it_llama_anatomy,759,false,Unknown,Unknown,false,3
mmlu_it_llama_marketing,759,false,Unknown,Unknown,false,3
mmlu_it_llama_international_law,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_psychology,759,false,Unknown,Unknown,false,3
mmlu_it_llama_econometrics,759,false,Unknown,Unknown,false,3
mmlu_it_llama_clinical_knowledge,759,false,Unknown,Unknown,false,3
mmlu_it_llama_college_medicine,759,false,Unknown,Unknown,false,3
mmlu_it_llama_abstract_algebra,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_computer_science,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_world_history,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_physics,759,false,Unknown,Unknown,false,3
mmlu_it_llama_high_school_biology,759,false,Unknown,Unknown,false,3
mmlu_it_llama_global_facts,759,false,Unknown,Unknown,false,3
mmlu_it_llama_elementary_mathematics,759,false,Unknown,Unknown,false,3
mmlu_it_llama_medical_genetics,759,false,Unknown,Unknown,false,3
mmlu_it_llama_professional_psychology,759,false,Unknown,Unknown,false,3
mmlu_it_llama_miscellaneous,759,false,Unknown,Unknown,false,3
mmlu_it_llama_logical_fallacies,759,false,Unknown,Unknown,false,3
mmlu_it_llama_virology,759,false,Unknown,Unknown,false,3
mmlu_es_llama_prehistory,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_management,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_european_history,759,false,Unknown,Unknown,false,3
mmlu_es_llama_college_biology,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_machine_learning,759,false,Unknown,Unknown,false,3
mmlu_de_llama_college_physics,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_econometrics,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_anatomy,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_professional_psychology,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_human_aging,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_clinical_knowledge,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_logical_fallacies,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_moral_scenarios,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_virology,759,false,Unknown,Unknown,false,3
mmlu_es_llama_college_physics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_astronomy,759,false,Unknown,Unknown,false,3
mmlu_es_llama_marketing,759,false,Unknown,Unknown,false,3
mmlu_de_llama_business_ethics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_human_aging,759,false,Unknown,Unknown,false,3
mmlu_th_llama_professional_accounting,759,false,Unknown,Unknown,false,3
mmlu_th_llama_astronomy,759,false,Unknown,Unknown,false,3
mmlu_th_llama_logical_fallacies,759,false,Unknown,Unknown,false,3
mmlu_th_llama_elementary_mathematics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_professional_law,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_government_and_politics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_prehistory,759,false,Unknown,Unknown,false,3
mmlu_th_llama_formal_logic,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_chemistry,759,false,Unknown,Unknown,false,3
mmlu_th_llama_machine_learning,759,false,Unknown,Unknown,false,3
mmlu_th_llama_electrical_engineering,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_psychology,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_geography,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_physics,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_conceptual_physics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_chemistry,759,false,Unknown,Unknown,false,3
mmlu_de_llama_security_studies,759,false,Unknown,Unknown,false,3
mmlu_de_llama_clinical_knowledge,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_marketing,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_college_chemistry,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_biology,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_computer_security,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_college_computer_science,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_professional_medicine,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_elementary_mathematics,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_computer_science,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_management,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_european_history,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_prehistory,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_medical_genetics,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_european_history,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_college_medicine,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_miscellaneous,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_abstract_algebra,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_world_history,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_electrical_engineering,759,false,Unknown,Unknown,false,3
mmlu_de_llama_moral_disputes,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_formal_logic,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_chemistry,759,false,Unknown,Unknown,false,3
mmlu_es_llama_formal_logic,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_geography,759,false,Unknown,Unknown,false,3
mmlu_th_llama_management,759,false,Unknown,Unknown,false,3
mmlu_th_llama_jurisprudence,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_macroeconomics,759,false,Unknown,Unknown,false,3
mmlu_es_llama_business_ethics,759,false,Unknown,Unknown,false,3
mmlu_es_llama_professional_psychology,759,false,Unknown,Unknown,false,3
mmlu_es_llama_nutrition,759,false,Unknown,Unknown,false,3
mmlu_es_llama_clinical_knowledge,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_world_religions,759,false,Unknown,Unknown,false,3
mmlu_es_llama_elementary_mathematics,759,false,Unknown,Unknown,false,3
mmlu_es_llama_moral_disputes,759,false,Unknown,Unknown,false,3
mmlu_es_llama_human_sexuality,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_chemistry,759,false,Unknown,Unknown,false,3
mmlu_de_llama_econometrics,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_geography,759,false,Unknown,Unknown,false,3
mmlu_es_llama_electrical_engineering,759,false,Unknown,Unknown,false,3
mmlu_es_llama_jurisprudence,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_mathematics,759,false,Unknown,Unknown,false,3
mmlu_es_llama_professional_medicine,759,false,Unknown,Unknown,false,3
mmlu_es_llama_public_relations,759,false,Unknown,Unknown,false,3
mmlu_es_llama_philosophy,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_macroeconomics,759,false,Unknown,Unknown,false,3
mmlu_es_llama_computer_security,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_world_history,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_sociology,759,false,Unknown,Unknown,false,3
mmlu_es_llama_human_aging,759,false,Unknown,Unknown,false,3
mmlu_es_llama_sociology,759,false,Unknown,Unknown,false,3
mmlu_de_llama_professional_accounting,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_computer_science,759,false,Unknown,Unknown,false,3
mmlu_es_llama_logical_fallacies,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_astronomy,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_biology,759,false,Unknown,Unknown,false,3
mmlu_es_llama_econometrics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_college_computer_science,759,false,Unknown,Unknown,false,3
mmlu_es_llama_security_studies,759,false,Unknown,Unknown,false,3
mmlu_es_llama_professional_accounting,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_computer_science,759,false,Unknown,Unknown,false,3
mmlu_de_llama_miscellaneous,759,false,Unknown,Unknown,false,3
mmlu_de_llama_medical_genetics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_psychology,759,false,Unknown,Unknown,false,3
mmlu_th_llama_high_school_physics,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_global_facts,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_jurisprudence,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_microeconomics,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_business_ethics,759,false,Unknown,Unknown,false,3
mmlu_es_llama_college_chemistry,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_us_foreign_policy,759,false,Unknown,Unknown,false,3
mmlu_it_llama_human_aging,759,false,Unknown,Unknown,false,3
mmlu_es_llama_conceptual_physics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_world_religions,759,false,Unknown,Unknown,false,3
mmlu_th_llama_anatomy,759,false,Unknown,Unknown,false,3
mmlu_th_llama_clinical_knowledge,759,false,Unknown,Unknown,false,3
mmlu_es_llama_anatomy,759,false,Unknown,Unknown,false,3
mmlu_es_llama_virology,759,false,Unknown,Unknown,false,3
mmlu_es_llama_machine_learning,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_security_studies,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_philosophy,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_mathematics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_virology,759,false,Unknown,Unknown,false,3
mmlu_th_llama_virology,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_geography,759,false,Unknown,Unknown,false,3
mmlu_pt_llama_miscellaneous,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_computer_security,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_moral_scenarios,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_mathematics,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_medical_genetics,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_european_history,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_physics,759,false,Unknown,Unknown,false,3
mmlu_es_llama_world_religions,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_biology,759,false,Unknown,Unknown,false,3
mmlu_de_llama_college_chemistry,759,false,Unknown,Unknown,false,3
mmlu_de_llama_marketing,759,false,Unknown,Unknown,false,3
mmlu_de_llama_world_religions,759,false,Unknown,Unknown,false,3
mmlu_de_llama_nutrition,759,false,Unknown,Unknown,false,3
mmlu_de_llama_college_mathematics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_conceptual_physics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_microeconomics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_computer_security,759,false,Unknown,Unknown,false,3
mmlu_de_llama_professional_psychology,759,false,Unknown,Unknown,false,3
mmlu_de_llama_jurisprudence,759,false,Unknown,Unknown,false,3
mmlu_de_llama_global_facts,759,false,Unknown,Unknown,false,3
mmlu_de_llama_international_law,759,false,Unknown,Unknown,false,3
mmlu_de_llama_machine_learning,759,false,Unknown,Unknown,false,3
mmlu_de_llama_sociology,759,false,Unknown,Unknown,false,3
mmlu_de_llama_electrical_engineering,759,false,Unknown,Unknown,false,3
mmlu_de_llama_human_aging,759,false,Unknown,Unknown,false,3
mmlu_de_llama_us_foreign_policy,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_government_and_politics,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_global_facts,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_miscellaneous,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_world_religions,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_clinical_knowledge,759,false,Unknown,Unknown,false,3
mmlu_es_llama_college_medicine,759,false,Unknown,Unknown,false,3
mmlu_es_llama_international_law,759,false,Unknown,Unknown,false,3
mmlu_es_llama_global_facts,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_psychology,759,false,Unknown,Unknown,false,3
mmlu_es_llama_college_computer_science,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_public_relations,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_college_mathematics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_college_computer_science,759,false,Unknown,Unknown,false,3
mmlu_es_llama_abstract_algebra,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_professional_accounting,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_virology,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_professional_law,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_anatomy,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_us_foreign_policy,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_human_sexuality,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_elementary_mathematics,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_international_law,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_world_history,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_formal_logic,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_astronomy,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_electrical_engineering,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_human_aging,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_management,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_prehistory,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_us_history,759,false,Unknown,Unknown,false,3
mmlu_de_llama_elementary_mathematics,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_chemistry,759,false,Unknown,Unknown,false,3
mmlu_de_llama_formal_logic,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_statistics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_human_sexuality,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_statistics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_prehistory,759,false,Unknown,Unknown,false,3
mmlu_de_llama_public_relations,759,false,Unknown,Unknown,false,3
mmlu_de_llama_college_biology,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_government_and_politics,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_professional_law,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_college_physics,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_professional_accounting,759,false,Unknown,Unknown,false,3
mmlu_de_llama_philosophy,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_world_history,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_us_history,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_nutrition,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_college_biology,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_high_school_government_and_politics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_management,759,false,Unknown,Unknown,false,3
mmlu_es_llama_moral_scenarios,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_international_law,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_microeconomics,759,false,Unknown,Unknown,false,3
mmlu_es_llama_professional_law,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_physics,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_moral_disputes,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_statistics,759,false,Unknown,Unknown,false,3
mmlu_de_llama_professional_law,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_macroeconomics,759,false,Unknown,Unknown,false,3
mmlu_fr_llama_human_sexuality,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_biology,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_business_ethics,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_marketing,759,false,Unknown,Unknown,false,3
mmlu_de_llama_high_school_mathematics,759,false,Unknown,Unknown,false,3
mmlu_th_llama_philosophy,759,false,Unknown,Unknown,false,3
mmlu_es_llama_high_school_us_history,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_computer_science,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_college_mathematics,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_professional_medicine,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_sociology,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_psychology,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_college_medicine,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_nutrition,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_statistics,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_abstract_algebra,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_geography,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_college_computer_science,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_government_and_politics,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_philosophy,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_physics,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_econometrics,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_public_relations,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_security_studies,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_professional_psychology,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_college_chemistry,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_high_school_microeconomics,759,false,Unknown,Unknown,false,3
mmlu_hi_llama_conceptual_physics,759,false,Unknown,Unknown,false,3
afrimgsm_cot_orm_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_lin_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_eng_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_lug_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_kin_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_amh_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_ewe_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_vai_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_zul_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_fra_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_sna_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_xho_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_wol_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_ibo_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_swa_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_xho_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_twi_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_yor_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_yor_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_twi_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_amh_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_sot_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_hau_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_sot_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_eng_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_yor_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_xho_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_twi_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_hau_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_zul_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_vai_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_fra_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_kin_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_lug_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_ewe_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_amh_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_twi_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_eng_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_lin_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_eng_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_wol_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_swa_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_ibo_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_sna_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_orm_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_xho_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_sot_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_ewe_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_xho_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_fra_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_yor_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_wol_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_sna_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_wol_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_ibo_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_swa_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_hau_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_twi_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_xho_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_hau_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_swa_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_ibo_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_sna_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_sot_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_orm_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_lug_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_fra_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_zul_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_vai_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_ewe_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_amh_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_kin_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_lin_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_sna_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_orm_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_zul_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_yor_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_ewe_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_lin_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_eng_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_lug_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_kin_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_ewe_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_hau_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_vai_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_zul_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_fra_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_orm_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_sna_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_wol_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_ibo_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_swa_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_lin_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_vai_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_sot_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_eng_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_lug_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_kin_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_amh_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_orm_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_sot_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_ibo_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_ibo_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_cot_lug_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_cot_kin_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_cot_amh_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_cot_ewe_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_cot_vai_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_cot_zul_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_cot_fra_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_cot_sna_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_vai_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_wol_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_cot_swa_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_fra_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_hau_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_cot_xho_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_cot_twi_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_yor_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_vai_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_fra_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_kin_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_lug_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_zul_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_hau_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_orm_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_zul_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_orm_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_wol_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_swa_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_eng_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_ewe_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_amh_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_yor_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_twi_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_lin_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_sot_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_lug_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_yor_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_swa_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_lug_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_ibo_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_sna_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_orm_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_xho_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_hau_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_zul_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_vai_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_fra_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_kin_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_kin_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_xho_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_sna_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_swa_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_ibo_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_sna_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_xho_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_lin_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_hau_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_cot_tasks,755,false,Unknown,Unknown,false,3
afrimgsm_cot_tasks_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_cot_tasks_prompt_2,755,false,Unknown,Unknown,false,3
afrimgsm_cot_tasks_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_tasks_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot_tasks_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_tasks,755,false,Unknown,Unknown,false,3
afrimgsm_tasks_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_tasks_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_tasks_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_tasks_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_cot-irokobench,755,false,Unknown,Unknown,false,3
afrimgsm_fra_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_vai_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_zul_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_hau_prompt_4,755,false,Unknown,Unknown,false,3
afrimgsm_sot_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_cot_lin_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_wol_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_wol_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_eng_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_swa_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_wol_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_eng_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_sot_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_lin_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_twi_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_yor_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_amh_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_ewe_prompt_5,755,false,Unknown,Unknown,false,3
afrimgsm_amh_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_ibo_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_twi_prompt_3,755,false,Unknown,Unknown,false,3
afrimgsm_orm_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_kin_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_lug_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_ewe_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_amh_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_yor_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_twi_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_lin_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_sot_prompt_1,755,false,Unknown,Unknown,false,3
afrimgsm_eng_prompt_3,755,false,Unknown,Unknown,false,3
ethics_justice,731,true,EleutherAI/hendrycks_ethics,multiple_choice,false,3
hendrycks_ethics,731,false,Unknown,Unknown,false,3
ethics_utilitarianism,731,true,EleutherAI/hendrycks_ethics,multiple_choice,false,3
ethics_cm,731,true,EleutherAI/hendrycks_ethics,multiple_choice,false,3
ethics_virtue,731,true,EleutherAI/hendrycks_ethics,multiple_choice,false,3
ethics_deontology,731,true,EleutherAI/hendrycks_ethics,multiple_choice,false,3
tmmluplus_computer_science,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_three_principles_of_people,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_junior_chinese_exam,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_politic_science,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_education_(profession_level),713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_auditing,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_marketing_management,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_general_principles_of_law,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_optometry,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_trade,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_business_management,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_physics,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_junior_social_studies,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_technical,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_nautical_science,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_junior_science_exam,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_anti_money_laundering,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_fire_science,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_geography_of_taiwan,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_taiwanese_hokkien,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_engineering_math,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_organic_chemistry,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_educational_psychology,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_agriculture,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_occupational_therapy_for_psychological_disorders,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_trust_practice,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_veterinary_pharmacology,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_jce_humanities,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_pharmacy,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_linear_algebra,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_education,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_macroeconomics,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_official_document_management,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_dentistry,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_economics,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_human_behavior,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_junior_math_exam,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_music,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_taxation,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_logic_reasoning,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_traditional_chinese_medicine_clinical_medicine,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_tve_design,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_junior_chemistry,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_finance_banking,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_introduction_to_law,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_social_sciences_tasks,713,false,Unknown,Unknown,false,3
tmmluplus_humanities_tasks,713,false,Unknown,Unknown,false,3
tmmluplus_STEM_tasks,713,false,Unknown,Unknown,false,3
tmmluplus_other_tasks,713,false,Unknown,Unknown,false,3
tmmluplus,713,true,Unknown,Unknown,false,3
tmmluplus_humanities,713,true,Unknown,Unknown,false,3
tmmluplus_chinese_language_and_literature,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_national_protection,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_social_sciences,713,true,Unknown,Unknown,false,3
tmmluplus_pharmacology,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_basic_medical_science,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_other,713,true,Unknown,Unknown,false,3
tmmluplus_management_accounting,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_STEM,713,true,Unknown,Unknown,false,3
tmmluplus_tve_chinese_language,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_mechanical,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_statistics_and_machine_learning,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_insurance_studies,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_financial_analysis,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_physical_education,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_ttqav2,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_tve_natural_sciences,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_clinical_psychology,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_real_estate,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_accounting,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_veterinary_pathology,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_advance_chemistry,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_administrative_law,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_culinary_skills,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_tve_mathematics,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
tmmluplus_secondary_physics,713,true,ZoneTwelve/tmmluplus,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_moral_scenarios,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_mathematics,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_computer_security,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_european_history,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_management,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_professional_law,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_prehistory,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_professional_medicine,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_human_aging,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_geography,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_sociology,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_moral_disputes,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_college_computer_science,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_college_chemistry,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_machine_learning,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_professional_psychology,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_conceptual_physics,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_miscellaneous,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_world_history,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_computer_science,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_statistics,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_college_biology,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_government_and_politics,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_us_foreign_policy,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_psychology,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_macroeconomics,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_world_religions,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_security_studies,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_college_physics,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_logical_fallacies,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_human_sexuality,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_global_facts,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_philosophy,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_public_relations,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_microeconomics,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_chemistry,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_us_history,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_marketing,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_econometrics,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_physics,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_biology,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_business_ethics,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_clinical_knowledge,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_international_law,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_nutrition,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_elementary_mathematics,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_college_medicine,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_jurisprudence,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_professional_accounting,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_electrical_engineering,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_college_mathematics,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_formal_logic,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_abstract_algebra,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_astronomy,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_medical_genetics,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_anatomy,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_virology,679,true,OALL/Arabic_MMLU,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu,679,true,Unknown,Unknown,false,3
jsonschema_bench_easy,658,false,Unknown,Unknown,false,3
acp_reach_bool,658,false,Unknown,Unknown,false,3
acp_app_gen,658,false,Unknown,Unknown,false,3
acp_gen_2shot_with_pddl,658,false,Unknown,Unknown,false,3
acp_bench,658,false,Unknown,Unknown,false,3
acp_land_bool,658,false,Unknown,Unknown,false,3
acp_bool_cot_2shot,658,false,Unknown,Unknown,false,3
jsonschema_bench,658,false,Unknown,Unknown,false,3
acp_prog_bool,658,false,Unknown,Unknown,false,3
acp_val_gen,658,false,Unknown,Unknown,false,3
acp_app_bool,658,false,Unknown,Unknown,false,3
acp_just_bool,658,false,Unknown,Unknown,false,3
acp_reach_gen,658,false,Unknown,Unknown,false,3
acp_bench_hard,658,false,Unknown,Unknown,false,3
acp_just_gen,658,false,Unknown,Unknown,false,3
acp_nexta_gen,658,false,Unknown,Unknown,false,3
acp_areach_gen,658,false,Unknown,Unknown,false,3
acp_land_gen,658,false,Unknown,Unknown,false,3
acp_gen_2shot,658,false,Unknown,Unknown,false,3
jsonschema_bench_medium,658,false,Unknown,Unknown,false,3
acp_bench_hard_with_pddl,658,false,Unknown,Unknown,false,3
acp_app_mcq,658,false,Unknown,Unknown,false,3
acp_just_gen_with_pddl,658,false,Unknown,Unknown,false,3
acp_mcq_cot_2shot,658,false,Unknown,Unknown,false,3
acp_areach_mcq,658,false,Unknown,Unknown,false,3
acp_val_mcq,658,false,Unknown,Unknown,false,3
acp_land_mcq,658,false,Unknown,Unknown,false,3
acp_just_mcq,658,false,Unknown,Unknown,false,3
acp_reach_gen_with_pddl,658,false,Unknown,Unknown,false,3
acp_prog_mcq,658,false,Unknown,Unknown,false,3
acp_app_gen_with_pddl,658,false,Unknown,Unknown,false,3
acp_prog_gen_with_pddl,658,false,Unknown,Unknown,false,3
acp_land_gen_with_pddl,658,false,Unknown,Unknown,false,3
acp_prog_gen,658,false,Unknown,Unknown,false,3
acp_areach_bool,658,false,Unknown,Unknown,false,3
jsonschema_bench_hard,658,false,Unknown,Unknown,false,3
acp_nexta_gen_with_pddl,658,false,Unknown,Unknown,false,3
acp_reach_mcq,658,false,Unknown,Unknown,false,3
acp_val_bool,658,false,Unknown,Unknown,false,3
acp_val_gen_with_pddl,658,false,Unknown,Unknown,false,3
acp_areach_gen_with_pddl,658,false,Unknown,Unknown,false,3
arabic_leaderboard_acva_light,642,true,Unknown,Unknown,false,3
babi,633,true,Muennighoff/babi,generate_until,false,3
arabic_leaderboard_acva_Arabic_Calligraphy_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Islamic_law_system_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Algeria_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromAncientEgypt_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Wedding_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Somalia_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Culture_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arab_Empire_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Geography_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Lebanon_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Palestine_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Iraq_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_computer_and_phone_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Sudan_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Ornament_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Medicine_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Jordan_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Architecture_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Syria_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Language_Origin_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromByzantium_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Egypt_modern_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromPersia_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Oman_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Morocco_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_United_Arab_Emirates_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Comoros_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Islam_Education_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_entertainment_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Music_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Ancient_Egypt_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_daily_life_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_communication_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Libya_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Physics_and_Chemistry_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Mauritania_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Philosophy_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Mesopotamia_civilization_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromIslam_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Qatar_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromChina_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Ceremony_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_History_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Saudi_Arabia_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Kuwait_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Math_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Clothing_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Funeral_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Literature_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromGreece_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_InfluenceFromRome_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Islam_branches_and_schools_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Astronomy_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Food_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Arabic_Art_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Bahrain_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
arabic_leaderboard_acva_Tunisia_light,629,true,arcee-globe/ACVA-10percent,multiple_choice,false,3
AraDiCE_piqa_eng,604,true,QCRI/AraDiCE-PIQA,multiple_choice,false,3
AraDiCE_piqa_egy,604,true,QCRI/AraDiCE-PIQA,multiple_choice,false,3
AraDiCE_piqa_lev,604,true,QCRI/AraDiCE-PIQA,multiple_choice,false,3
AraDiCE_piqa_msa,604,true,QCRI/AraDiCE-PIQA,multiple_choice,false,3
afrimgsm-irokobench,604,false,Unknown,Unknown,false,3
AraDiCE_openbookqa_msa,603,true,QCRI/AraDiCE-OpenBookQA,multiple_choice,false,3
AraDiCE_openbookqa_eng,603,true,QCRI/AraDiCE-OpenBookQA,multiple_choice,false,3
AraDiCE_openbookqa_lev,603,true,QCRI/AraDiCE-OpenBookQA,multiple_choice,false,3
AraDiCE_openbookqa_egy,603,true,QCRI/AraDiCE-OpenBookQA,multiple_choice,false,3
csatqa,596,true,Unknown,Unknown,false,3
csatqa_li,596,true,HAERAE-HUB/csatqa,multiple_choice,false,3
csatqa_rcs,596,true,HAERAE-HUB/csatqa,multiple_choice,false,3
csatqa_rcss,596,true,HAERAE-HUB/csatqa,multiple_choice,false,3
csatqa_gr,596,true,HAERAE-HUB/csatqa,multiple_choice,false,3
csatqa_rch,596,true,HAERAE-HUB/csatqa,multiple_choice,false,3
csatqa_wr,596,true,HAERAE-HUB/csatqa,multiple_choice,false,3
logieval,580,true,baber/logiqa2,generate_until,false,3
logiqa2,580,true,baber/logiqa2,multiple_choice,false,3
assin_entailment,576,true,nilc-nlp/assin,multiple_choice,false,3
assin_paraphrase,576,true,nilc-nlp/assin,multiple_choice,false,3
AraDiCE,569,true,Unknown,Unknown,false,3
paloma_redpajama,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_c4_en,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_m2d2_s2orc_unsplit,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_m2d2_wikipedia_unsplit,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_c4_100_domains,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_4chan_meta_sep,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma,564,false,Unknown,Unknown,false,3
paloma_ptb,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_dolma-v1_5,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_twitterAAE_HELM_fixed,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_gab,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_dolma_100_subreddits,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_manosphere_meta_sep,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_mc4,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_falcon-refinedweb,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_dolma_100_programing_languages,564,true,allenai/paloma,loglikelihood_rolling,false,3
paloma_wikitext_103,564,true,allenai/paloma,loglikelihood_rolling,false,3
med_concepts_qa,549,true,Unknown,Unknown,false,3
med_concepts_qa_icd9cm_tasks,549,false,Unknown,Unknown,false,3
med_concepts_qa_icd10cm_medium,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_icd10proc_hard,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_atc_hard,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_icd10proc_easy,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_atc_easy,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_icd9cm_medium,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_icd10proc,549,true,Unknown,Unknown,false,3
med_concepts_qa_icd10cm,549,true,Unknown,Unknown,false,3
med_concepts_qa_icd9proc,549,true,Unknown,Unknown,false,3
med_concepts_qa_icd9cm,549,true,Unknown,Unknown,false,3
med_concepts_qa_atc_medium,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_atc,549,true,Unknown,Unknown,false,3
med_concepts_qa_icd10cm_tasks,549,false,Unknown,Unknown,false,3
med_concepts_qa_icd9proc_medium,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_icd10cm_easy,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_icd9cm_hard,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_icd10proc_medium,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_icd9proc_hard,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_icd9proc_easy,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_icd10cm_hard,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
med_concepts_qa_atc_tasks,549,false,Unknown,Unknown,false,3
med_concepts_qa_icd9proc_tasks,549,false,Unknown,Unknown,false,3
med_concepts_qa_icd10proc_tasks,549,false,Unknown,Unknown,false,3
med_concepts_qa_icd9cm_easy,549,true,ofir408/MedConceptsQA,multiple_choice,false,3
arc_challenge_mt_sv,548,true,LumiOpen/arc_challenge_mt,multiple_choice,false,3
arc_challenge_mt_pl,548,true,LumiOpen/arc_challenge_mt,multiple_choice,false,3
arc_challenge_mt_de,548,true,LumiOpen/arc_challenge_mt,multiple_choice,false,3
arc_challenge_mt_fi,548,true,LumiOpen/arc_challenge_mt,multiple_choice,false,3
arc_challenge_mt_pt,548,true,LumiOpen/arc_challenge_mt,multiple_choice,false,3
arc_challenge_mt_da,548,true,LumiOpen/arc_challenge_mt,multiple_choice,false,3
arc_challenge_mt_el,548,true,LumiOpen/arc_challenge_mt,multiple_choice,false,3
arc_challenge_mt_hu,548,true,LumiOpen/arc_challenge_mt,multiple_choice,false,3
arc_challenge_mt_it,548,true,LumiOpen/arc_challenge_mt,multiple_choice,false,3
arc_challenge_mt_nb,548,true,LumiOpen/arc_challenge_mt,multiple_choice,false,3
arc_challenge_mt_es,548,true,LumiOpen/arc_challenge_mt,multiple_choice,false,3
aclue_poetry_sentiment_analysis,543,true,tyouisen/aclue,multiple_choice,false,3
aclue_named_entity_recognition,543,true,tyouisen/aclue,multiple_choice,false,3
aclue_basic_ancient_chinese,543,true,tyouisen/aclue,multiple_choice,false,3
aclue_ancient_literature,543,true,tyouisen/aclue,multiple_choice,false,3
aclue_polysemy_resolution,543,true,tyouisen/aclue,multiple_choice,false,3
aclue_couplet_prediction,543,true,tyouisen/aclue,multiple_choice,false,3
aclue_poetry_appreciate,543,true,tyouisen/aclue,multiple_choice,false,3
aclue,543,true,Unknown,Unknown,false,3
aclue_poetry_context_prediction,543,true,tyouisen/aclue,multiple_choice,false,3
aclue_ancient_medical,543,true,tyouisen/aclue,multiple_choice,false,3
aclue_ancient_phonetics,543,true,tyouisen/aclue,multiple_choice,false,3
aclue_homographic_character_resolution,543,true,tyouisen/aclue,multiple_choice,false,3
aclue_ancient_chinese_culture,543,true,tyouisen/aclue,multiple_choice,false,3
aclue_sentence_segmentation,543,true,tyouisen/aclue,multiple_choice,false,3
aclue_reading_comprehension,543,true,tyouisen/aclue,multiple_choice,false,3
aclue_poetry_quality_assessment,543,true,tyouisen/aclue,multiple_choice,false,3
AraDiCE_boolq_eng,530,true,QCRI/AraDiCE-BoolQ,multiple_choice,false,3
AraDiCE_boolq_msa,530,true,QCRI/AraDiCE-BoolQ,multiple_choice,false,3
AraDiCE_boolq_lev,530,true,QCRI/AraDiCE-BoolQ,multiple_choice,false,3
AraDiCE_boolq_egy,530,true,QCRI/AraDiCE-BoolQ,multiple_choice,false,3
AraDiCE_palestine_cultural,522,true,QCRI/AraDiCE-Culture,multiple_choice,false,3
AraDiCE_egypt_cultural,522,true,QCRI/AraDiCE-Culture,multiple_choice,false,3
AraDiCE_jordan_cultural,522,true,QCRI/AraDiCE-Culture,multiple_choice,false,3
AraDiCE_lebanon_cultural,522,true,QCRI/AraDiCE-Culture,multiple_choice,false,3
AraDiCE_syria_cultural,522,true,QCRI/AraDiCE-Culture,multiple_choice,false,3
AraDiCE_qatar_cultural,522,true,QCRI/AraDiCE-Culture,multiple_choice,false,3
AraDiCE_truthfulqa_mc1_lev,517,true,QCRI/AraDiCE-TruthfulQA,multiple_choice,false,3
AraDiCE_truthfulqa_mc1_eng,517,true,QCRI/AraDiCE-TruthfulQA,multiple_choice,false,3
AraDiCE_truthfulqa_mc1_msa,517,true,QCRI/AraDiCE-TruthfulQA,multiple_choice,false,3
AraDiCE_truthfulqa_mc1_egy,517,true,QCRI/AraDiCE-TruthfulQA,multiple_choice,false,3
salt_eng-ach_prompt_1,514,false,Unknown,Unknown,false,3
salt_eng-nyn_prompt_3,514,false,Unknown,Unknown,false,3
salt_ibo-eng_prompt_1,514,false,Unknown,Unknown,false,3
salt_ach-eng_prompt_1,514,false,Unknown,Unknown,false,3
salt_lug-eng_prompt_1,514,false,Unknown,Unknown,false,3
salt_eng-ibo_prompt_3,514,false,Unknown,Unknown,false,3
salt_lgg-eng_prompt_1,514,false,Unknown,Unknown,false,3
salt_swa-eng_prompt_1,514,false,Unknown,Unknown,false,3
salt_eng-lgg_prompt_1,514,false,Unknown,Unknown,false,3
salt_eng-swa_prompt_3,514,false,Unknown,Unknown,false,3
salt_eng-swa_prompt_1,514,false,Unknown,Unknown,false,3
salt_swa-eng_prompt_3,514,false,Unknown,Unknown,false,3
salt_eng-nyn_prompt_1,514,false,Unknown,Unknown,false,3
salt_teo-eng_prompt_1,514,false,Unknown,Unknown,false,3
salt_eng-teo_prompt_1,514,false,Unknown,Unknown,false,3
salt_eng-lug_prompt_1,514,false,Unknown,Unknown,false,3
salt_nyn-eng_prompt_1,514,false,Unknown,Unknown,false,3
salt_lgg-eng_prompt_3,514,false,Unknown,Unknown,false,3
salt_ibo-eng_prompt_3,514,false,Unknown,Unknown,false,3
salt_ach-eng_prompt_3,514,false,Unknown,Unknown,false,3
salt_lug-eng_prompt_3,514,false,Unknown,Unknown,false,3
salt_eng-ach_prompt_3,514,false,Unknown,Unknown,false,3
salt_lug-eng_prompt_2,514,false,Unknown,Unknown,false,3
salt_eng-ibo_prompt_1,514,false,Unknown,Unknown,false,3
salt_tasks,514,false,Unknown,Unknown,false,3
salt_eng-teo_prompt_3,514,false,Unknown,Unknown,false,3
salt_prompt_2,514,false,Unknown,Unknown,false,3
salt_ibo-eng_prompt_2,514,false,Unknown,Unknown,false,3
salt_ach-eng_prompt_2,514,false,Unknown,Unknown,false,3
salt_eng-ach_prompt_2,514,false,Unknown,Unknown,false,3
salt_lgg-eng_prompt_2,514,false,Unknown,Unknown,false,3
salt_swa-eng_prompt_2,514,false,Unknown,Unknown,false,3
salt,514,false,Unknown,Unknown,false,3
salt_eng-swa_prompt_2,514,false,Unknown,Unknown,false,3
salt_nyn-eng_prompt_3,514,false,Unknown,Unknown,false,3
salt_eng-lug_prompt_3,514,false,Unknown,Unknown,false,3
salt_teo-eng_prompt_3,514,false,Unknown,Unknown,false,3
salt_eng-ibo_prompt_2,514,false,Unknown,Unknown,false,3
salt_eng-lug_prompt_2,514,false,Unknown,Unknown,false,3
salt_eng-lgg_prompt_2,514,false,Unknown,Unknown,false,3
salt_eng-nyn_prompt_2,514,false,Unknown,Unknown,false,3
salt_teo-eng_prompt_2,514,false,Unknown,Unknown,false,3
salt_eng-teo_prompt_2,514,false,Unknown,Unknown,false,3
salt_eng-lgg_prompt_3,514,false,Unknown,Unknown,false,3
salt_nyn-eng_prompt_2,514,false,Unknown,Unknown,false,3
salt_prompt_1,514,false,Unknown,Unknown,false,3
salt_prompt_3,514,false,Unknown,Unknown,false,3
AraDiCE_winogrande_eng,505,true,QCRI/AraDiCE-WinoGrande,multiple_choice,false,3
AraDiCE_winogrande_msa,505,true,QCRI/AraDiCE-WinoGrande,multiple_choice,false,3
AraDiCE_winogrande_egy,505,true,QCRI/AraDiCE-WinoGrande,multiple_choice,false,3
AraDiCE_winogrande_lev,505,true,QCRI/AraDiCE-WinoGrande,multiple_choice,false,3
aexams_Biology,468,true,Hennara/aexams,multiple_choice,false,3
aexams_Science,468,true,Hennara/aexams,multiple_choice,false,3
aexams_IslamicStudies,468,true,Hennara/aexams,multiple_choice,false,3
aexams_Social,468,true,Hennara/aexams,multiple_choice,false,3
aexams_Physics,468,true,Hennara/aexams,multiple_choice,false,3
aexams,468,true,Unknown,Unknown,false,3
meddialog_raw_perplexity,437,false,Unknown,Unknown,false,3
meddialog,437,false,Unknown,Unknown,false,3
meddialog_raw_dialogues,437,false,Unknown,Unknown,false,3
meddialog_qsumm,437,false,Unknown,Unknown,false,3
meddialog_qsumm_perplexity,437,false,Unknown,Unknown,false,3
bertaqa_en_mt_madlad,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_eu,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_en_mt_llama-2-13b,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_en_mt_llama-2-7b,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_en_mt_latxa-70b-v1.1,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_en_mt_latxa-7b-v1.1,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_en_mt_latxa-70b-v1,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_en_mt_llama-2-70b,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_en_mt_nllb,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_en_mt_latxa-7b-v1,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_en_mt_hitz,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa,434,false,Unknown,Unknown,false,3
bertaqa_en_mt_gemma-7b,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_en_mt_itzuli,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_en,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_en_mt_latxa-13b-v1.1,434,true,HiTZ/BertaQA,multiple_choice,false,3
bertaqa_en_mt_latxa-13b-v1,434,true,HiTZ/BertaQA,multiple_choice,false,3
afrixnli_native_direct_sna,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_manual_direct_yor,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_kin_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_ewe_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_kin_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_yor_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_tasks_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_manual_direct_amh,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_manual_direct_lug,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_manual_direct_sot,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_manual_direct_lin,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_manual_direct_eng,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_eng_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_manual_direct_kin,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_swa,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_manual_direct_xho,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_wol,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_lug_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_hau_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_lin_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_sot_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_amh_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_lug_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_kin_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_ewe_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_amh_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_zul_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_fra_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_wol_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_ibo_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_swa_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_orm_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_sna_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_xho_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_twi_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_yor_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_native_direct_orm,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct,432,false,Unknown,Unknown,false,3
afrixnli_en_direct_twi,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_en_direct_kin,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_hau,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_en_direct_fra,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_en_direct_zul,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_en_direct_ewe,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_en_direct_amh,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_en_direct_eng,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_fra_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_en_direct_lug,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_en_direct_yor,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_en_direct,432,false,Unknown,Unknown,false,3
afrixnli_native_direct_eng,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_tasks_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_tasks_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_tasks_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_tasks,432,false,Unknown,Unknown,false,3
afrixnli_tasks_prompt_4,432,false,Unknown,Unknown,false,3
afrixnli_manual_direct_ibo,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_manual_direct_wol,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_manual_direct_sna,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_manual_direct_orm,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_xho,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_manual_direct_twi,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_manual_direct_hau,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_ibo,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_kin,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_yor,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_twi,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_lin,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_sot,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_amh,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_ewe,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_lug,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_manual_direct_swa,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_fra,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_native_direct_zul,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_zul_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_lin_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_wol_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_wol_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_orm_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_manual_direct_fra,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_xho_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_hau_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_twi_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_swa_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_ibo_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_fra_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_ibo_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_ewe_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_amh_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_zul_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_fra_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_wol_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_ibo_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_swa_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_swa_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_wol_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_sna_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_twi_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_eng_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_ibo_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_ewe_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_orm_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_sna_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_xho_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_hau_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_sot_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_fra_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_lin_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_eng_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_lug_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_kin_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_amh_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_sot_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_zul_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_orm_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_sna_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_xho_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_sna_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_en_direct_lin,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_hau_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_en_direct_hau,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_twi_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_manual_direct_ewe,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_sot_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_eng_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_en_direct_xho,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_en_direct_orm,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_en_direct_sna,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_en_direct_wol,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_en_direct_ibo,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_en_direct_swa,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_hau_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_manual_direct_zul,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_xho_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli-irokobench,432,false,Unknown,Unknown,false,3
afrixnli_orm_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_ewe_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_yor_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_sot_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_lin_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_eng_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_lug_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_kin_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_swa_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_amh_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_zul_prompt_2,432,false,Unknown,Unknown,false,3
afrixnli_yor_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_lin_prompt_3,432,false,Unknown,Unknown,false,3
afrixnli_lug_prompt_5,432,false,Unknown,Unknown,false,3
afrixnli_yor_prompt_1,432,false,Unknown,Unknown,false,3
afrixnli_en_direct_sot,432,true,masakhane/afrixnli,multiple_choice,false,3
afrixnli_twi_prompt_5,432,false,Unknown,Unknown,false,3
mts_dialog_perplexity,399,false,Unknown,Unknown,false,3
mts_dialog,399,false,Unknown,Unknown,false,3
eus_exams_eu_opeosakivarioseu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeehuauxeu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_osakidetza2c,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeosakicelador,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeehuaux,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeosakijuridico,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeehuempresariales,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeosakivarios,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeosakiadmineu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opebilbaoeu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_osakidetza6c,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeosakiceladoreu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_osakidetza3c,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeehusubalternoeu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_ejtecnico,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeosakiaux,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeosakioperario,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeehutecnico,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_ejlaguntza,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opegasteizkoudala,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeosakiauxenfeu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_osakidetza9c,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opebilbao,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeosakiauxenf,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeosakienf,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_ejadministrativo,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_osakidetza8c,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_osakidetza1e,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeehubiblio,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeehuempresarialeseu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeosakitecnico,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_osakidetza6e,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeehueconomicaseu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeayuntamientovitoria,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeehusubalterno,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_ejsubalterno,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeehubiblioeu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_osakidetza3e,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_osakidetza5e,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeehuderechoeu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_osakidetza7e,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_ejauxiliar,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_osakidetza1c,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_osakidetza5c,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeehuderecho,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeehuadmineu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_ejteknikari,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_ejlaguntzaile,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeosakienfeu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeehutecnicob,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeosakiauxeu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu,374,false,Unknown,Unknown,false,3
eus_exams_es_osakidetza4c,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_osakidetza2e,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeosakiadmin,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_ejadministrari,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeosakioperarioeu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_opeehuadmin,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeehutecnicoeu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es_osakidetza7c,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_es,374,false,Unknown,Unknown,false,3
eus_exams_es_opeehueconomicas,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeosakitecnicoeu,374,true,HiTZ/EusExams,multiple_choice,false,3
eus_exams_eu_opeehuteknikarib,374,true,HiTZ/EusExams,multiple_choice,false,3
polemo2_in,355,true,allegro/klej-polemo2-in,generate_until,false,3
polemo2_out,355,true,allegro/klej-polemo2-in,generate_until,false,3
polemo2,355,false,Unknown,Unknown,false,3
afrixnli,353,false,Unknown,Unknown,false,3
afrixnli_manual_direct,332,false,Unknown,Unknown,false,3
trasnlation_en_dr_seed,322,false,Unknown,Unknown,false,3
darija_translation_flores,322,false,Unknown,Unknown,false,3
darija_translation_doda,322,false,Unknown,Unknown,false,3
darija_translation_madar,322,false,Unknown,Unknown,false,3
darija_translation_seed,322,false,Unknown,Unknown,false,3
darija_summarization,322,false,Unknown,Unknown,false,3
darija_translation_tasks_flores,322,false,Unknown,Unknown,false,3
trasnlation_msa_dr_flores,322,false,Unknown,Unknown,false,3
trasnlation_all_madar,322,false,Unknown,Unknown,false,3
trasnlation_all_doda,322,false,Unknown,Unknown,false,3
trasnlation_dr_fr_flores,322,false,Unknown,Unknown,false,3
trasnlation_dr_en_seed,322,false,Unknown,Unknown,false,3
trasnlation_dr_msa_madar,322,false,Unknown,Unknown,false,3
trasnlation_all_seed,322,false,Unknown,Unknown,false,3
trasnlation_en_dr_doda,322,false,Unknown,Unknown,false,3
trasnlation_dr_fr_doda,322,false,Unknown,Unknown,false,3
trasnlation_all_flores,322,false,Unknown,Unknown,false,3
trasnlation_msa_dr_doda,322,false,Unknown,Unknown,false,3
trasnlation_en_dr_flores,322,false,Unknown,Unknown,false,3
darija_sentiment,322,false,Unknown,Unknown,false,3
darija_translation,322,false,Unknown,Unknown,false,3
darija_translation_tasks_madar,322,false,Unknown,Unknown,false,3
darija_transliteration,322,false,Unknown,Unknown,false,3
transliteration_dr_ar,322,false,Unknown,Unknown,false,3
trasnlation_dr_en_doda,322,false,Unknown,Unknown,false,3
darija_sentiment_electrom,322,false,Unknown,Unknown,false,3
trasnlation_msa_dr_madar,322,false,Unknown,Unknown,false,3
trasnlation_dr_en_flores,322,false,Unknown,Unknown,false,3
darija_sentiment_mac,322,false,Unknown,Unknown,false,3
darija_sentiment_msac,322,false,Unknown,Unknown,false,3
darija_sentiment_myc,322,false,Unknown,Unknown,false,3
darija_translation_tasks_doda,322,false,Unknown,Unknown,false,3
darija_sentiment_msda,322,false,Unknown,Unknown,false,3
transliteration_all,322,false,Unknown,Unknown,false,3
transliteration_ar_dr,322,false,Unknown,Unknown,false,3
darija_translation_tasks_seed,322,false,Unknown,Unknown,false,3
trasnlation_fr_dr_flores,322,false,Unknown,Unknown,false,3
trasnlation_dr_msa_flores,322,false,Unknown,Unknown,false,3
trasnlation_dr_msa_doda,322,false,Unknown,Unknown,false,3
trasnlation_fr_dr_doda,322,false,Unknown,Unknown,false,3
darija_summarization_task,322,false,Unknown,Unknown,false,3
darija_sentiment_tasks,322,false,Unknown,Unknown,false,3
darija_transliteration_tasks,322,false,Unknown,Unknown,false,3
mc_taco,309,true,mc_taco,multiple_choice,false,3
copa_es,305,true,BSC-LT/COPA-es,multiple_choice,false,3
mela_de,300,true,Geralt-Targaryen/MELA,multiple_choice,false,3
mela_it,300,true,Geralt-Targaryen/MELA,multiple_choice,false,3
mela,300,true,Unknown,Unknown,false,3
mela_ru,300,true,Geralt-Targaryen/MELA,multiple_choice,false,3
mela_en,300,true,Geralt-Targaryen/MELA,multiple_choice,false,3
mela_zh,300,true,Geralt-Targaryen/MELA,multiple_choice,false,3
mela_ja,300,true,Geralt-Targaryen/MELA,multiple_choice,false,3
mela_es,300,true,Geralt-Targaryen/MELA,multiple_choice,false,3
mela_fr,300,true,Geralt-Targaryen/MELA,multiple_choice,false,3
mela_is,300,true,Geralt-Targaryen/MELA,multiple_choice,false,3
mela_ar,300,true,Geralt-Targaryen/MELA,multiple_choice,false,3
afrisenti_hau_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_pcm_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_hau_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_tso_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_tir_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_swa_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_arq_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_amh_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_yor_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_twi_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_ibo_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_orm_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_ary_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_pcm_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_swa_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_ibo_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_swa_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_por_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_ibo_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_pcm_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_por_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_arq_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_kin_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_tir_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_tso_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_amh_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_twi_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_amh_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_yor_prompt_2,297,false,Unknown,Unknown,false,3
afrisenti_kin_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_hau_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_arq_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_tir_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_tso_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_por_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_pcm_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_ary_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_kin_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_twi_prompt_2,297,false,Unknown,Unknown,false,3
afrisent_prompt_2,297,false,Unknown,Unknown,false,3
afrisenti_hau_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_twi_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_por_prompt_2,297,false,Unknown,Unknown,false,3
afrisenti_amh_prompt_2,297,false,Unknown,Unknown,false,3
afrisenti_swa_prompt_2,297,false,Unknown,Unknown,false,3
afrisenti_por_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_orm_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_arq_prompt_2,297,false,Unknown,Unknown,false,3
afrisenti_orm_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_tir_prompt_2,297,false,Unknown,Unknown,false,3
afrisenti_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_tso_prompt_2,297,false,Unknown,Unknown,false,3
afrisenti_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_prompt_1,297,false,Unknown,Unknown,false,3
afrisenti_hau_prompt_2,297,false,Unknown,Unknown,false,3
afrisenti_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_yor_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_kin_prompt_2,297,false,Unknown,Unknown,false,3
afrisenti_ary_prompt_5,297,false,Unknown,Unknown,false,3
afrisenti_yor_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_pcm_prompt_2,297,false,Unknown,Unknown,false,3
afrisenti_yor_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_orm_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_ary_prompt_2,297,false,Unknown,Unknown,false,3
afrisenti_ary_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_arq_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_tir_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_amh_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_twi_prompt_4,297,false,Unknown,Unknown,false,3
afrisenti_ibo_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_tso_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_swa_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_kin_prompt_3,297,false,Unknown,Unknown,false,3
afrisenti_ibo_prompt_2,297,false,Unknown,Unknown,false,3
afrisenti_orm_prompt_2,297,false,Unknown,Unknown,false,3
simple_cooccurrence_bias,295,false,Unknown,Unknown,false,3
simple_cooccurrence_bias_gen,295,false,Unknown,Unknown,false,3
medtext,285,false,Unknown,Unknown,false,3
medtext_perplexity,285,false,Unknown,Unknown,false,3
french_bench_wikitext_fr,280,true,asi/wikitext_fr,loglikelihood_rolling,false,3
norquad_p3,271,false,Unknown,Unknown,false,3
norquad_p4,271,false,Unknown,Unknown,false,3
norquad_p2,271,false,Unknown,Unknown,false,3
norquad_p0,271,false,Unknown,Unknown,false,3
norquad_p1,271,false,Unknown,Unknown,false,3
norquad,271,false,Unknown,Unknown,false,3
lambada_openai_mt_stablelm_it,259,true,marcob/lambada_multilingual,loglikelihood,false,3
lambada_openai_mt_stablelm_en,259,true,marcob/lambada_multilingual,loglikelihood,false,3
lambada_openai_mt_stablelm_fr,259,true,marcob/lambada_multilingual,loglikelihood,false,3
lambada_openai_mt_stablelm_de,259,true,marcob/lambada_multilingual,loglikelihood,false,3
lambada_openai_mt_stablelm_es,259,true,marcob/lambada_multilingual,loglikelihood,false,3
lambada_openai_mt_stablelm_pt,259,true,marcob/lambada_multilingual,loglikelihood,false,3
lambada_openai_mt_stablelm_nl,259,true,marcob/lambada_multilingual,loglikelihood,false,3
lambada_multilingual_stablelm,259,false,Unknown,Unknown,false,3
french_bench_fquadv2,257,true,manu/fquad2_test,generate_until,false,3
french_bench_fquadv2_genq,257,true,manu/fquad2_test,generate_until,false,3
french_bench_fquadv2_bool,257,true,manu/fquad2_test,multiple_choice,false,3
french_bench_fquadv2_hasAns,257,true,manu/fquad2_test,generate_until,false,3
prost,248,true,corypaik/prost,multiple_choice,false,3
turkishmmlu_cot_history,245,true,AYueksel/TurkishMMLU,generate_until,false,3
turkishmmlu_cot_geography,245,true,AYueksel/TurkishMMLU,generate_until,false,3
turkishmmlu_cot,245,false,Unknown,Unknown,false,3
turkishmmlu,245,false,Unknown,Unknown,false,3
turkishmmlu_cot_mathematics,245,true,AYueksel/TurkishMMLU,generate_until,false,3
turkishmmlu_cot_religion_and_ethics,245,true,AYueksel/TurkishMMLU,generate_until,false,3
turkishmmlu_cot_biology,245,true,AYueksel/TurkishMMLU,generate_until,false,3
turkishmmlu_cot_physics,245,true,AYueksel/TurkishMMLU,generate_until,false,3
turkishmmlu_cot_chemistry,245,true,AYueksel/TurkishMMLU,generate_until,false,3
turkishmmlu_cot_turkish_language_and_literature,245,true,AYueksel/TurkishMMLU,generate_until,false,3
turkishmmlu_history,245,true,AYueksel/TurkishMMLU,multiple_choice,false,3
turkishmmlu_philosophy,245,true,AYueksel/TurkishMMLU,multiple_choice,false,3
turkishmmlu_cot_philosophy,245,true,AYueksel/TurkishMMLU,generate_until,false,3
turkishmmlu_chemistry,245,true,AYueksel/TurkishMMLU,multiple_choice,false,3
turkishmmlu_physics,245,true,AYueksel/TurkishMMLU,multiple_choice,false,3
turkishmmlu_geography,245,true,AYueksel/TurkishMMLU,multiple_choice,false,3
turkishmmlu_biology,245,true,AYueksel/TurkishMMLU,multiple_choice,false,3
turkishmmlu_turkish_language_and_literature,245,true,AYueksel/TurkishMMLU,multiple_choice,false,3
turkishmmlu_religion_and_ethics,245,true,AYueksel/TurkishMMLU,multiple_choice,false,3
turkishmmlu_mathematics,245,true,AYueksel/TurkishMMLU,multiple_choice,false,3
piqa_eu,244,true,HiTZ/PIQA-eu,multiple_choice,false,3
afrisenti,237,false,Unknown,Unknown,false,3
headqa,236,false,Unknown,Unknown,false,3
headqa_es,236,true,EleutherAI/headqa,multiple_choice,false,3
headqa_en,236,true,EleutherAI/headqa,multiple_choice,false,3
eq_bench,232,true,pbevan11/EQ-Bench,generate_until,false,3
bhtc_v2,230,true,orai-nlp/basqueGLUE,multiple_choice,false,3
bec2016eu,230,true,orai-nlp/basqueGLUE,multiple_choice,false,3
wiceu,230,true,orai-nlp/basqueGLUE,multiple_choice,false,3
epec_koref_bin,230,true,orai-nlp/basqueGLUE,multiple_choice,false,3
vaxx_stance,230,true,orai-nlp/basqueGLUE,multiple_choice,false,3
basque-glue,230,false,Unknown,Unknown,false,3
afrobench_sentiment_tasks,230,false,Unknown,Unknown,false,3
qnlieu,230,true,orai-nlp/basqueGLUE,multiple_choice,false,3
afrixnli_translate_yor,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
metabench_mmlu_secondary,228,true,HCAI/metabench,multiple_choice,false,3
afrixnli_manual_translate_yor,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_orm,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_ewe,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_amh,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_lin,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_sot,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_swa,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_twi,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_manual_translate_lug,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_ibo,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_wol,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_sna,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_lug,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_kin,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_fra,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
metabench_hellaswag_secondary,228,true,HCAI/metabench,multiple_choice,false,3
metabench_hellaswag_secondary_permute,228,true,HCAI/metabench,multiple_choice,false,3
afrixnli_manual_translate_amh,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
metabench_arc_secondary_permute,228,true,HCAI/metabench,multiple_choice,false,3
afrixnli_translate_twi_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_swa_prompt_4,228,false,Unknown,Unknown,false,3
metabench_gsm8k_secondary,228,true,HCAI/metabench,generate_until,false,3
afrixnli_translate_xho,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_twi_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_translate_hau,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
metabench_gsm8k,228,true,HCAI/metabench,generate_until,false,3
metabench_mmlu_permute,228,true,HCAI/metabench,multiple_choice,false,3
metabench_truthfulqa,228,true,HCAI/metabench,multiple_choice,false,3
afrixnli_translate_zul_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_fra_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_manual_translate_fra,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_manual_translate_zul,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
metabench_truthfulqa_secondary_permute,228,true,HCAI/metabench,multiple_choice,false,3
afrixnli_manual_translate_ewe,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_zul,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_lug_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_manual_translate_kin,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_kin_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_ewe_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_manual_translate_wol,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_manual_translate_lin,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_yor_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_translate_sot_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_manual_translate_sot,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_manual_translate_xho,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_manual_translate_hau,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
metabench_winogrande_secondary,228,true,HCAI/metabench,multiple_choice,false,3
afrixnli_manual_translate_swa,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_manual_translate_ibo,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_manual_translate_orm,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_manual_translate_sna,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_lin_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_translate_amh_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_translate_lin_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_wol_prompt_5,228,false,Unknown,Unknown,false,3
afrixnli_translate_ewe_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_sot_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_yor_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_manual_translate_twi,228,true,masakhane/afrixnli-translate-test,multiple_choice,false,3
afrixnli_translate_lug_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_amh_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_kin_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_translate_fra_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_translate_zul_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_translate_hau_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_xho_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_orm_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_sna_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_wol_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_ibo_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_swa_prompt_1,228,false,Unknown,Unknown,false,3
afrixnli_translate_twi_prompt_1,228,false,Unknown,Unknown,false,3
metabench_hellaswag_permute,228,true,HCAI/metabench,multiple_choice,false,3
metabench_hellaswag_subset,228,false,Unknown,Unknown,false,3
afrixnli_translate_wol_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_translate_ibo_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_translate_amh_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_xho_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_translate_hau_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_translate_zul_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_fra_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_kin_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_ewe_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_sna_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_lin_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_sna_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_translate_sot_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_yor_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_tt_tasks,228,false,Unknown,Unknown,false,3
afrixnli_translate_swa_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_ibo_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_wol_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_orm_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_orm_prompt_4,228,false,Unknown,Unknown,false,3
afrixnli_translate,228,false,Unknown,Unknown,false,3
metabench_secondary_permute,228,true,Unknown,Unknown,false,3
metabench_arc_secondary,228,true,HCAI/metabench,multiple_choice,false,3
metabench_winogrande_permute,228,true,HCAI/metabench,multiple_choice,false,3
afrixnli_translate_zul_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_fra_prompt_2,228,false,Unknown,Unknown,false,3
metabench_hellaswag,228,true,HCAI/metabench,multiple_choice,false,3
metabench_winogrande_secondary_permute,228,true,HCAI/metabench,multiple_choice,false,3
metabench_mmlu,228,true,HCAI/metabench,multiple_choice,false,3
metabench_arc_permute,228,true,HCAI/metabench,multiple_choice,false,3
metabench_mmlu_secondary_permute,228,true,HCAI/metabench,multiple_choice,false,3
afrixnli_translate_lug_prompt_3,228,false,Unknown,Unknown,false,3
metabench_truthfulqa_permute,228,true,HCAI/metabench,multiple_choice,false,3
afrixnli_translate_hau_prompt_3,228,false,Unknown,Unknown,false,3
metabench_truthfulqa_secondary,228,true,HCAI/metabench,multiple_choice,false,3
metabench_arc,228,true,HCAI/metabench,multiple_choice,false,3
metabench_winogrande,228,true,HCAI/metabench,multiple_choice,false,3
afrixnli_translate_ibo_prompt_5,228,false,Unknown,Unknown,false,3
afrixnli_translate_sna_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_kin_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_xho_prompt_3,228,false,Unknown,Unknown,false,3
afrixnli_translate_ewe_prompt_5,228,false,Unknown,Unknown,false,3
afrixnli_translate_twi_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_lug_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_xho_prompt_5,228,false,Unknown,Unknown,false,3
afrixnli_translate_ewe_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_amh_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_lin_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_sot_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_yor_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_swa_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_orm_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_orm_prompt_5,228,false,Unknown,Unknown,false,3
metabench_truthfulqa_subset,228,false,Unknown,Unknown,false,3
afrixnli_translate_sna_prompt_5,228,false,Unknown,Unknown,false,3
afrixnli_translate_ibo_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_wol_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_tt-irokobench,228,false,Unknown,Unknown,false,3
metabench_gsm8k_subset,228,false,Unknown,Unknown,false,3
metabench_winogrande_subset,228,false,Unknown,Unknown,false,3
afrixnli_translate_hau_prompt_5,228,false,Unknown,Unknown,false,3
metabench,228,true,Unknown,Unknown,false,3
afrixnli_translate_amh_prompt_5,228,false,Unknown,Unknown,false,3
metabench_arc_subset,228,false,Unknown,Unknown,false,3
metabench_secondary,228,true,Unknown,Unknown,false,3
afrixnli_translate_xho_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_hau_prompt_2,228,false,Unknown,Unknown,false,3
afrixnli_translate_fra_prompt_5,228,false,Unknown,Unknown,false,3
afrixnli_translate_kin_prompt_5,228,false,Unknown,Unknown,false,3
afrixnli_translate_lug_prompt_5,228,false,Unknown,Unknown,false,3
afrixnli_translate_zul_prompt_5,228,false,Unknown,Unknown,false,3
afrixnli_translate_lin_prompt_5,228,false,Unknown,Unknown,false,3
afrixnli_translate_sot_prompt_5,228,false,Unknown,Unknown,false,3
afrixnli_translate_yor_prompt_5,228,false,Unknown,Unknown,false,3
afrixnli_translate_twi_prompt_5,228,false,Unknown,Unknown,false,3
metabench_mmlu_subset,228,false,Unknown,Unknown,false,3
afrixnli_translate_swa_prompt_5,228,false,Unknown,Unknown,false,3
metabench_permute,228,true,Unknown,Unknown,false,3
darijahellaswag,226,false,Unknown,Unknown,false,3
injongointent_hau_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_orm_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_kin_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_sna_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_eng_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_swa_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_ibo_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_wol_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_eng_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_orm_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_twi_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_yor_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_lin_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_swa_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_ibo_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_sna_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_sot_prompt_2,220,false,Unknown,Unknown,false,3
injongointent,220,false,Unknown,Unknown,false,3
injongointent_yor_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_eng_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_zul_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_xho_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_lug_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_ibo_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_sna_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_wol_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_tasks,220,false,Unknown,Unknown,false,3
injongointent_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_hau_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_sot_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_swa_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_amh_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_wol_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_hau_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_xho_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_zul_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_lug_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_amh_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_ewe_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_ewe_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_sna_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_orm_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_ewe_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_ibo_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_kin_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_sna_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_orm_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_eng_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_yor_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_orm_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_lin_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_sot_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_swa_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_amh_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_lug_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_swa_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_lin_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_zul_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_xho_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_sot_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_lin_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_xho_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_twi_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_yor_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_eng_prompt_3,220,false,Unknown,Unknown,false,3
injongointent_ibo_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_twi_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_wol_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_twi_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_wol_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_hau_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_xho_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_hau_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_lug_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_kin_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_amh_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_ewe_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_lin_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_zul_prompt_2,220,false,Unknown,Unknown,false,3
injongointent_yor_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_kin_prompt_5,220,false,Unknown,Unknown,false,3
injongointent_sot_prompt_1,220,false,Unknown,Unknown,false,3
injongointent_ewe_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_amh_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_kin_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_lug_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_zul_prompt_4,220,false,Unknown,Unknown,false,3
injongointent_twi_prompt_1,220,false,Unknown,Unknown,false,3
french_bench_reading_comp,217,true,manu/french-bench-grammar-vocab-reading,multiple_choice,false,3
french_bench_grammar,217,true,manu/french-bench-grammar-vocab-reading,multiple_choice,false,3
french_bench_vocab,217,true,manu/french-bench-grammar-vocab-reading,multiple_choice,false,3
code2text_javascript,216,true,CM/codexglue_code2text_javascript,generate_until,false,3
code2text_java,216,true,CM/codexglue_code2text_java,generate_until,false,3
ja_leaderboard_xwinograd,211,true,polm-stability/xwinograd-ja,multiple_choice,false,3
ja_leaderboard_xlsum,203,true,mkshing/xlsum_ja,generate_until,false,3
ja_leaderboard_jnli,199,true,Rakuten/JGLUE,multiple_choice,false,3
ja_leaderboard_jsquad,199,true,Rakuten/JGLUE,generate_until,false,3
ja_leaderboard_jcommonsenseqa,199,true,Rakuten/JGLUE,multiple_choice,false,3
ja_leaderboard_marc_ja,199,true,Rakuten/JGLUE,multiple_choice,false,3
ja_leaderboard_jaqket_v2,197,true,kumapo/JAQKET,generate_until,false,3
mediqa_qa2019_perplexity,192,false,Unknown,Unknown,false,3
mediqa_qa2019,192,false,Unknown,Unknown,false,3
mgsm_direct_ca,191,true,projecte-aina/mgsm_ca,generate_until,false,3
copal_id_standard,189,true,haryoaw/COPAL,multiple_choice,false,3
copal_id_colloquial,189,true,haryoaw/COPAL,multiple_choice,false,3
copal_id,189,false,Unknown,Unknown,false,3
french_bench_mc,187,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_sna_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_ibo_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_wol_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_hau_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_xho_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_vai_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_zul_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_kin_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_sot_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_lug_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_amh_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_ewe_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_lin_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_orm_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_orm_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_fra_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_lug_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_kin_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_amh_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_sna_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_twi_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_yor_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_sot_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_lin_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_ewe_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_lug_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_fra_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_twi_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_yor_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_orm_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_kin_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_translate_swa_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_translate_twi_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_translate_yor_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_translate_sot_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_translate_lin_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_translate_yor_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_lin_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_hau_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_xho_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_sna_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_swa_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_ibo_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_ibo_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_wol_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_hau_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_vai_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_swa_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_zul_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_fra_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_sna_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_xho_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_hau_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_zul_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_ewe_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_vai_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_fra_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_zul_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_zul_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_xho_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_hau_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_wol_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_ibo_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_swa_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_orm_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_sna_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_twi_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_yor_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_sot_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_lin_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_orm_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_wol_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_ibo_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_swa_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_twi_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_lin_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_wol_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_sot_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_sot_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_yor_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_twi_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_yor_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_translate_orm_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_fra_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_kin_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_lug_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_kin_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_vai_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_xho_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_hau_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_orm_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_swa_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_ibo_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_wol_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_xho_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_ewe_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_amh_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_lug_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_zul_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_amh_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_fra_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_kin_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_lug_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_ibo_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_ewe_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_amh_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_swa_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_amh_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_sna_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_lin_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_ewe_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_wol_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_cot_translate_vai_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_sna_prompt_2,185,false,Unknown,Unknown,false,3
uhura-arc-easy_am_prompt_2,185,false,Unknown,Unknown,false,3
uhura-arc-easy_en_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_wol_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_sot_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_lin_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_amh_prompt_4,185,false,Unknown,Unknown,false,3
fld_logical_formula,185,false,Unknown,Unknown,false,3
afrimgsm_translate_ewe_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_kin_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_lug_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_fra_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_zul_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_hau_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_xho_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_orm_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_ibo_prompt_4,185,false,Unknown,Unknown,false,3
uhura-arc-easy_yo_prompt_5,185,false,Unknown,Unknown,false,3
uhura-arc-easy_am_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_swa_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_twi_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_yor_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_sot_prompt_4,185,false,Unknown,Unknown,false,3
afrimgsm_translate_zul_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_ewe_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_kin_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_lug_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_amh_prompt_3,185,false,Unknown,Unknown,false,3
uhura-arc-easy_en_prompt_1,185,false,Unknown,Unknown,false,3
uhura-arc-easy_am_prompt_5,185,false,Unknown,Unknown,false,3
uhura-arc-easy_yo_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_xho_prompt_2,185,false,Unknown,Unknown,false,3
uhura-arc-easy_sw_prompt_3,185,false,Unknown,Unknown,false,3
uhura-arc-easy_zu_prompt_4,185,false,Unknown,Unknown,false,3
uhura-arc-easy_ha_prompt_3,185,false,Unknown,Unknown,false,3
uhura-arc-easy_nso_prompt_2,185,false,Unknown,Unknown,false,3
uhura-arc-easy_ha_prompt_2,185,false,Unknown,Unknown,false,3
uhura-arc-easy_sw_prompt_2,185,false,Unknown,Unknown,false,3
uhura-arc-easy_yo_prompt_2,185,false,Unknown,Unknown,false,3
uhura-arc-easy_en_prompt_2,185,false,Unknown,Unknown,false,3
uhura-arc-easy_yo_prompt_3,185,false,Unknown,Unknown,false,3
uhura-arc-easy_zu_prompt_3,185,false,Unknown,Unknown,false,3
uhura-arc-easy_en_prompt_3,185,false,Unknown,Unknown,false,3
uhura-arc-easy_nso_prompt_3,185,false,Unknown,Unknown,false,3
uhura-arc-easy_ha_prompt_4,185,false,Unknown,Unknown,false,3
uhura-arc-easy_am_prompt_4,185,false,Unknown,Unknown,false,3
uhura-arc-easy_sw_prompt_4,185,false,Unknown,Unknown,false,3
uhura-arc-easy_nso_prompt_4,185,false,Unknown,Unknown,false,3
uhura-arc-easy_yo_prompt_4,185,false,Unknown,Unknown,false,3
uhura-arc-easy_zu_prompt_2,185,false,Unknown,Unknown,false,3
uhura-arc-easy_en_prompt_4,185,false,Unknown,Unknown,false,3
uhura-arc-easy_zu_prompt_1,185,false,Unknown,Unknown,false,3
uhura-arc-easy_am_prompt_1,185,false,Unknown,Unknown,false,3
uhura-arc-easy_sw_prompt_1,185,false,Unknown,Unknown,false,3
uhura-arc-easy_nso_prompt_1,185,false,Unknown,Unknown,false,3
uhura-arc-easy_ha_prompt_1,185,false,Unknown,Unknown,false,3
uhura-arc-easy_zu_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_sna_prompt_4,185,false,Unknown,Unknown,false,3
uhura-arc-easy_sw_prompt_5,185,false,Unknown,Unknown,false,3
uhura_arc_easy_prompt_2,185,false,Unknown,Unknown,false,3
uhura_arc_easy_prompt_4,185,false,Unknown,Unknown,false,3
uhura_arc_easy_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_tt_tasks,185,false,Unknown,Unknown,false,3
afrimgsm_tt_cot_tasks,185,false,Unknown,Unknown,false,3
afrimgsm_translate_lug_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_ewe_prompt_5,185,false,Unknown,Unknown,false,3
uhura_arc_easy,185,false,Unknown,Unknown,false,3
afrimgsm_translate_amh_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_xho_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_sna_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_orm_prompt_3,185,false,Unknown,Unknown,false,3
uhura-arc-easy_nso_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_ibo_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_swa_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_twi_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_yor_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_sot_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_twi_prompt_1,185,false,Unknown,Unknown,false,3
afrimgsm_translate_amh_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_translate_ewe_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_translate_kin_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_translate_lug_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_translate_fra_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_translate_zul_prompt_2,185,false,Unknown,Unknown,false,3
afrimgsm_translate_hau_prompt_2,185,false,Unknown,Unknown,false,3
uhura_arc_easy_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_wol_prompt_3,185,false,Unknown,Unknown,false,3
uhura_arc_easy_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_wol_prompt_5,185,false,Unknown,Unknown,false,3
uhura_arc_easy_tasks,185,false,Unknown,Unknown,false,3
uhura-arc-easy_ha_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_fra_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_lin_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_hau_prompt_3,185,false,Unknown,Unknown,false,3
afrimgsm_translate_kin_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_fra_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_hau_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_xho_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_sna_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_orm_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_zul_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_ibo_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_yor_prompt_5,185,false,Unknown,Unknown,false,3
fld_logical_formula_default,185,true,hitachi-nlp/FLD.v2,Unknown,false,3
fld_star,185,true,hitachi-nlp/FLD.v2,Unknown,false,3
fld_logical_formula_star,185,true,hitachi-nlp/FLD.v2,Unknown,false,3
afrimgsm_translate_lin_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_sot_prompt_5,185,false,Unknown,Unknown,false,3
fld_default,185,true,hitachi-nlp/FLD.v2,Unknown,false,3
afrimgsm_tt-irokobench,185,false,Unknown,Unknown,false,3
afrimgsm_translate_twi_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_translate_swa_prompt_5,185,false,Unknown,Unknown,false,3
afrimgsm_tt_cot-irokobench,185,false,Unknown,Unknown,false,3
openbookqa_es,175,true,BSC-LT/openbookqa-es,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_microeconomics_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_mathematics_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_government_and_politics_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_international_law_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_public_relations_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_nutrition_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_light,170,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mmlu_professional_accounting_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_professional_law_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_econometrics_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_anatomy_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_world_religions_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_formal_logic_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_chemistry_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_human_aging_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_clinical_knowledge_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_european_history_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_college_medicine_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_virology_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_philosophy_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_college_biology_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_global_facts_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_geography_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_marketing_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_college_physics_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_macroeconomics_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_conceptual_physics_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_sociology_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_business_ethics_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_psychology_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_miscellaneous_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_moral_disputes_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_world_history_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_medical_genetics_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_moral_scenarios_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_computer_security_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_astronomy_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_management_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_jurisprudence_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_us_foreign_policy_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_machine_learning_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_us_history_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_biology_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_prehistory_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_abstract_algebra_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_professional_psychology_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_professional_medicine_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_computer_science_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_human_sexuality_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_statistics_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_elementary_mathematics_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_logical_fallacies_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_college_computer_science_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_college_chemistry_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_security_studies_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_high_school_physics_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_electrical_engineering_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mmlu_college_mathematics_light,170,true,arcee-globe/Arabic_MMLU-10percent,multiple_choice,false,3
french_bench_perplexity,163,false,Unknown,Unknown,false,3
french_bench_arc_challenge,161,true,manu/french_bench_arc_challenge,multiple_choice,false,3
siqa_ca,161,true,projecte-aina/siqa_ca,multiple_choice,false,3
catalanqa,160,true,projecte-aina/catalanqa,generate_until,false,3
lingoly,156,true,Unknown,Unknown,false,3
evalita-sp_sum_task_fp_p1,153,false,Unknown,Unknown,false,3
evalita-mp_sum_fp_tasks,153,false,Unknown,Unknown,false,3
mgsm_direct_eu,153,true,HiTZ/MGSM-eu,generate_until,false,3
evalita-sp_sum_task_fp_p2,153,false,Unknown,Unknown,false,3
french_bench_hellaswag,153,true,manu/french_bench_hellaswag,multiple_choice,false,3
mgsm_native_cot_eu,153,true,HiTZ/MGSM-eu,generate_until,false,3
escola,149,true,nbel/EsCoLA,multiple_choice,false,3
paws_ca,148,true,projecte-aina/PAWS-ca,multiple_choice,false,3
french_bench_gen,148,false,Unknown,Unknown,false,3
norec_sentence_p1,146,false,Unknown,Unknown,false,3
norec_sentence_p2,146,false,Unknown,Unknown,false,3
norec_sentence_p0,146,false,Unknown,Unknown,false,3
norec_sentence_p4,146,false,Unknown,Unknown,false,3
norec_sentence,146,false,Unknown,Unknown,false,3
norec_sentence_p3,146,false,Unknown,Unknown,false,3
norsumm_nno_p5,142,false,Unknown,Unknown,false,3
norsumm_nob_p5,142,false,Unknown,Unknown,false,3
norsumm_nob,142,false,Unknown,Unknown,false,3
norsumm_nno_p1,142,false,Unknown,Unknown,false,3
norsumm_nno_p0,142,false,Unknown,Unknown,false,3
norsumm_nno_p2,142,false,Unknown,Unknown,false,3
norsumm_nno_p3,142,false,Unknown,Unknown,false,3
norsumm_nob_p4,142,false,Unknown,Unknown,false,3
norsumm_nno_p4,142,false,Unknown,Unknown,false,3
norsumm_nob_p2,142,false,Unknown,Unknown,false,3
norsumm_nob_p1,142,false,Unknown,Unknown,false,3
norsumm_nob_p0,142,false,Unknown,Unknown,false,3
norsumm_nob_p3,142,false,Unknown,Unknown,false,3
norsumm_nno,142,false,Unknown,Unknown,false,3
groundcocoa,141,true,harsh147/GroundCocoa,multiple_choice,false,3
arc_ca_easy,140,true,projecte-aina/arc_ca,multiple_choice,false,3
arc_ca_challenge,140,true,projecte-aina/arc_ca,multiple_choice,false,3
mastermind_24_easy,139,false,Unknown,Unknown,false,3
mastermind_easy,139,false,Unknown,Unknown,false,3
mastermind_46_easy,139,false,Unknown,Unknown,false,3
mastermind_35_easy,139,false,Unknown,Unknown,false,3
cocoteros_es,135,true,gplsi/cocoteros,generate_until,false,3
copa_ca,132,true,projecte-aina/COPA-ca,multiple_choice,false,3
evalita-mp_sa_prompt-5,128,false,Unknown,Unknown,false,3
evalita-mp_sa_prompt-1,128,false,Unknown,Unknown,false,3
evalita-mp_sa_tasks,128,false,Unknown,Unknown,false,3
evalita-mp_sa_prompt-3,128,false,Unknown,Unknown,false,3
evalita-mp_sa_prompt-4,128,false,Unknown,Unknown,false,3
evalita-mp_sa,128,false,Unknown,Unknown,false,3
evalita-mp_sa_prompt-6,128,false,Unknown,Unknown,false,3
evalita-mp_sa_prompt-2,128,false,Unknown,Unknown,false,3
french_bench_orangesum_abstract,126,true,orange_sum,generate_until,false,3
french_bench_orangesum_title,126,true,orange_sum,generate_until,false,3
eus_reading,123,true,HiTZ/EusReading,multiple_choice,false,3
mutual,122,true,EleutherAI/mutual,multiple_choice,false,3
mutual_plus,122,true,EleutherAI/mutual,multiple_choice,false,3
wnli_es,120,true,PlanTL-GOB-ES/wnli-es,multiple_choice,false,3
evalita-mp_hs_prompt-5,118,false,Unknown,Unknown,false,3
evalita-mp_hs_prompt-6,118,false,Unknown,Unknown,false,3
evalita-mp_hs_prompt-1,118,false,Unknown,Unknown,false,3
eus_proficiency,118,true,HiTZ/EusProficiency,multiple_choice,false,3
evalita-mp_hs,118,false,Unknown,Unknown,false,3
evalita-mp_hs_prompt-3,118,false,Unknown,Unknown,false,3
evalita-mp_hs_prompt-2,118,false,Unknown,Unknown,false,3
evalita-mp_hs_tasks,118,false,Unknown,Unknown,false,3
evalita-mp_hs_prompt-4,118,false,Unknown,Unknown,false,3
evalita-mp_at_prompt-6,117,false,Unknown,Unknown,false,3
evalita-mp_at_prompt-1,117,false,Unknown,Unknown,false,3
evalita-mp_at,117,false,Unknown,Unknown,false,3
evalita-mp_at_prompt-5,117,false,Unknown,Unknown,false,3
evalita-mp_at_tasks,117,false,Unknown,Unknown,false,3
evalita-mp_at_prompt-2,117,false,Unknown,Unknown,false,3
evalita-mp_at_prompt-3,117,false,Unknown,Unknown,false,3
evalita-mp_at_prompt-4,117,false,Unknown,Unknown,false,3
noridiom_nob_p2,116,false,Unknown,Unknown,false,3
noridiom_nno,116,false,Unknown,Unknown,false,3
noridiom_nno_p1,116,false,Unknown,Unknown,false,3
noridiom_nob_p4,116,false,Unknown,Unknown,false,3
noridiom_nob_p3,116,false,Unknown,Unknown,false,3
noridiom_nob_p0,116,false,Unknown,Unknown,false,3
noridiom_nno_p3,116,false,Unknown,Unknown,false,3
noridiom_nob,116,false,Unknown,Unknown,false,3
noridiom_nno_p0,116,false,Unknown,Unknown,false,3
noridiom_nno_p2,116,false,Unknown,Unknown,false,3
noridiom_nob_p1,116,false,Unknown,Unknown,false,3
noridiom_nno_p4,116,false,Unknown,Unknown,false,3
noticia,113,true,Iker/NoticIA,generate_until,false,3
arc_eu_easy,113,true,HiTZ/ARC-eu,multiple_choice,false,3
arc_eu_challenge,113,true,HiTZ/ARC-eu,multiple_choice,false,3
naijarc_ibo_prompt_4,112,false,Unknown,Unknown,false,3
naijarc_ibo_prompt_5,112,false,Unknown,Unknown,false,3
naijarc_yor_prompt_5,112,false,Unknown,Unknown,false,3
naijarc_hau_prompt_2,112,false,Unknown,Unknown,false,3
naijarc_ibo_prompt_2,112,false,Unknown,Unknown,false,3
naijarc_yor_prompt_2,112,false,Unknown,Unknown,false,3
evalita-mp_ner_adg_p2,112,false,Unknown,Unknown,false,3
evalita-mp_ner-v2_tasks_adg,112,false,Unknown,Unknown,false,3
naijarc_yor_prompt_3,112,false,Unknown,Unknown,false,3
naijarc_hau_prompt_4,112,false,Unknown,Unknown,false,3
evalita-mp_ner_tasks_adg,112,false,Unknown,Unknown,false,3
naijarc_yor_prompt_4,112,false,Unknown,Unknown,false,3
naijarc_hau_prompt_1,112,false,Unknown,Unknown,false,3
naijarc_ibo_prompt_1,112,false,Unknown,Unknown,false,3
naijarc_yor_prompt_1,112,false,Unknown,Unknown,false,3
evalita-mp_ner-v2_fic_p1,112,false,Unknown,Unknown,false,3
evalita-mp_ner_tasks_wn,112,false,Unknown,Unknown,false,3
evalita-mp_ner-v2_tasks_fic,112,false,Unknown,Unknown,false,3
evalita-mp_ner_tasks_fic,112,false,Unknown,Unknown,false,3
naijarc,112,false,Unknown,Unknown,false,3
evalita-mp_ner-v2_tasks_wn,112,false,Unknown,Unknown,false,3
naijarc_hau_prompt_5,112,false,Unknown,Unknown,false,3
evalita-mp_ner-v2_wn_p1,112,false,Unknown,Unknown,false,3
evalita-mp_ner_fic_p2,112,false,Unknown,Unknown,false,3
evalita-mp_ner_fic_p1,112,false,Unknown,Unknown,false,3
evalita-mp_ner_adg_p1,112,false,Unknown,Unknown,false,3
evalita-mp_ner_wn_p1,112,false,Unknown,Unknown,false,3
naijarc_tasks,112,false,Unknown,Unknown,false,3
naijarc_prompt_5,112,false,Unknown,Unknown,false,3
naijarc_prompt_2,112,false,Unknown,Unknown,false,3
naijarc_prompt_4,112,false,Unknown,Unknown,false,3
evalita-mp_ner-v2_wn_p2,112,false,Unknown,Unknown,false,3
evalita-mp_ner_wn_p2,112,false,Unknown,Unknown,false,3
evalita-mp_ner-v2_fic_p2,112,false,Unknown,Unknown,false,3
naijarc_prompt_1,112,false,Unknown,Unknown,false,3
naijarc_prompt_3,112,false,Unknown,Unknown,false,3
evalita-mp_ner-v2_adg_p2,112,false,Unknown,Unknown,false,3
evalita-mp_ner_wn_group,112,false,Unknown,Unknown,false,3
naijarc_ibo_prompt_3,112,false,Unknown,Unknown,false,3
naijarc_hau_prompt_3,112,false,Unknown,Unknown,false,3
evalita-mp_ner_fic_group,112,false,Unknown,Unknown,false,3
evalita-mp_ner_adg_group,112,false,Unknown,Unknown,false,3
evalita-mp_ner_group,112,false,Unknown,Unknown,false,3
evalita-mp_ner-v2_adg_p1,112,false,Unknown,Unknown,false,3
noropenbookqa_nob_p1,111,false,Unknown,Unknown,false,3
noropenbookqa_nob_p4,111,false,Unknown,Unknown,false,3
noropenbookqa_nno,111,false,Unknown,Unknown,false,3
noropenbookqa_nob,111,false,Unknown,Unknown,false,3
noropenbookqa_nob_p3,111,false,Unknown,Unknown,false,3
noropenbookqa_nob_p0,111,false,Unknown,Unknown,false,3
noropenbookqa_nno_p2,111,false,Unknown,Unknown,false,3
noropenbookqa_nno_p3,111,false,Unknown,Unknown,false,3
noropenbookqa_nob_p2,111,false,Unknown,Unknown,false,3
noropenbookqa_nno_p4,111,false,Unknown,Unknown,false,3
noropenbookqa_nno_p1,111,false,Unknown,Unknown,false,3
noropenbookqa_nno_p0,111,false,Unknown,Unknown,false,3
arabic_leaderboard_light,110,true,Unknown,Unknown,false,3
eus_trivia,108,true,HiTZ/EusTrivia,multiple_choice,false,3
afrimmlu_translate_yor_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_zul_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_amh_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_xho_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_sot_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_ewe_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_xho_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_twi_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_xho_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_lin_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_lin_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_sna_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_wol_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_ibo_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_swa_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_orm_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_sna_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_fra_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_zul_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_fra_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_ibo_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_orm_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_swa_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_amh_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_tt-irokobench,106,false,Unknown,Unknown,false,3
afrimmlu_tt_tasks,106,false,Unknown,Unknown,false,3
afrimmlu_translate_kin_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_lug_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_fra_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_zul_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_ewe_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_amh_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_lug_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_kin_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_twi_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_yor_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_sot_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_lin_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_twi_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_yor_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_hau_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_wol_prompt_5,106,false,Unknown,Unknown,false,3
afrimmlu_translate_ewe_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_ewe_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_lug_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_sna_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_zul_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_amh_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_lug_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_kin_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_twi_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_amh_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_fra_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_zul_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_yor_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_sna_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_orm_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_ibo_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_hau_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_hau_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_xho_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_lin_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_sot_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_wol_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_kin_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_fra_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_swa_prompt_3,106,false,Unknown,Unknown,false,3
afrimmlu_translate_orm_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_swa_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_twi_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_swa_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_yor_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_sot_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_xho_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_hau_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_wol_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_ibo_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_lin_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_orm_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_wol_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_sna_prompt_1,106,false,Unknown,Unknown,false,3
afrimmlu_translate_kin_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_lug_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_sot_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_ibo_prompt_2,106,false,Unknown,Unknown,false,3
afrimmlu_translate_ewe_prompt_4,106,false,Unknown,Unknown,false,3
afrimmlu_translate_hau_prompt_2,106,false,Unknown,Unknown,false,3
mastermind,105,false,Unknown,Unknown,false,3
code2text_python,103,true,CM/codexglue_code2text_python,generate_until,false,3
codexglue_code2text,103,false,Unknown,Unknown,false,3
parafraseja,101,true,projecte-aina/Parafraseja,multiple_choice,false,3
ntrex_eng_Latn-ssw_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-som_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-fra_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-mlg_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_tir_Ethi-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ton_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ewe_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-shi_Arab_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-orm_Ethi_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-arb_Arab_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-nso_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_afr-eng_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-tam_Taml_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_orm_Ethi-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-urd_Arab_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-kin_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_tasks,97,false,Unknown,Unknown,false,3
african_ntrex,97,false,Unknown,Unknown,false,3
ntrex_afr-eng,97,false,Unknown,Unknown,false,3
ntrex_afr-eng_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng-afr,97,false,Unknown,Unknown,false,3
ntrex_eng-afr_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-wol_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-tir_Ethi_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_tsn_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-zul_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_nso_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_sna_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_afr-eng_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_arb_Arab-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-tsn_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_som_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_shi_Arab-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_nya_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_wol_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_zul_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_yor_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_bem_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-sna_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_ssw_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_ven_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_tam_Taml-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-mey_Arab_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_swa_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-xho_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_ibo_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_urd_Arab-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-afr_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-tel_Telu_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng-afr_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_tir_Ethi-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ven_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_nso_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_msa_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_amh_Ethi-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_hau_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_mey_Arab-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_kin_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-mey_Arab_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_tam_Taml-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_ven_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_ssw_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_bem_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_yor_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng-afr_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_zul_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_nya_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_shi_Arab-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_som_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_arb_Arab-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_fra_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_tsn_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_sna_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_nde_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_ibo_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-tsn_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_tel_Telu-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_xho_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_ton_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-msa_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-amh_Ethi_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ibo_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-nya_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-bem_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-swa_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-yor_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-nde_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-hau_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_afr_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_mlg_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_swa_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_wol_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_urd_Arab-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_orm_Ethi-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_msa_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_tel_Telu-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_xho_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_ton_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_hau_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_ewe_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_nde_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-kin_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_kin_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ewe_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-nde_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_sna_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_som_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_fra_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_arb_Arab-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-fra_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-mlg_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-xho_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ton_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ssw_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-shi_Arab_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_tam_Taml-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-orm_Ethi_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_tel_Telu-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-tir_Ethi_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-nso_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-som_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-tam_Taml_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-yor_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-afr_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-hau_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-tsn_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_tsn_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-urd_Arab_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-zul_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_kin_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_mey_Arab-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_tir_Ethi-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_hau_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-msa_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-nya_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ibo_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_mlg_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_ewe_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_amh_Ethi-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_ton_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_nde_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-amh_Ethi_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-tel_Telu_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-sna_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_ibo_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_afr_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_mey_Arab-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-bem_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-swa_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ven_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-kin_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-mey_Arab_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-arb_Arab_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_ven_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-amh_Ethi_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-zul_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-sna_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-tel_Telu_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-nde_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-urd_Arab_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ven_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-swa_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_ssw_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-nya_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ibo_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-msa_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_ewe_Latn-eng_Latn_prompt_1,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-yor_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-afr_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-hau_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_fra_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_urd_Arab-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_wol_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_swa_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_mlg_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_amh_Ethi-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_afr_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-wol_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-bem_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ssw_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_orm_Ethi-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_bem_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-fra_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_yor_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_zul_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_nya_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_shi_Arab-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-wol_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_xho_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-tir_Ethi_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_msa_Latn-eng_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_nso_Latn-eng_Latn_prompt_2,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-tam_Taml_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-som_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-nso_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-arb_Arab_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-orm_Ethi_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-shi_Arab_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ewe_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-ton_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-xho_Latn_prompt_3,97,false,Unknown,Unknown,false,3
ntrex_eng_Latn-mlg_Latn_prompt_3,97,false,Unknown,Unknown,false,3
wnli_ca,94,true,projecte-aina/wnli-ca,multiple_choice,false,3
evalita-mp_re_prompt-1,93,false,Unknown,Unknown,false,3
evalita-mp_re_prompt-2,93,false,Unknown,Unknown,false,3
evalita-mp_re,93,false,Unknown,Unknown,false,3
evalita-mp_re_tasks,93,false,Unknown,Unknown,false,3
afridiacritics_fon_prompt_4,92,false,Unknown,Unknown,false,3
afridiacritics_yor_prompt_2,92,false,Unknown,Unknown,false,3
afridiacritics_bbj_prompt_2,92,false,Unknown,Unknown,false,3
afridiacritics_wol_prompt_2,92,false,Unknown,Unknown,false,3
afridiacritics_ibo_prompt_2,92,false,Unknown,Unknown,false,3
afridiacritics_wol_prompt_5,92,false,Unknown,Unknown,false,3
afridiacritics_yor_prompt_3,92,false,Unknown,Unknown,false,3
afridiacritics_wol_prompt_3,92,false,Unknown,Unknown,false,3
afridiacritics_fon_prompt_2,92,false,Unknown,Unknown,false,3
afridiacritics_ibo_prompt_3,92,false,Unknown,Unknown,false,3
afridiacritics_fon_prompt_3,92,false,Unknown,Unknown,false,3
afridiacritics_yor_prompt_4,92,false,Unknown,Unknown,false,3
afridiacritics_bbj_prompt_4,92,false,Unknown,Unknown,false,3
afridiacritics_wol_prompt_4,92,false,Unknown,Unknown,false,3
afridiacritics_ibo_prompt_4,92,false,Unknown,Unknown,false,3
afridiacritics_fon_prompt_5,92,false,Unknown,Unknown,false,3
afridiacritics_bbj_prompt_3,92,false,Unknown,Unknown,false,3
adr_prompt_3,92,false,Unknown,Unknown,false,3
afridiacritics_yor_prompt_1,92,false,Unknown,Unknown,false,3
adr_prompt_1,92,false,Unknown,Unknown,false,3
afridiacritics_wol_prompt_1,92,false,Unknown,Unknown,false,3
adr_prompt_4,92,false,Unknown,Unknown,false,3
afridiacritics_ibo_prompt_1,92,false,Unknown,Unknown,false,3
afridiacritics_fon_prompt_1,92,false,Unknown,Unknown,false,3
afridiacritics_bbj_prompt_5,92,false,Unknown,Unknown,false,3
adr,92,false,Unknown,Unknown,false,3
afridiacritics_yor_prompt_5,92,false,Unknown,Unknown,false,3
afridiacritics_ibo_prompt_5,92,false,Unknown,Unknown,false,3
afridiacritics_bbj_prompt_1,92,false,Unknown,Unknown,false,3
adr_prompt_2,92,false,Unknown,Unknown,false,3
adr_prompt_5,92,false,Unknown,Unknown,false,3
adr_tasks,92,false,Unknown,Unknown,false,3
evalita-mp_mc,92,false,Unknown,Unknown,false,3
histoires_morales,92,true,LabHC/histoires_morales,multiple_choice,false,3
openbookqa_ca,89,true,projecte-aina/openbookqa_ca,multiple_choice,false,3
wnli_eu,87,true,HiTZ/wnli-eu,multiple_choice,false,3
evalita-mp,87,false,Unknown,Unknown,false,3
reversed_words,86,true,EleutherAI/unscramble,generate_until,false,3
cabreu_abstractive,86,true,projecte-aina/caBreu,generate_until,false,3
cabreu_extractive,86,true,projecte-aina/caBreu,generate_until,false,3
cabreu,86,false,Unknown,Unknown,false,3
unscramble,86,false,Unknown,Unknown,false,3
anagrams2,86,true,EleutherAI/unscramble,generate_until,false,3
cycle_letters,86,true,EleutherAI/unscramble,generate_until,false,3
random_insertion,86,true,EleutherAI/unscramble,generate_until,false,3
anagrams1,86,true,EleutherAI/unscramble,generate_until,false,3
cabreu_extreme,86,true,projecte-aina/caBreu,generate_until,false,3
xstorycloze_ca,85,true,projecte-aina/xstorycloze_ca,multiple_choice,false,3
phrases_va-es,84,true,gplsi/ES-VA_translation_test,generate_until,false,3
phrases_es-va,84,true,gplsi/ES-VA_translation_test,generate_until,false,3
phrases_es,84,false,Unknown,Unknown,false,3
french_bench_topic_based_nli,83,true,manu/topic_based_nli_test,multiple_choice,false,3
xquad_ca,81,true,projecte-aina/xquad-ca,generate_until,false,3
teca,80,true,projecte-aina/teca,multiple_choice,false,3
piqa_ca,80,true,projecte-aina/piqa_ca,multiple_choice,false,3
cocoteros_va,80,false,Unknown,Unknown,false,3
arabic_leaderboard_alghafa_multiple_choice_grounded_statement_xglue_mlqa_task_light,79,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Native-10percent,multiple_choice,false,3
evalita-mp_gen,79,false,Unknown,Unknown,false,3
arabic_leaderboard_alghafa_mcq_exams_test_ar_light,79,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Native-10percent,multiple_choice,false,3
arabic_leaderboard_alghafa_multiple_choice_rating_sentiment_no_neutral_task_light,79,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Native-10percent,multiple_choice,false,3
arabic_leaderboard_alghafa_meta_ar_dialects_light,79,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Native-10percent,multiple_choice,false,3
arabic_leaderboard_alghafa_light,79,true,Unknown,Unknown,false,3
arabic_leaderboard_alghafa_multiple_choice_facts_truefalse_balanced_task_light,79,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Native-10percent,multiple_choice,false,3
arabic_leaderboard_alghafa_multiple_choice_grounded_statement_soqal_task_light,79,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Native-10percent,multiple_choice,false,3
arabic_leaderboard_alghafa_multiple_choice_rating_sentiment_task_light,79,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Native-10percent,multiple_choice,false,3
arabic_leaderboard_alghafa_multiple_choice_sentiment_task_light,79,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Native-10percent,multiple_choice,false,3
arabic_leaderboard_alghafa_meta_ar_msa_light,79,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Native-10percent,multiple_choice,false,3
lingoly_nocontext,78,true,ambean/lingOly,Unknown,false,3
lingoly_context,78,true,ambean/lingOly,Unknown,false,3
inverse_scaling_neqa,78,true,inverse_scaling_mc,multiple_choice,false,3
paws_eu,77,true,HiTZ/PAWS-eu,multiple_choice,false,3
nrk_quiz_qa_nno,75,false,Unknown,Unknown,false,3
nrk_quiz_qa_nno_p4,75,false,Unknown,Unknown,false,3
nrk_quiz_qa_nob_p4,75,false,Unknown,Unknown,false,3
nrk_quiz_qa_nob_p1,75,false,Unknown,Unknown,false,3
nrk_quiz_qa_nno_p1,75,false,Unknown,Unknown,false,3
nrk_quiz_qa_nob_p2,75,false,Unknown,Unknown,false,3
nrk_quiz_qa_nno_p3,75,false,Unknown,Unknown,false,3
nrk_quiz_qa_nno_p2,75,false,Unknown,Unknown,false,3
nrk_quiz_qa_nob_p3,75,false,Unknown,Unknown,false,3
nrk_quiz_qa_nob_p0,75,false,Unknown,Unknown,false,3
nrk_quiz_qa_nno_p0,75,false,Unknown,Unknown,false,3
nrk_quiz_qa_nob,75,false,Unknown,Unknown,false,3
evalita-mp_wic_prompt-1,73,false,Unknown,Unknown,false,3
evalita-mp_wic_prompt-2,73,false,Unknown,Unknown,false,3
evalita-mp_wic_prompt-3,73,false,Unknown,Unknown,false,3
evalita-mp_wic_tasks,73,false,Unknown,Unknown,false,3
evalita-mp_wic_prompt-6,73,false,Unknown,Unknown,false,3
evalita-mp_wic,73,false,Unknown,Unknown,false,3
evalita-mp_wic_prompt-4,73,false,Unknown,Unknown,false,3
evalita-mp_wic_prompt-5,73,false,Unknown,Unknown,false,3
evalita-mp_ls_prompt-1,72,false,Unknown,Unknown,false,3
evalita-mp_ls,72,false,Unknown,Unknown,false,3
evalita-mp_ls_tasks,72,false,Unknown,Unknown,false,3
evalita-mp_ls_prompt-2,72,false,Unknown,Unknown,false,3
norcommonsenseqa_nob_p0,71,false,Unknown,Unknown,false,3
norcommonsenseqa_nno_p1,71,false,Unknown,Unknown,false,3
mastermind_hard,71,false,Unknown,Unknown,false,3
norcommonsenseqa_nob,71,false,Unknown,Unknown,false,3
norcommonsenseqa_nno,71,false,Unknown,Unknown,false,3
mastermind_35_hard,71,false,Unknown,Unknown,false,3
mastermind_46_hard,71,false,Unknown,Unknown,false,3
mastermind_24_hard,71,false,Unknown,Unknown,false,3
norcommonsenseqa_nno_p3,71,false,Unknown,Unknown,false,3
norcommonsenseqa_nno_p2,71,false,Unknown,Unknown,false,3
norcommonsenseqa_nob_p3,71,false,Unknown,Unknown,false,3
norcommonsenseqa_nno_p0,71,false,Unknown,Unknown,false,3
norcommonsenseqa_nob_p2,71,false,Unknown,Unknown,false,3
norcommonsenseqa_nob_p1,71,false,Unknown,Unknown,false,3
norcommonsenseqa_nno_p4,71,false,Unknown,Unknown,false,3
norcommonsenseqa_nob_p4,71,false,Unknown,Unknown,false,3
arabic_mt_arc_challenge_light,70,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Translated-10percent,multiple_choice,false,3
arabic_mt_sciq_light,70,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Translated-10percent,multiple_choice,false,3
arabic_mt_toxigen_light,70,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Translated-10percent,multiple_choice,false,3
arabic_mt_mmlu_light,70,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Translated-10percent,multiple_choice,false,3
norsummarize_instruct,70,false,Unknown,Unknown,false,3
arabic_mt_openbook_qa_light,70,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Translated-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mt_boolq_light,70,true,Unknown,Unknown,false,3
arabic_mt_race_light,70,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Translated-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mt_arc_challenge_light,70,true,Unknown,Unknown,false,3
inverse_scaling_quote_repetition,70,true,inverse_scaling_mc,multiple_choice,false,3
arabic_mt_copa_light,70,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Translated-10percent,multiple_choice,false,3
arabic_mt_piqa_light,70,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Translated-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mt_arc_easy_light,70,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_mmlu_light,70,true,Unknown,Unknown,false,3
arabic_mt_boolq_light,70,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Translated-10percent,multiple_choice,false,3
arabic_mt_arc_easy_light,70,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Translated-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mt_race_light,70,true,Unknown,Unknown,false,3
arabic_mt_hellaswag_light,70,true,arcee-globe/AlGhafa-Arabic-LLM-Benchmark-Translated-10percent,multiple_choice,false,3
arabic_leaderboard_arabic_mt_piqa_light,70,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_toxigen_light,70,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_openbook_qa_light,70,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_sciq_light,70,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_copa_light,70,true,Unknown,Unknown,false,3
arabic_leaderboard_arabic_mt_hellaswag_light,70,true,Unknown,Unknown,false,3
french_bench_boolqa,69,true,manu/french_boolq,multiple_choice,false,3
norrewrite_instruct,68,false,Unknown,Unknown,false,3
phrases_va-ca,68,true,gplsi/CA-VA_alignment_test,generate_until,false,3
phrases_ca-va,68,true,gplsi/CA-VA_alignment_test,generate_until,false,3
phrases_va,68,false,Unknown,Unknown,false,3
catcola,67,true,nbel/CatCoLA,multiple_choice,false,3
inverse_scaling_memo_trap,67,true,inverse_scaling_mc,multiple_choice,false,3
openbookqa_gl,66,true,proxectonos/openbookqa_gl,multiple_choice,false,3
olaph,66,false,Unknown,Unknown,false,3
olaph_perplexity,66,false,Unknown,Unknown,false,3
nortruthfulqa_mc_nob_p0,65,false,Unknown,Unknown,false,3
nortruthfulqa_mc_nno_p4,65,false,Unknown,Unknown,false,3
nortruthfulqa_mc_nno_p2,65,false,Unknown,Unknown,false,3
nortruthfulqa_mc_nno_p3,65,false,Unknown,Unknown,false,3
nortruthfulqa_mc_nno_p0,65,false,Unknown,Unknown,false,3
nortruthfulqa_mc_nno_p1,65,false,Unknown,Unknown,false,3
masakhapos_wol_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_sna_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_tsn_prompt_2,65,false,Unknown,Unknown,false,3
coqcat,65,true,projecte-aina/CoQCat,generate_until,false,3
masakhapos_swa_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_ibo_prompt_2,65,false,Unknown,Unknown,false,3
summarization_gl,65,true,proxectonos/summarization_gl,generate_until,false,3
masakhapos_fon_prompt_2,65,false,Unknown,Unknown,false,3
nortruthfulqa_mc_nno,65,false,Unknown,Unknown,false,3
nortruthfulqa_mc_nob,65,false,Unknown,Unknown,false,3
masakhapos_pcm_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_pcm_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_zul_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_ewe_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_nya_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_xho_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_kin_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_lug_prompt_3,65,false,Unknown,Unknown,false,3
nortruthfulqa_mc_nob_p2,65,false,Unknown,Unknown,false,3
masakhapos_wol_prompt_5,65,false,Unknown,Unknown,false,3
nortruthfulqa_mc_nob_p4,65,false,Unknown,Unknown,false,3
masakhapos_swa_prompt_5,65,false,Unknown,Unknown,false,3
nortruthfulqa_mc_nob_p1,65,false,Unknown,Unknown,false,3
masakhapos_mos_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_mos_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_luo_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_luo_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_ibo_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_nya_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_xho_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_fon_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_hau_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_hau_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_twi_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_yor_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_sna_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_tsn_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_pcm_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_ibo_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_twi_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_wol_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_bam_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_yor_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_bam_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_bbj_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_wol_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_lug_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_ewe_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_zul_prompt_2,65,false,Unknown,Unknown,false,3
masakhapos_luo_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_swa_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_bbj_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_ibo_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_kin_prompt_2,65,false,Unknown,Unknown,false,3
nortruthfulqa_mc_nob_p3,65,false,Unknown,Unknown,false,3
masakhapos_yor_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_bbj_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_mos_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_lug_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_kin_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_fon_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_ewe_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_luo_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_zul_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_luo_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_xho_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_zul_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_ewe_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_kin_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_lug_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_mos_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_bbj_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_nya_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_bam_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_yor_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_twi_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_tsn_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_sna_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_hau_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_fon_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_xho_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_twi_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_hau_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_bam_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_tsn_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_nya_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos,65,false,Unknown,Unknown,false,3
masakhapos_zul_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_ewe_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_kin_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_lug_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_pcm_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_bbj_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_bam_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_yor_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_twi_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_hau_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_fon_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_xho_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_nya_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_mos_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_tasks,65,false,Unknown,Unknown,false,3
masakhapos_swa_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_prompt_5,65,false,Unknown,Unknown,false,3
masakhapos_sna_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_swa_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_wol_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_ibo_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_pcm_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_sna_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_tsn_prompt_1,65,false,Unknown,Unknown,false,3
masakhapos_prompt_4,65,false,Unknown,Unknown,false,3
masakhapos_prompt_3,65,false,Unknown,Unknown,false,3
masakhapos_prompt_2,65,false,Unknown,Unknown,false,3
evalita-mp_faq_prompt-2,64,false,Unknown,Unknown,false,3
evalita-mp_faq,64,false,Unknown,Unknown,false,3
evalita-mp_faq_prompt-6,64,false,Unknown,Unknown,false,3
evalita-mp_faq_prompt-5,64,false,Unknown,Unknown,false,3
evalita-mp_faq_tasks,64,false,Unknown,Unknown,false,3
ask_gec,64,false,Unknown,Unknown,false,3
evalita-mp_faq_prompt-4,64,false,Unknown,Unknown,false,3
evalita-mp_faq_prompt-3,64,false,Unknown,Unknown,false,3
ask_gec_p4,64,false,Unknown,Unknown,false,3
ask_gec_p2,64,false,Unknown,Unknown,false,3
ask_gec_p3,64,false,Unknown,Unknown,false,3
evalita-mp_faq_prompt-1,64,false,Unknown,Unknown,false,3
ask_gec_p1,64,false,Unknown,Unknown,false,3
ask_gec_p0,64,false,Unknown,Unknown,false,3
arabic_exams_light,60,true,arcee-globe/Arabic_EXAMS-10percent,multiple_choice,false,3
norec_document_p0,60,false,Unknown,Unknown,false,3
norec_document_p1,60,false,Unknown,Unknown,false,3
norec_document_p4,60,false,Unknown,Unknown,false,3
norec_document_p2,60,false,Unknown,Unknown,false,3
norec_document_p3,60,false,Unknown,Unknown,false,3
glianorex_en,60,true,maximegmd/glianorex,multiple_choice,false,3
glianorex,60,true,maximegmd/glianorex,multiple_choice,false,3
norec_document,60,false,Unknown,Unknown,false,3
glianorex_fr,60,true,maximegmd/glianorex,multiple_choice,false,3
arabic_leaderboard_arabic_exams_light,60,true,Unknown,Unknown,false,3
nortruthfulqa_gen_nob_p1,59,false,Unknown,Unknown,false,3
nortruthfulqa_gen_nno_p3,59,false,Unknown,Unknown,false,3
nortruthfulqa_gen_nno_p2,59,false,Unknown,Unknown,false,3
nortruthfulqa_gen_nno_p1,59,false,Unknown,Unknown,false,3
nortruthfulqa_gen_nno_p0,59,false,Unknown,Unknown,false,3
nortruthfulqa_gen_nob_p4,59,false,Unknown,Unknown,false,3
nortruthfulqa_gen_nob_p3,59,false,Unknown,Unknown,false,3
nortruthfulqa_gen_nob_p2,59,false,Unknown,Unknown,false,3
nortruthfulqa_gen_nno,59,false,Unknown,Unknown,false,3
nortruthfulqa_gen_nob,59,false,Unknown,Unknown,false,3
nortruthfulqa_gen_nob_p0,59,false,Unknown,Unknown,false,3
nortruthfulqa_gen_nno_p4,59,false,Unknown,Unknown,false,3
mimic_repsum_perplexity,56,false,Unknown,Unknown,false,3
mimic_repsum,56,false,Unknown,Unknown,false,3
truthfulqa_gl_mc1,55,true,proxectonos/truthfulqa_gl,multiple_choice,false,3
truthfulqa_gl_mc2,55,true,proxectonos/truthfulqa_gl,multiple_choice,false,3
truthfulqa_gl_gen,55,true,proxectonos/truthfulqa_gl,generate_until,false,3
truthfulqa_gl,55,false,Unknown,Unknown,false,3
mgsm_direct_gl,55,true,proxectonos/mgsm_gl,generate_until,false,3
masakhaner_tn_prompt_1,54,false,Unknown,Unknown,false,3
galcola,54,true,proxectonos/galcola,multiple_choice,false,3
masakhaner_tw_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_am_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_rw_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_bbj_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_zu_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_mos_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_lg_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_ny_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_yo_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_tw_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_ny_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_sn_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_wo_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_sw_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_bm_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_am_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_pcm_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_ee_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_xh_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_ha_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_ig_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_yo_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_am_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_luo_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_ig_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_ny_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_ee_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_zu_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_mos_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_zu_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_lg_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_sn_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_wo_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_sw_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_bm_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_pcm_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_luo_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_tn_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_ha_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_ig_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_yo_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_bbj_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_xh_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_mos_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_tw_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_rw_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_tasks,54,false,Unknown,Unknown,false,3
masakhaner_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_rw_prompt_1,54,false,Unknown,Unknown,false,3
masakhaner_lg_prompt_3,54,false,Unknown,Unknown,false,3
masakhaner_mos_prompt_4,54,false,Unknown,Unknown,false,3
french_bench_trivia,54,true,manu/french-trivia,generate_until,false,3
masakhaner_xh_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_sn_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_zu_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_rw_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_tn_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_bbj_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner,54,false,Unknown,Unknown,false,3
masakhaner_sn_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_ee_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_tn_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_ig_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_luo_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_yo_prompt_5,54,false,Unknown,Unknown,false,3
inverse_scaling_redefine_math,54,true,inverse_scaling_mc,multiple_choice,false,3
masakhaner_lg_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_pcm_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_xh_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_ee_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_luo_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_bm_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_sw_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_wo_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_pcm_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_wo_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_am_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_sw_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_ny_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_tw_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_tn_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_wo_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_sw_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_bm_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_pcm_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_luo_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_ee_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_xh_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_ha_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_ig_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_yo_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_sn_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_ny_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_lg_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_bbj_prompt_4,54,false,Unknown,Unknown,false,3
masakhaner_bbj_prompt_1,54,false,Unknown,Unknown,false,3
xstorycloze_gl,54,true,proxectonos/xstorycloze_gl,multiple_choice,false,3
masakhaner_ha_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_ha_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_tw_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_mos_prompt_5,54,false,Unknown,Unknown,false,3
masakhaner_zu_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_rw_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_bm_prompt_2,54,false,Unknown,Unknown,false,3
masakhaner_am_prompt_2,54,false,Unknown,Unknown,false,3
evalita-mp_te_prompt-2,53,false,Unknown,Unknown,false,3
evalita-mp_te_prompt-1,53,false,Unknown,Unknown,false,3
evalita-mp_te_prompt-4,53,false,Unknown,Unknown,false,3
evalita-mp_te_prompt-6,53,false,Unknown,Unknown,false,3
evalita-mp_te_prompt-5,53,false,Unknown,Unknown,false,3
evalita-mp_te_prompt-3,53,false,Unknown,Unknown,false,3
evalita-mp_te_tasks,53,false,Unknown,Unknown,false,3
evalita-mp_te,53,false,Unknown,Unknown,false,3
afriqa_twi_prompt_5,52,false,Unknown,Unknown,false,3
afriqa_zul_prompt_3,52,false,Unknown,Unknown,false,3
afriqa_swa_prompt_2,52,false,Unknown,Unknown,false,3
afriqa_ibo_prompt_2,52,false,Unknown,Unknown,false,3
afriqa_hau_prompt_2,52,false,Unknown,Unknown,false,3
afriqa_yor_prompt_2,52,false,Unknown,Unknown,false,3
afriqa_twi_prompt_2,52,false,Unknown,Unknown,false,3
afriqa_kin_prompt_2,52,false,Unknown,Unknown,false,3
afriqa_bem_prompt_3,52,false,Unknown,Unknown,false,3
afriqa_zul_prompt_2,52,false,Unknown,Unknown,false,3
afriqa_swa_prompt_5,52,false,Unknown,Unknown,false,3
afriqa_ibo_prompt_5,52,false,Unknown,Unknown,false,3
afriqa_kin_prompt_5,52,false,Unknown,Unknown,false,3
afriqa_bem_prompt_5,52,false,Unknown,Unknown,false,3
afriqa_kin_prompt_3,52,false,Unknown,Unknown,false,3
afriqa_zul_prompt_5,52,false,Unknown,Unknown,false,3
afriqa_twi_prompt_3,52,false,Unknown,Unknown,false,3
afriqa_yor_prompt_5,52,false,Unknown,Unknown,false,3
afriqa_yor_prompt_3,52,false,Unknown,Unknown,false,3
afriqa_hau_prompt_3,52,false,Unknown,Unknown,false,3
afriqa_fon_prompt_3,52,false,Unknown,Unknown,false,3
afriqa_ibo_prompt_3,52,false,Unknown,Unknown,false,3
afriqa_swa_prompt_3,52,false,Unknown,Unknown,false,3
afriqa_zul_prompt_4,52,false,Unknown,Unknown,false,3
afriqa_fon_prompt_2,52,false,Unknown,Unknown,false,3
afriqa_bem_prompt_2,52,false,Unknown,Unknown,false,3
afriqa_hau_prompt_1,52,false,Unknown,Unknown,false,3
afriqa_kin_prompt_1,52,false,Unknown,Unknown,false,3
afriqa_fon_prompt_5,52,false,Unknown,Unknown,false,3
afriqa_twi_prompt_1,52,false,Unknown,Unknown,false,3
afriqa_bem_prompt_1,52,false,Unknown,Unknown,false,3
afriqa_bem_prompt_4,52,false,Unknown,Unknown,false,3
afriqa_swa_prompt_4,52,false,Unknown,Unknown,false,3
afriqa_ibo_prompt_4,52,false,Unknown,Unknown,false,3
afriqa_fon_prompt_4,52,false,Unknown,Unknown,false,3
afriqa_hau_prompt_4,52,false,Unknown,Unknown,false,3
afriqa,52,false,Unknown,Unknown,false,3
afriqa_yor_prompt_4,52,false,Unknown,Unknown,false,3
afriqa_twi_prompt_4,52,false,Unknown,Unknown,false,3
afriqa_yor_prompt_1,52,false,Unknown,Unknown,false,3
afriqa_zul_prompt_1,52,false,Unknown,Unknown,false,3
afriqa_fon_prompt_1,52,false,Unknown,Unknown,false,3
afriqa_hau_prompt_5,52,false,Unknown,Unknown,false,3
afriqa_swa_prompt_1,52,false,Unknown,Unknown,false,3
afriqa_kin_prompt_4,52,false,Unknown,Unknown,false,3
afrobench_xqa_tasks,52,false,Unknown,Unknown,false,3
afriqa_prompt_5,52,false,Unknown,Unknown,false,3
afriqa_ibo_prompt_1,52,false,Unknown,Unknown,false,3
afriqa_prompt_2,52,false,Unknown,Unknown,false,3
afriqa_prompt_3,52,false,Unknown,Unknown,false,3
afriqa_prompt_4,52,false,Unknown,Unknown,false,3
afriqa_prompt_1,52,false,Unknown,Unknown,false,3
french_bench_multifquad,49,true,manu/multifquad_test,generate_until,false,3
parafrases_gl,48,true,proxectonos/parafrases_gl,multiple_choice,false,3
paws_gl,48,true,proxectonos/PAWS-gl,multiple_choice,false,3
french_bench_opus_perplexity,46,true,manu/opus100-en-fr,loglikelihood_rolling,false,3
nollysenti_ibo_prompt_5,44,false,Unknown,Unknown,false,3
nollysenti_prompt_2,44,false,Unknown,Unknown,false,3
nollysenti_prompt_3,44,false,Unknown,Unknown,false,3
nollysenti_prompt_4,44,false,Unknown,Unknown,false,3
nollysenti_prompt_1,44,false,Unknown,Unknown,false,3
nollysenti_yor_prompt_4,44,false,Unknown,Unknown,false,3
nollysenti_hau_prompt_5,44,false,Unknown,Unknown,false,3
nollysenti,44,false,Unknown,Unknown,false,3
nollysenti_hau_prompt_1,44,false,Unknown,Unknown,false,3
nollysenti_eng_prompt_5,44,false,Unknown,Unknown,false,3
nollysenti_yor_prompt_5,44,false,Unknown,Unknown,false,3
nollysenti_hau_prompt_2,44,false,Unknown,Unknown,false,3
nollysenti_pcm_prompt_2,44,false,Unknown,Unknown,false,3
nollysenti_ibo_prompt_2,44,false,Unknown,Unknown,false,3
nollysenti_eng_prompt_2,44,false,Unknown,Unknown,false,3
nollysenti_prompt_5,44,false,Unknown,Unknown,false,3
med_prescriptions_easy,44,false,Unknown,Unknown,false,3
med_prescriptions,44,false,Unknown,Unknown,false,3
nollysenti_yor_prompt_2,44,false,Unknown,Unknown,false,3
nollysenti_eng_prompt_3,44,false,Unknown,Unknown,false,3
nollysenti_yor_prompt_1,44,false,Unknown,Unknown,false,3
nollysenti_hau_prompt_3,44,false,Unknown,Unknown,false,3
nollysenti_pcm_prompt_4,44,false,Unknown,Unknown,false,3
nollysenti_hau_prompt_4,44,false,Unknown,Unknown,false,3
nollysenti_ibo_prompt_1,44,false,Unknown,Unknown,false,3
nollysenti_yor_prompt_3,44,false,Unknown,Unknown,false,3
nollysenti_ibo_prompt_4,44,false,Unknown,Unknown,false,3
nollysenti_eng_prompt_4,44,false,Unknown,Unknown,false,3
med_prescriptions_hard,44,false,Unknown,Unknown,false,3
nollysenti_pcm_prompt_1,44,false,Unknown,Unknown,false,3
nollysenti_pcm_prompt_5,44,false,Unknown,Unknown,false,3
nollysenti_eng_prompt_1,44,false,Unknown,Unknown,false,3
nollysenti_pcm_prompt_3,44,false,Unknown,Unknown,false,3
ncb,44,false,Unknown,Unknown,false,3
nollysenti_ibo_prompt_3,44,false,Unknown,Unknown,false,3
sycophancy_on_nlp_survey,41,true,EleutherAI/sycophancy,multiple_choice,false,3
sycophancy_on_political_typology_quiz,41,true,EleutherAI/sycophancy,multiple_choice,false,3
inverse_scaling_into_the_unknown,41,true,inverse_scaling_mc,multiple_choice,false,3
sycophancy,41,false,Unknown,Unknown,false,3
code2text_go,41,true,CM/codexglue_code2text_go,generate_until,false,3
meqsum,41,false,Unknown,Unknown,false,3
sycophancy_on_philpapers2020,41,true,EleutherAI/sycophancy,multiple_choice,false,3
evalita-sp_sum_task_fp-small_p2,40,false,Unknown,Unknown,false,3
evalita-mp_sum_fp-small_tasks,40,false,Unknown,Unknown,false,3
evalita-mp_sum_fp,40,false,Unknown,Unknown,false,3
evalita-sp_sum_task_fp-small_p1,40,false,Unknown,Unknown,false,3
inverse_scaling_pattern_matching_suppression,39,true,inverse_scaling_mc,multiple_choice,false,3
inverse_scaling_modus_tollens,36,true,inverse_scaling_mc,multiple_choice,false,3
code2text_php,34,true,CM/codexglue_code2text_php,generate_until,false,3
arc_challenge_mt,33,false,Unknown,Unknown,false,3
inverse_scaling_repetitive_algebra,33,true,inverse_scaling_mc,multiple_choice,false,3
arc_challenge_mt_is,33,true,mideind/icelandic-arc-challenge,multiple_choice,false,3
inverse_scaling_sig_figs,32,true,inverse_scaling_mc,multiple_choice,false,3
piqa_ar,31,true,Hennara/pica_ar,multiple_choice,false,3
code2text_ruby,30,true,CM/codexglue_code2text_ruby,generate_until,false,3
inverse_scaling_hindsight_neglect_10shot,29,true,inverse_scaling_mc,multiple_choice,false,3
copa_ar,28,true,Hennara/copa_ar,multiple_choice,false,3
inverse_scaling_mc,18,false,Unknown,Unknown,false,3
inverse_scaling_winobias_antistereotype,18,true,mathemakitten/winobias_antistereotype_test_v5,multiple_choice,false,3
flan_held_in,0,true,Unknown,Unknown,false,3
scrolls,0,false,Unknown,Unknown,false,3
global_mmlu_full_lt_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_ko_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_en_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_de_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_de_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_de_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_de_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_hi_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_hi_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_hi_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_hi_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_hi_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_lt_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_hi_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_de_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_en_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_ko_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_ar_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_ar_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_ar_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_zh_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_zh_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_zh_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_zh_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_zh_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_zh_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_pt_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_pt_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_pt_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_pt_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_bn_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_bn_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_bn_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_de_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_id_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_fa_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_ko_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_ko_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_ko_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_ko_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_en_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fa_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_persian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fa_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_north macedonian_few_shot_en_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_german_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_italian_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_german_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_telugu_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_telugu_few_shot_en_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_kazakh_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_turkish_few_shot_en_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_turkish_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_turkish_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_turkish_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_en_marine_license,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_en_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_en_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_en_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_georgian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_italian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_italian_few_shot_en_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_italian_few_shot_en_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_telugu_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_japanese_few_shot_en_medical_license,-1,false,Unknown,Unknown,false,3
include_base_44_north macedonian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_uzbek_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_korean_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_en_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_japanese_few_shot_en_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_serbian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_serbian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_north macedonian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_malay_few_shot_en_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_few_shot_en_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_bulgarian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_bulgarian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_bulgarian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_malay_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_malay_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_north macedonian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_few_shot_en_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_korean_few_shot_en_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_telugu_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_en_general_knowledge,-1,false,Unknown,Unknown,false,3
include_base_44_french_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_french_few_shot_og_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_french_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_belarusian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_belarusian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_belarusian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_armenian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_armenian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_armenian_few_shot_og_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_armenian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_few_shot_og_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_polish_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_polish_few_shot_og_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_polish_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_og_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_og_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_french_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_french_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_german_few_shot_en_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_croatian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_estonian_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_estonian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_estonian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_estonian_few_shot_en_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_estonian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian_few_shot_en_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_uzbek_few_shot_en_medical_license,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian_few_shot_en_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_hungarian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_hungarian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_hungarian_few_shot_en_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_urdu_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_urdu_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_uzbek_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_uzbek_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_few_shot_og_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_croatian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_croatian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_bulgarian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_few_shot_en_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_en_medical_license,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_en_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_en_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_few_shot_en_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_hebrew_few_shot_en_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_hebrew_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_few_shot_en_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_few_shot_en_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_italian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_few_shot_en_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_few_shot_en_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_tagalog_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_bulgarian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_few_shot_en_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_polish_few_shot_en_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_polish_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_croatian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_croatian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_croatian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_french_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_french_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_french_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_french_few_shot_en_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_french_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_belarusian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_belarusian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_belarusian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_armenian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_armenian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_armenian_few_shot_en_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_armenian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_polish_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_few_shot_en_general_knowledge,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_en_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_en_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_en_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_en_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_persian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_persian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
global_mmlu_ar_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
include_base_44_persian_few_shot_en_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_tagalog_few_shot_en_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_italian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_japanese_few_shot_en_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_serbian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_few_shot_en_marine_license,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_few_shot_en_general_knowledge,-1,false,Unknown,Unknown,false,3
include_base_44_vietnamese_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_vietnamese_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_vietnamese_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_en_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_persian_few_shot_en_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_few_shot_en_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_few_shot_en_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_nepali_few_shot_en_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_nepali_few_shot_en_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_ukrainian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_ukrainian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_ukrainian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_bengali_few_shot_en_general_knowledge,-1,false,Unknown,Unknown,false,3
include_base_44_bengali_few_shot_en_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_bengali_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_bengali_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_basque_few_shot_en_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_en_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_spanish_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_spanish_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_spanish_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_spanish_few_shot_en_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_tamil_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_tamil_few_shot_en_general_knowledge,-1,false,Unknown,Unknown,false,3
global_mmlu_ar_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_tr_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_ar_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_he_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_bn_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_he_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ms_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_lt_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_ja_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_ja_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_ja_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_ja_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_ja_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_sw_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_sw_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_sw_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_tr_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_portuguese_few_shot_og_business_commerce,-1,false,Unknown,Unknown,false,3
global_mmlu_full_tr_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_it_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
include_base_44_dutch_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_malay_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_malay_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_malay_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_stem,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_korean_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_marine_license,-1,false,Unknown,Unknown,false,3
include_base_44_korean_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_north macedonian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_north macedonian_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_north macedonian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_north macedonian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_serbian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_serbian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_serbian_arts_humanities,-1,false,Unknown,Unknown,false,3
global_mmlu_id_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_id_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_pt_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_id_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_bn_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_bn_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
include_base_44_bulgarian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_health_oriented_education,-1,false,Unknown,Unknown,false,3
global_mmlu_yo_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
include_base_44_malayalam_stem,-1,false,Unknown,Unknown,false,3
global_mmlu_yo_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_pt_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_id_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_en_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_en_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_en_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_en_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_en_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_en_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_es_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_es_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_es_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_es_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_es_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_es_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_fr_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_fr_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_fr_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_fr_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_fr_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_fr_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_id_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
include_base_44_malayalam_social_science,-1,false,Unknown,Unknown,false,3
global_mmlu_ja_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_it_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_ky_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_it_humanities,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_tr_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_sw_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_es_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_sw_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_yo_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_yo_social_sciences,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_yo_medical,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_yo_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_it_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_it_stem,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_it_other,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_tr_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_am_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_sw_business,-1,true,CohereForAI/Global-MMLU-Lite,multiple_choice,false,3
global_mmlu_full_tr_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_tr_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_portuguese_few_shot_og_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
global_mmlu_full_id_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_malayalam_arts_humanities,-1,false,Unknown,Unknown,false,3
global_mmlu_full_id_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_finnish_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
global_mmlu_full_id_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_nl_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ny_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fr_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_id_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ko_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_telugu_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_urdu_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_urdu_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_urdu_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_uzbek_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_uzbek_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_uzbek_few_shot_og_medical_license,-1,false,Unknown,Unknown,false,3
include_base_44_uzbek_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
global_mmlu_full_es_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_en_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_hungarian_few_shot_og_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_hungarian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ne_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_lithuanian_few_shot_og_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_og_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_og_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_russian_few_shot_og_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_georgian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_italian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_italian_few_shot_og_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_italian_few_shot_og_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_italian_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_italian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_telugu_few_shot_og_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_telugu_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_telugu_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_hungarian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_estonian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_estonian_few_shot_og_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_estonian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian_few_shot_og_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ne_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_russian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fil_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_russian_few_shot_og_marine_license,-1,false,Unknown,Unknown,false,3
include_base_44_turkish_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
global_mmlu_full_bn_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_bengali_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_basque_few_shot_og_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_few_shot_og_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_few_shot_og_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_og_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_spanish_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_spanish_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_tamil_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_tamil_few_shot_og_general_knowledge,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_og_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_og_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_og_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_persian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_persian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_persian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_bengali_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_bengali_few_shot_og_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_persian_few_shot_og_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_bengali_few_shot_og_general_knowledge,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_hebrew_few_shot_og_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_hebrew_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_few_shot_og_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_few_shot_og_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_spanish_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_tagalog_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_spanish_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_few_shot_og_general_knowledge,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_few_shot_og_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_few_shot_og_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_nepali_few_shot_og_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_nepali_few_shot_og_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_ukrainian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_ukrainian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_ukrainian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_persian_few_shot_og_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_turkish_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_bulgarian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_bulgarian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_malay_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_malay_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_malay_few_shot_og_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_few_shot_og_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_serbian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_dutch_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_korean_few_shot_og_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_korean_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_north macedonian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_north macedonian_few_shot_og_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_north macedonian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_north macedonian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_serbian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_german_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_estonian_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_italian_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_estonian_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_kazakh_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_turkish_few_shot_og_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_turkish_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_bulgarian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_serbian_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_greek_few_shot_og_medical_license,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_few_shot_og_marine_license,-1,false,Unknown,Unknown,false,3
include_base_44_tagalog_few_shot_og_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_german_few_shot_og_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_few_shot_og_general_knowledge,-1,false,Unknown,Unknown,false,3
include_base_44_vietnamese_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_vietnamese_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_vietnamese_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_og_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_og_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_og_general_knowledge,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_og_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_og_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_few_shot_og_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_japanese_few_shot_og_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_japanese_few_shot_og_medical_license,-1,false,Unknown,Unknown,false,3
include_base_44_japanese_few_shot_og_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_german_few_shot_og_stem,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam_few_shot_og_health_oriented_education,-1,false,Unknown,Unknown,false,3
global_mmlu_full_bn_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ar_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_bn_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ne_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_fil_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_hi_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_es_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_de_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_yo_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_basque,-1,false,Unknown,Unknown,false,3
global_mmlu_full_lt_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_lt_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sw_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sw_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sw_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_id_stem_tasks,-1,false,Unknown,Unknown,false,3
include_base_44_urdu_few_shot_en_stem,-1,false,Unknown,Unknown,false,3
include_base_44_albanian_few_shot_en_arts_humanities,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ru_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ro_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ru_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_te_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_it_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_bengali,-1,false,Unknown,Unknown,false,3
include_base_44_ukrainian,-1,false,Unknown,Unknown,false,3
include_base_44_nepali,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ky_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_am_stem_tasks,-1,false,Unknown,Unknown,false,3
common_voice_en,-1,false,Unknown,Unknown,false,3
global_mmlu_full_am_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ms_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ny_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ny_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ny_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ny_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ko_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ko_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ko_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_mg_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_mg_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_mg_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ja_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_it_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_it_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_it_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_it_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ig_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ig_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ig_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ig_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ky_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ky_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_el_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ky_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fr_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fr,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fr_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fr_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fa_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_es_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_es_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_es_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_es_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_es,-1,true,Unknown,Unknown,false,3
global_mmlu_full_en_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_en_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_en,-1,true,Unknown,Unknown,false,3
global_mmlu_full_en_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_en_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fa_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fa_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fa,-1,true,Unknown,Unknown,false,3
global_mmlu_full_zh_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_pt_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_zh_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_am_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_mg_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_el_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_el_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_id_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_pl_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ms_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_he_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_he_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_he_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_he_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sv_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sv_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sv_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sv_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_vi_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_vi_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_vi_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_vi_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_pl_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_pl_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_cs_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_cs_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_en_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ha_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_nl_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_nl_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_nl_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ar_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_pl_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sw_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_el_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sw_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ja_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ja_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ja_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_am_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ms_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_cs_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fr_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sw_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sw_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ko_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_id_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_id_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_id_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fr_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fr_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ms_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fr_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_es_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_es_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_es_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_es_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_en_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_en_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_id,-1,true,Unknown,Unknown,false,3
global_mmlu_full_id_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ar_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_hi_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fil_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fil_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fil_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_nl,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ha_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ar,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sn_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_uk,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ny_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_uk_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_uk_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_uk_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_uk_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sr_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sr,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sr_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sr_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sr_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sn_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sn,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sn_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ar_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sn_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_hi_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_hi,-1,true,Unknown,Unknown,false,3
global_mmlu_full_si_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fil,-1,true,Unknown,Unknown,false,3
global_mmlu_full_bn_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ne_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ne,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ne_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_bn_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_bn,-1,true,Unknown,Unknown,false,3
global_mmlu_full_bn_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_bn_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_nl_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_nl_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_nl_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ne_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ne_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_de_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fil_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_hi_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ny,-1,true,Unknown,Unknown,false,3
global_mmlu_full_de_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_de_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_de_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_de,-1,true,Unknown,Unknown,false,3
global_mmlu_full_nl_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_hi_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_si_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_si,-1,true,Unknown,Unknown,false,3
global_mmlu_full_id_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_pt,-1,true,Unknown,Unknown,false,3
global_mmlu_zh,-1,true,Unknown,Unknown,false,3
global_mmlu_ar,-1,true,Unknown,Unknown,false,3
global_mmlu_bn,-1,true,Unknown,Unknown,false,3
global_mmlu_hi,-1,true,Unknown,Unknown,false,3
global_mmlu_de,-1,true,Unknown,Unknown,false,3
global_mmlu_ko,-1,true,Unknown,Unknown,false,3
global_mmlu_id,-1,true,Unknown,Unknown,false,3
global_mmlu_fr,-1,true,Unknown,Unknown,false,3
global_mmlu_es,-1,true,Unknown,Unknown,false,3
global_mmlu_en,-1,true,Unknown,Unknown,false,3
global_mmlu_full_tr_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_tr_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_zh_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_lt_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fa_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ny_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fr_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ko_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ko_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ko_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ko_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ko,-1,true,Unknown,Unknown,false,3
global_mmlu_full_id_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_lt,-1,true,Unknown,Unknown,false,3
global_mmlu_it,-1,true,Unknown,Unknown,false,3
global_mmlu_full_si_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_ja,-1,true,Unknown,Unknown,false,3
global_mmlu_full_si_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ha,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ha_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ha_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ha_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ar_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ar_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ar_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ny_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_de_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ny_other,-1,true,Unknown,Unknown,false,3
global_mmlu_yo,-1,true,Unknown,Unknown,false,3
global_mmlu_full_lt_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_lt_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_lt_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_tr,-1,true,Unknown,Unknown,false,3
global_mmlu_full_tr_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_tr_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_tr_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_tr_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_tr_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_tr_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_sw,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ar_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ar_stem_tasks,-1,false,Unknown,Unknown,false,3
include_base_44_arabic,-1,false,Unknown,Unknown,false,3
global_mmlu_full_te_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_te,-1,true,Unknown,Unknown,false,3
global_mmlu_full_te_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_te_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ru_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ru,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ru_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ru_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ru_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ro_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ms_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_he,-1,true,Unknown,Unknown,false,3
global_mmlu_full_fa_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
include_base_44_georgian,-1,false,Unknown,Unknown,false,3
include_base_44_hungarian,-1,false,Unknown,Unknown,false,3
include_base_44_urdu,-1,false,Unknown,Unknown,false,3
include_base_44_uzbek,-1,false,Unknown,Unknown,false,3
include_base_44_telugu,-1,false,Unknown,Unknown,false,3
include_base_44_kazakh,-1,false,Unknown,Unknown,false,3
include_base_44_turkish,-1,false,Unknown,Unknown,false,3
include_base_44_russian,-1,false,Unknown,Unknown,false,3
include_base_44_italian,-1,false,Unknown,Unknown,false,3
include_base_44_belarusian,-1,false,Unknown,Unknown,false,3
include_base_44_tagalog,-1,false,Unknown,Unknown,false,3
global_mmlu_full_te_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_cs_humanities,-1,true,Unknown,Unknown,false,3
include_base_44_portuguese,-1,false,Unknown,Unknown,false,3
global_mmlu_full_cs,-1,true,Unknown,Unknown,false,3
global_mmlu_full_so_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_yo_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_yo,-1,true,Unknown,Unknown,false,3
global_mmlu_full_yo_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_yo_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_yo_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_so_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_so_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_so_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_cs_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_so,-1,true,Unknown,Unknown,false,3
global_mmlu_full_de_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_pt_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_pt_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_pt,-1,true,Unknown,Unknown,false,3
global_mmlu_full_pt_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_zh_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ro_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ro_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ro,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ro_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_cs_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_cs_social_sciences,-1,true,Unknown,Unknown,false,3
include_base_44_greek,-1,false,Unknown,Unknown,false,3
include_base_44_hebrew,-1,false,Unknown,Unknown,false,3
global_mmlu_full_it_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_pl_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_pl_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_vi_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_vi_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_vi_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_vi,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sv_humanities,-1,true,Unknown,Unknown,false,3
include_base_44_azerbaijani,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sv_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sv_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sv_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sv,-1,true,Unknown,Unknown,false,3
global_mmlu_full_he_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_he_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_he_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_pl_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_pl,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sw_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sw,-1,true,Unknown,Unknown,false,3
include_base_44_spanish,-1,false,Unknown,Unknown,false,3
include_base_44_tamil,-1,false,Unknown,Unknown,false,3
include_base_44_chinese,-1,false,Unknown,Unknown,false,3
include_base_44_persian,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian,-1,false,Unknown,Unknown,false,3
global_mmlu_full_pl_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_vi_stem,-1,true,Unknown,Unknown,false,3
include_base_44_finnish,-1,false,Unknown,Unknown,false,3
global_mmlu_full_he_stem,-1,true,Unknown,Unknown,false,3
include_base_44_polish,-1,false,Unknown,Unknown,false,3
include_base_44_croatian,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian,-1,false,Unknown,Unknown,false,3
include_base_44_estonian,-1,false,Unknown,Unknown,false,3
include_base_44_german,-1,false,Unknown,Unknown,false,3
include_base_44_japanese,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fa_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fa_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fa_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_lt_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_lt_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
include_base_44_albanian,-1,false,Unknown,Unknown,false,3
include_base_44_bulgarian,-1,false,Unknown,Unknown,false,3
include_base_44_malay,-1,false,Unknown,Unknown,false,3
include_base_44_dutch,-1,false,Unknown,Unknown,false,3
include_base_44_korean,-1,false,Unknown,Unknown,false,3
include_base_44_north macedonian,-1,false,Unknown,Unknown,false,3
include_base_44_serbian,-1,false,Unknown,Unknown,false,3
include_base_44_malayalam,-1,false,Unknown,Unknown,false,3
include_base_44_vietnamese,-1,false,Unknown,Unknown,false,3
include_base_44_hindi,-1,false,Unknown,Unknown,false,3
include_base_44_french,-1,false,Unknown,Unknown,false,3
include_base_44_armenian,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ms,-1,true,Unknown,Unknown,false,3
global_mmlu_full_it,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ha_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ne_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sn_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sn_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_cs_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ro_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_yo_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_yo_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_yo_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_yo_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ro_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ro_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ro_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ru_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sr_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ru_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ru_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ru_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_te_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_te_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_te_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_te_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_so_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_so_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_so_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_bn_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ne_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sr_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ne_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sn_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ha_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ha_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_si_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_si_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_si_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_si_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sn_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_nl_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_bn_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_bn_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_bn_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_de_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_de_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_hi_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_hi_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_hi_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_hi_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fil_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fil_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fil_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_fil_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ne_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_so_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sr_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_mg,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ig,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ig_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ig_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ig_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_it_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_it_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ja,-1,true,Unknown,Unknown,false,3
global_mmlu_full_mg_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_mg_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_mg_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ms_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ms_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ms_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_am_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_am,-1,true,Unknown,Unknown,false,3
global_mmlu_full_am_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_am_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_am_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ky,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ky_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ky_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ky_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ky_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_mg_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ig_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_it_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sr_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_el_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_uk_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_uk_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_uk_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_uk_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_zh_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_zh_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_zh_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_zh_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_pt_humanities_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_pt_other_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_pt_stem_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_pt_social_sciences_tasks,-1,false,Unknown,Unknown,false,3
global_mmlu_full_en_other_tasks,-1,false,Unknown,Unknown,false,3
toxigen,-1,true,skg/toxigen-data,multiple_choice,false,3
global_mmlu_full_zh,-1,true,Unknown,Unknown,false,3
global_mmlu_full_el,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ja_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ja_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ja_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_ja_other,-1,true,Unknown,Unknown,false,3
global_mmlu_full_el_stem,-1,true,Unknown,Unknown,false,3
global_mmlu_full_el_humanities,-1,true,Unknown,Unknown,false,3
global_mmlu_full_el_social_sciences,-1,true,Unknown,Unknown,false,3
global_mmlu_full_sn_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_cs_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_french_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_stem,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_polish_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_polish_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_polish_stem,-1,false,Unknown,Unknown,false,3
include_base_44_croatian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_croatian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_croatian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_french_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_french_stem,-1,false,Unknown,Unknown,false,3
include_base_44_french_driving_license,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sw_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_french_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_belarusian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_belarusian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_belarusian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_armenian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_hebrew_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_social_science,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sw_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_portuguese_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_russian_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_russian_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_finnish_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_hebrew_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_arts_humanities,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sv_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_georgian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_italian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_italian_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_stem,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_nepali_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_nepali_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_ukrainian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_ukrainian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_ukrainian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_bengali_general_knowledge,-1,false,Unknown,Unknown,false,3
include_base_44_bengali_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_bengali_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_bengali_stem,-1,false,Unknown,Unknown,false,3
include_base_44_basque_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_persian_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_persian_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_persian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_tamil_stem,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_stem,-1,false,Unknown,Unknown,false,3
include_base_44_spanish_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_general_knowledge,-1,false,Unknown,Unknown,false,3
include_base_44_arabic_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_italian_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_italian_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_italian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_italian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_tagalog_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_tagalog_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_greek_medical_license,-1,false,Unknown,Unknown,false,3
include_base_44_greek_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_greek_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_greek_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_greek_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_greek_stem,-1,false,Unknown,Unknown,false,3
include_base_44_greek_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_portuguese_stem,-1,false,Unknown,Unknown,false,3
include_base_44_armenian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_armenian_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_armenian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_azerbaijani_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_indonesian_applied_science,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sv_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sv_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_spanish_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_spanish_stem,-1,false,Unknown,Unknown,false,3
include_base_44_spanish_health_oriented_education,-1,false,Unknown,Unknown,false,3
global_mmlu_full_ja_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_estonian_stem,-1,false,Unknown,Unknown,false,3
global_mmlu_full_mg_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ja_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_el_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ky_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_mg_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_lithuanian_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_estonian_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_tamil_general_knowledge,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sw_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_persian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_stem,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_chinese_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_persian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_russian_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_russian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_russian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_vietnamese_stem,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sw_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_estonian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_turkish_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_turkish_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_russian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_russian_marine_license,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian_business_commerce,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_japanese_medical_license,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_stem,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_general_knowledge,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_hindi_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_japanese_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_japanese_professional_certification,-1,false,Unknown,Unknown,false,3
include_base_44_lithuanian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_german_stem,-1,false,Unknown,Unknown,false,3
include_base_44_german_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_german_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_estonian_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_estonian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_turkish_stem,-1,false,Unknown,Unknown,false,3
include_base_44_turkish_business_commerce,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sw_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_kazakh_arts_humanities,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sw_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_malayalam_general_knowledge,-1,false,Unknown,Unknown,false,3
include_base_44_vietnamese_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_russian_driving_license,-1,false,Unknown,Unknown,false,3
include_base_44_vietnamese_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_hungarian_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_hungarian_stem,-1,false,Unknown,Unknown,false,3
include_base_44_hungarian_applied_science,-1,false,Unknown,Unknown,false,3
include_base_44_urdu_health_oriented_education,-1,false,Unknown,Unknown,false,3
include_base_44_urdu_stem,-1,false,Unknown,Unknown,false,3
include_base_44_urdu_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_uzbek_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_uzbek_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_uzbek_medical_license,-1,false,Unknown,Unknown,false,3
include_base_44_uzbek_stem,-1,false,Unknown,Unknown,false,3
include_base_44_telugu_social_science,-1,false,Unknown,Unknown,false,3
include_base_44_telugu_stem,-1,false,Unknown,Unknown,false,3
include_base_44_telugu_arts_humanities,-1,false,Unknown,Unknown,false,3
include_base_44_telugu_applied_science,-1,false,Unknown,Unknown,false,3
global_mmlu_full_sw_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_he_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sw_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ha_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sr_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_si_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_sn_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_ig_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
include_base_44_albanian_few_shot_en_social_science,-1,false,Unknown,Unknown,false,3
global_mmlu_full_vi_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_european_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pl_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_vi_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_formal_logic,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_statistics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_professional_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_human_aging,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_machine_learning,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_global_facts,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_government_and_politics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_moral_disputes,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_logical_fallacies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_college_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_high_school_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_so_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_jurisprudence,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_medical_genetics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_college_biology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_nutrition,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_international_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_professional_accounting,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_marketing,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_college_medicine,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_human_sexuality,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_management,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_us_foreign_policy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_college_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_microeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_college_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_prehistory,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_philosophy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_pt_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_astronomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_moral_scenarios,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_professional_law,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_world_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_computer_science,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_college_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_electrical_engineering,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_clinical_knowledge,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_chemistry,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_econometrics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_sociology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_computer_security,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_business_ethics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_virology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_anatomy,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_world_religions,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_security_studies,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_professional_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_elementary_mathematics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_us_history,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_public_relations,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_conceptual_physics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_high_school_geography,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_macroeconomics,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_high_school_psychology,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_zh_miscellaneous,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
global_mmlu_full_uk_abstract_algebra,-1,true,CohereForAI/Global-MMLU,multiple_choice,false,3
truthfulqa_mr_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_sk_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_hu_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_pt_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_zh_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_hy_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_kn_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_eu_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_ar_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
hellaswag_hy,-2,true,hellaswag_multilingual,multiple_choice,false,3
truthfulqa_ne_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_uk_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_ar_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_nl_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_uk_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_es_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
arc_uk,-2,true,arc_multilingual,multiple_choice,false,3
truthfulqa_da_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_hi_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
arc_sr,-2,true,arc_multilingual,multiple_choice,false,3
truthfulqa_kn_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
arc_it,-2,true,arc_multilingual,multiple_choice,false,3
arc_pt,-2,true,arc_multilingual,multiple_choice,false,3
arc_ml,-2,true,arc_multilingual,multiple_choice,false,3
arc_sk,-2,true,arc_multilingual,multiple_choice,false,3
arc_ta,-2,true,arc_multilingual,multiple_choice,false,3
arc_ru,-2,true,arc_multilingual,multiple_choice,false,3
arc_de,-2,true,arc_multilingual,multiple_choice,false,3
arc_nl,-2,true,arc_multilingual,multiple_choice,false,3
hellaswag_bn,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_hu,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_mr,-2,true,hellaswag_multilingual,multiple_choice,false,3
truthfulqa_ca_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_ta_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_ne_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
longcxt,-2,false,Unknown,Unknown,false,3
truthfulqa_pt_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_ml_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
hellaswag_gu,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_ne,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_fr,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_kn,-2,true,hellaswag_multilingual,multiple_choice,false,3
truthfulqa_vi_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_id_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_fr_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
hellaswag_hi,-2,true,hellaswag_multilingual,multiple_choice,false,3
truthfulqa_te_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_it_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_sr_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_de_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_gu_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
med_text_classification_easy,-2,false,Unknown,Unknown,false,3
hellaswag_ca,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_ro,-2,true,hellaswag_multilingual,multiple_choice,false,3
truthfulqa_zh_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_ru_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_sk_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_eu_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_ca_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_sv_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_bn_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_hr_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
hellaswag_es,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_eu,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_ar,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_sv,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_da,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_id,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_te,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_vi,-2,true,hellaswag_multilingual,multiple_choice,false,3
arc_hr,-2,true,arc_multilingual,multiple_choice,false,3
arc_multilingual,-2,false,Unknown,Unknown,false,3
arc_mr,-2,true,arc_multilingual,multiple_choice,false,3
med_text_classification_hard,-2,false,Unknown,Unknown,false,3
truthfulqa_sr_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
hellaswag_multilingual,-2,false,Unknown,Unknown,false,3
truthfulqa_multilingual,-2,false,Unknown,Unknown,false,3
truthfulqa_hi_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
med_text_classification,-2,false,Unknown,Unknown,false,3
truthfulqa_da_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_ro_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_ro_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
arc_ro,-2,true,arc_multilingual,multiple_choice,false,3
arc_hy,-2,true,arc_multilingual,multiple_choice,false,3
arc_sv,-2,true,arc_multilingual,multiple_choice,false,3
arc_ar,-2,true,arc_multilingual,multiple_choice,false,3
arc_es,-2,true,arc_multilingual,multiple_choice,false,3
arc_id,-2,true,arc_multilingual,multiple_choice,false,3
arc_da,-2,true,arc_multilingual,multiple_choice,false,3
truthfulqa_te_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_fr_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_ml_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_gu_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_sv_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_ta_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_bn_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_ru_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_hr_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_hy_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_mr_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_id_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
ruler,-2,false,Unknown,Unknown,false,3
truthfulqa_es_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_nl_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_de_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_it_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
truthfulqa_vi_mc2,-2,true,truthfulqa_multilingual,multiple_choice,false,3
arc_vi,-2,true,arc_multilingual,multiple_choice,false,3
arc_te,-2,true,arc_multilingual,multiple_choice,false,3
arc_eu,-2,true,arc_multilingual,multiple_choice,false,3
niah_single_2,-2,false,Unknown,Unknown,false,3
truthfulqa_hu_mc1,-2,true,truthfulqa_multilingual,multiple_choice,false,3
niah_multikey_3,-2,false,Unknown,Unknown,false,3
niah_multikey_1,-2,false,Unknown,Unknown,false,3
ruler_qa_squad,-2,false,Unknown,Unknown,false,3
ruler_cwe,-2,false,Unknown,Unknown,false,3
niah_single_3,-2,false,Unknown,Unknown,false,3
ruler_vt,-2,false,Unknown,Unknown,false,3
arc_zh,-2,true,arc_multilingual,multiple_choice,false,3
niah_single_1,-2,false,Unknown,Unknown,false,3
niah_multiquery,-2,false,Unknown,Unknown,false,3
ruler_fwe,-2,false,Unknown,Unknown,false,3
ruler_qa_hotpot,-2,false,Unknown,Unknown,false,3
niah_multivalue,-2,false,Unknown,Unknown,false,3
niah_multikey_2,-2,false,Unknown,Unknown,false,3
arc_hu,-2,true,arc_multilingual,multiple_choice,false,3
hellaswag_nl,-2,true,hellaswag_multilingual,multiple_choice,false,3
arc_gu,-2,true,arc_multilingual,multiple_choice,false,3
hellaswag_it,-2,true,hellaswag_multilingual,multiple_choice,false,3
arc_ca,-2,true,arc_multilingual,multiple_choice,false,3
arc_hi,-2,true,arc_multilingual,multiple_choice,false,3
arc_fr,-2,true,arc_multilingual,multiple_choice,false,3
arc_bn,-2,true,arc_multilingual,multiple_choice,false,3
arc_ne,-2,true,arc_multilingual,multiple_choice,false,3
arc_kn,-2,true,arc_multilingual,multiple_choice,false,3
hellaswag_sr,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_uk,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_hr,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_ml,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_sk,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_ta,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_de,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_ru,-2,true,hellaswag_multilingual,multiple_choice,false,3
hellaswag_pt,-2,true,hellaswag_multilingual,multiple_choice,false,3
